<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Hypothesis testing: A-level recap | MAS109 - An Introduction to Data Science</title>
  <meta name="description" content="Lecture notes for MAS109" />
  <meta name="generator" content="bookdown 0.42 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Hypothesis testing: A-level recap | MAS109 - An Introduction to Data Science" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Lecture notes for MAS109" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Hypothesis testing: A-level recap | MAS109 - An Introduction to Data Science" />
  
  <meta name="twitter:description" content="Lecture notes for MAS109" />
  

<meta name="author" content="Dr Jill Johnson" />


<meta name="date" content="2025-02-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="interval-estimates-and-confidence-intervals.html"/>
<link rel="next" href="hypothesis-testing-comparing-two-population-means.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">MAS109 - Introduction to Data Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About these notes</a></li>
<li class="chapter" data-level="1" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html"><i class="fa fa-check"></i><b>1</b> Exploratory Data Analysis using R</a>
<ul>
<li class="chapter" data-level="1.1" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#case-study-what-makes-a-country-good-at-maths"><i class="fa fa-check"></i><b>1.1</b> Case study: what makes a country good at maths?</a></li>
<li class="chapter" data-level="1.2" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#the-tidyverse"><i class="fa fa-check"></i><b>1.2</b> The “Tidyverse”</a></li>
<li class="chapter" data-level="1.3" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#importing-data-into-r-csv-and-.xlsx-files"><i class="fa fa-check"></i><b>1.3</b> Importing data into R: <code>csv</code> and <code>.xlsx</code> files</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#importing-excel-.xlsx-files"><i class="fa fa-check"></i><b>1.3.1</b> Importing Excel <code>.xlsx</code> files</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#data-frames-and-tibbles-in-r"><i class="fa fa-check"></i><b>1.4</b> Data frames and tibbles in R</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#ordering-the-rows-by-a-variable-with-the-arrange-command"><i class="fa fa-check"></i><b>1.4.1</b> Ordering the rows by a variable with the <code>arrange()</code> command</a></li>
<li class="chapter" data-level="1.4.2" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#selecting-rows-with-the-filter-command"><i class="fa fa-check"></i><b>1.4.2</b> Selecting rows with the <code>filter()</code> command</a></li>
<li class="chapter" data-level="1.4.3" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#viewing-and-extracting-data-from-a-column"><i class="fa fa-check"></i><b>1.4.3</b> Viewing and extracting data from a column</a></li>
<li class="chapter" data-level="1.4.4" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#creating-new-columns-in-a-data-frame-with-the-mutate-command"><i class="fa fa-check"></i><b>1.4.4</b> Creating new columns in a data frame with the <code>mutate()</code> command</a></li>
<li class="chapter" data-level="1.4.5" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#chaining-commands-together-with-the-pipe-operator"><i class="fa fa-check"></i><b>1.4.5</b> Chaining commands together with the pipe operator <code>%&gt;%</code></a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#calculating-summary-statistics-with-the-summary-command"><i class="fa fa-check"></i><b>1.5</b> Calculating summary statistics with the <code>summary()</code> command</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#calculating-individual-summary-statistics"><i class="fa fa-check"></i><b>1.5.1</b> Calculating individual summary statistics</a></li>
<li class="chapter" data-level="1.5.2" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#calculating-other-quantilespercentiles"><i class="fa fa-check"></i><b>1.5.2</b> Calculating other quantiles/percentiles</a></li>
<li class="chapter" data-level="1.5.3" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#computing-summaries-per-group"><i class="fa fa-check"></i><b>1.5.3</b> Computing summaries per group</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#plotting-a-distribution-using-a-histogram"><i class="fa fa-check"></i><b>1.6</b> Plotting a distribution using a histogram</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#describing-the-shape-of-a-distribution-skewness"><i class="fa fa-check"></i><b>1.6.1</b> Describing the shape of a distribution: skewness</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#introducing-ggplot2"><i class="fa fa-check"></i><b>1.7</b> Introducing <code>ggplot2</code></a></li>
<li class="chapter" data-level="1.8" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#drawing-a-histogram-in-r"><i class="fa fa-check"></i><b>1.8</b> Drawing a histogram in R</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#customising-a-histogram-plot-in-r"><i class="fa fa-check"></i><b>1.8.1</b> Customising a histogram plot in R</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#covariance-and-correlation"><i class="fa fa-check"></i><b>1.9</b> Covariance and correlation</a>
<ul>
<li class="chapter" data-level="1.9.1" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#calculating-a-covariance-in-r"><i class="fa fa-check"></i><b>1.9.1</b> Calculating a covariance in R</a></li>
<li class="chapter" data-level="1.9.2" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#pearsons-correlation-coefficient"><i class="fa fa-check"></i><b>1.9.2</b> Pearson’s correlation coefficient</a></li>
<li class="chapter" data-level="1.9.3" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#calculating-pearsons-correlation-coefficient-in-r"><i class="fa fa-check"></i><b>1.9.3</b> Calculating Pearson’s correlation coefficient in R</a></li>
<li class="chapter" data-level="1.9.4" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#spearmans-correlation-coefficient"><i class="fa fa-check"></i><b>1.9.4</b> Spearman’s correlation coefficient</a></li>
<li class="chapter" data-level="1.9.5" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#calculating-spearmans-correlation-coefficient-in-r"><i class="fa fa-check"></i><b>1.9.5</b> Calculating Spearman’s correlation coefficient in R</a></li>
<li class="chapter" data-level="1.9.6" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#interpreting-correlation-coefficients"><i class="fa fa-check"></i><b>1.9.6</b> Interpreting correlation coefficients</a></li>
<li class="chapter" data-level="1.9.7" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#correlations-for-the-maths-data-set"><i class="fa fa-check"></i><b>1.9.7</b> Correlations for the <code>maths</code> data set</a></li>
</ul></li>
<li class="chapter" data-level="1.10" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#drawing-a-scatter-plot-in-r"><i class="fa fa-check"></i><b>1.10</b> Drawing a scatter plot in R</a>
<ul>
<li class="chapter" data-level="1.10.1" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#customising-a-scatter-plot-in-r"><i class="fa fa-check"></i><b>1.10.1</b> Customising a scatter plot in R</a></li>
<li class="chapter" data-level="1.10.2" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#adding-a-nonlinear-trend-to-a-scatter-plot-in-r"><i class="fa fa-check"></i><b>1.10.2</b> Adding a nonlinear trend to a scatter plot in R</a></li>
<li class="chapter" data-level="1.10.3" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#adding-a-linear-trend-to-a-scatter-plot-in-r"><i class="fa fa-check"></i><b>1.10.3</b> Adding a linear trend to a scatter plot in R</a></li>
</ul></li>
<li class="chapter" data-level="1.11" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#box-plots"><i class="fa fa-check"></i><b>1.11</b> Box plots</a></li>
<li class="chapter" data-level="1.12" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#scatter-plots-to-represent-three-variables"><i class="fa fa-check"></i><b>1.12</b> Scatter plots to represent three variables</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="machine-learning.html"><a href="machine-learning.html"><i class="fa fa-check"></i><b>2</b> Machine Learning</a>
<ul>
<li class="chapter" data-level="2.1" data-path="machine-learning.html"><a href="machine-learning.html#can-we-teach-a-computer-to-identify-handwritten-digits"><i class="fa fa-check"></i><b>2.1</b> Can we teach a computer to identify handwritten digits?</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="machine-learning.html"><a href="machine-learning.html#step-1-converting-an-image-into-data"><i class="fa fa-check"></i><b>2.1.1</b> Step 1: converting an image into data</a></li>
<li class="chapter" data-level="2.1.2" data-path="machine-learning.html"><a href="machine-learning.html#step-2-assembling-the-training-data-set"><i class="fa fa-check"></i><b>2.1.2</b> Step 2: assembling the training data set</a></li>
<li class="chapter" data-level="2.1.3" data-path="machine-learning.html"><a href="machine-learning.html#step-3-an-algorithm-for-estimating-the-digit-in-a-new-image"><i class="fa fa-check"></i><b>2.1.3</b> Step 3: an algorithm for estimating the digit in a new image</a></li>
<li class="chapter" data-level="2.1.4" data-path="machine-learning.html"><a href="machine-learning.html#the-k-nearest-neighbour-algorithm-knn"><i class="fa fa-check"></i><b>2.1.4</b> The <span class="math inline">\(K\)</span> nearest neighbour algorithm (KNN)</a></li>
<li class="chapter" data-level="2.1.5" data-path="machine-learning.html"><a href="machine-learning.html#using-k-nearest-neighbours-in-r"><i class="fa fa-check"></i><b>2.1.5</b> Using <span class="math inline">\(K\)</span> nearest neighbours in R</a></li>
<li class="chapter" data-level="2.1.6" data-path="machine-learning.html"><a href="machine-learning.html#the-performance-of-the-algorithm"><i class="fa fa-check"></i><b>2.1.6</b> The performance of the algorithm</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="populations-samples-and-statistical-models.html"><a href="populations-samples-and-statistical-models.html"><i class="fa fa-check"></i><b>3</b> Populations, samples and statistical models</a>
<ul>
<li class="chapter" data-level="3.1" data-path="populations-samples-and-statistical-models.html"><a href="populations-samples-and-statistical-models.html#statistical-models"><i class="fa fa-check"></i><b>3.1</b> Statistical models</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="populations-samples-and-statistical-models.html"><a href="populations-samples-and-statistical-models.html#objectives"><i class="fa fa-check"></i><b>3.1.1</b> Objectives</a></li>
<li class="chapter" data-level="3.1.2" data-path="populations-samples-and-statistical-models.html"><a href="populations-samples-and-statistical-models.html#comment-infinite-and-finite-populations"><i class="fa fa-check"></i><b>3.1.2</b> Comment: infinite and finite populations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="point-estimation.html"><a href="point-estimation.html"><i class="fa fa-check"></i><b>4</b> Point estimation</a>
<ul>
<li class="chapter" data-level="4.1" data-path="point-estimation.html"><a href="point-estimation.html#estimating-the-parameters-of-a-normal-distribution"><i class="fa fa-check"></i><b>4.1</b> Estimating the parameters of a normal distribution</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="point-estimation.html"><a href="point-estimation.html#problem-setup-and-notation"><i class="fa fa-check"></i><b>4.1.1</b> Problem setup and notation</a></li>
<li class="chapter" data-level="4.1.2" data-path="point-estimation.html"><a href="point-estimation.html#the-sample-mean-and-sample-variance"><i class="fa fa-check"></i><b>4.1.2</b> The sample mean and sample variance</a></li>
<li class="chapter" data-level="4.1.3" data-path="point-estimation.html"><a href="point-estimation.html#point-estimates-for-the-mean-and-variance"><i class="fa fa-check"></i><b>4.1.3</b> Point estimates for the mean and variance</a></li>
<li class="chapter" data-level="4.1.4" data-path="point-estimation.html"><a href="point-estimation.html#testing-the-method"><i class="fa fa-check"></i><b>4.1.4</b> Testing the method</a></li>
<li class="chapter" data-level="4.1.5" data-path="point-estimation.html"><a href="point-estimation.html#estimators-and-estimates"><i class="fa fa-check"></i><b>4.1.5</b> Estimators and estimates</a></li>
<li class="chapter" data-level="4.1.6" data-path="point-estimation.html"><a href="point-estimation.html#the-chi2-distribution"><i class="fa fa-check"></i><b>4.1.6</b> The <span class="math inline">\(\chi^2\)</span> distribution</a></li>
<li class="chapter" data-level="4.1.7" data-path="point-estimation.html"><a href="point-estimation.html#the-distribution-of-the-estimators"><i class="fa fa-check"></i><b>4.1.7</b> The distribution of the estimators</a></li>
<li class="chapter" data-level="4.1.8" data-path="point-estimation.html"><a href="point-estimation.html#unbiased-estimators"><i class="fa fa-check"></i><b>4.1.8</b> Unbiased estimators</a></li>
<li class="chapter" data-level="4.1.9" data-path="point-estimation.html"><a href="point-estimation.html#the-standard-error-of-an-estimator"><i class="fa fa-check"></i><b>4.1.9</b> The standard error of an estimator</a></li>
<li class="chapter" data-level="4.1.10" data-path="point-estimation.html"><a href="point-estimation.html#consistent-estimators"><i class="fa fa-check"></i><b>4.1.10</b> Consistent estimators</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="point-estimation.html"><a href="point-estimation.html#estimating-the-probability-parameter-in-a-binomial-distribution"><i class="fa fa-check"></i><b>4.2</b> Estimating the probability parameter in a Binomial distribution</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="interval-estimates-and-confidence-intervals.html"><a href="interval-estimates-and-confidence-intervals.html"><i class="fa fa-check"></i><b>5</b> Interval estimates and confidence intervals</a>
<ul>
<li class="chapter" data-level="5.1" data-path="interval-estimates-and-confidence-intervals.html"><a href="interval-estimates-and-confidence-intervals.html#the-student-t-distribution"><i class="fa fa-check"></i><b>5.1</b> The Student <span class="math inline">\(t\)</span> distribution</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="interval-estimates-and-confidence-intervals.html"><a href="interval-estimates-and-confidence-intervals.html#mean-and-variance-of-the-t-distribution"><i class="fa fa-check"></i><b>5.1.1</b> Mean and variance of the <span class="math inline">\(t\)</span>-distribution</a></li>
<li class="chapter" data-level="5.1.2" data-path="interval-estimates-and-confidence-intervals.html"><a href="interval-estimates-and-confidence-intervals.html#notation-quantilespercentiles-of-the-t-distribution"><i class="fa fa-check"></i><b>5.1.2</b> Notation: quantiles/percentiles of the <span class="math inline">\(t\)</span> distribution</a></li>
<li class="chapter" data-level="5.1.3" data-path="interval-estimates-and-confidence-intervals.html"><a href="interval-estimates-and-confidence-intervals.html#the-t-distribution-in-r."><i class="fa fa-check"></i><b>5.1.3</b> The <span class="math inline">\(t\)</span> distribution in R.</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="interval-estimates-and-confidence-intervals.html"><a href="interval-estimates-and-confidence-intervals.html#confidence-intervals-for-the-mean-and-the-variance-of-a-normal-distribution"><i class="fa fa-check"></i><b>5.2</b> Confidence intervals for the mean and the variance of a normal distribution</a></li>
<li class="chapter" data-level="5.3" data-path="interval-estimates-and-confidence-intervals.html"><a href="interval-estimates-and-confidence-intervals.html#confidence-interval-for-the-probability-parameter-in-a-binomial-distribution"><i class="fa fa-check"></i><b>5.3</b> Confidence interval for the probability parameter in a binomial distribution</a></li>
<li class="chapter" data-level="5.4" data-path="interval-estimates-and-confidence-intervals.html"><a href="interval-estimates-and-confidence-intervals.html#alpha-confidence-intervals"><i class="fa fa-check"></i><b>5.4</b> <span class="math inline">\(100(1-\alpha)\%\)</span> Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="hypothesis-testing-a-level-recap.html"><a href="hypothesis-testing-a-level-recap.html"><i class="fa fa-check"></i><b>6</b> Hypothesis testing: A-level recap</a>
<ul>
<li class="chapter" data-level="6.1" data-path="hypothesis-testing-a-level-recap.html"><a href="hypothesis-testing-a-level-recap.html#hypothesis-testing-with-the-neyman-pearson-approach"><i class="fa fa-check"></i><b>6.1</b> Hypothesis testing with the Neyman-Pearson approach</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="hypothesis-testing-a-level-recap.html"><a href="hypothesis-testing-a-level-recap.html#one-sided-and-two-sided-alternative-hypotheses"><i class="fa fa-check"></i><b>6.1.1</b> One-sided and two-sided alternative hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="hypothesis-testing-a-level-recap.html"><a href="hypothesis-testing-a-level-recap.html#fishers-p-value-method"><i class="fa fa-check"></i><b>6.2</b> Fisher’s <span class="math inline">\(p\)</span>-value method</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="hypothesis-testing-a-level-recap.html"><a href="hypothesis-testing-a-level-recap.html#what-counts-as-a-small-p-value"><i class="fa fa-check"></i><b>6.2.1</b> What counts as a small <span class="math inline">\(p\)</span>-value?</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="hypothesis-testing-a-level-recap.html"><a href="hypothesis-testing-a-level-recap.html#relationship-between-the-neyman-pearson-and-p-value-methods"><i class="fa fa-check"></i><b>6.3</b> Relationship between the Neyman-Pearson and <span class="math inline">\(p\)</span>-value methods</a></li>
<li class="chapter" data-level="6.4" data-path="hypothesis-testing-a-level-recap.html"><a href="hypothesis-testing-a-level-recap.html#which-hypothesis-test-do-i-use-for"><i class="fa fa-check"></i><b>6.4</b> Which hypothesis test do I use for…?</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html"><i class="fa fa-check"></i><b>7</b> Hypothesis testing: comparing two population means</a>
<ul>
<li class="chapter" data-level="7.1" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#example-can-imagining-eating-food-make-you-eat-less"><i class="fa fa-check"></i><b>7.1</b> Example: can imagining eating food make you eat less?</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#the-hypotheses"><i class="fa fa-check"></i><b>7.1.1</b> The hypotheses</a></li>
<li class="chapter" data-level="7.1.2" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#a-test-statistic"><i class="fa fa-check"></i><b>7.1.2</b> A test statistic</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#hypothesis-testing-using-simulation"><i class="fa fa-check"></i><b>7.2</b> Hypothesis testing using simulation</a></li>
<li class="chapter" data-level="7.3" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#the-two-sample-t-test"><i class="fa fa-check"></i><b>7.3</b> The two-sample <span class="math inline">\(t\)</span> test</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#the-two-sample-t-test-with-the-neyman-pearson-method"><i class="fa fa-check"></i><b>7.3.1</b> The two-sample <span class="math inline">\(t\)</span>-test with the Neyman-Pearson method</a></li>
<li class="chapter" data-level="7.3.2" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#an-illustrated-guide"><i class="fa fa-check"></i><b>7.3.2</b> An illustrated guide</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#confidence-interval-for-the-difference-between-two-means"><i class="fa fa-check"></i><b>7.4</b> Confidence interval for the difference between two means</a></li>
<li class="chapter" data-level="7.5" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#equivalence-of-confidence-intervals-and-neyman-pearson-testing"><i class="fa fa-check"></i><b>7.5</b> Equivalence of confidence intervals and Neyman-Pearson testing</a></li>
<li class="chapter" data-level="7.6" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#the-two-sample-t-test-in-r"><i class="fa fa-check"></i><b>7.6</b> The two-sample <span class="math inline">\(t\)</span> test in R</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#t-tests-with-data-frames-in-r"><i class="fa fa-check"></i><b>7.6.1</b> <span class="math inline">\(t\)</span>-tests with data frames in R</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#examples"><i class="fa fa-check"></i><b>7.7</b> Examples</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#using-the-p-value-method"><i class="fa fa-check"></i><b>7.7.1</b> Using the <span class="math inline">\(p\)</span>-value method</a></li>
<li class="chapter" data-level="7.7.2" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#using-neyman-pearson-testing"><i class="fa fa-check"></i><b>7.7.2</b> Using Neyman-Pearson testing</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="hypothesis-testing-comparing-two-proportions.html"><a href="hypothesis-testing-comparing-two-proportions.html"><i class="fa fa-check"></i><b>8</b> Hypothesis testing: comparing two proportions</a>
<ul>
<li class="chapter" data-level="8.1" data-path="hypothesis-testing-comparing-two-proportions.html"><a href="hypothesis-testing-comparing-two-proportions.html#example-an-investigation-into-gender-bias"><i class="fa fa-check"></i><b>8.1</b> Example: an investigation into gender bias</a></li>
<li class="chapter" data-level="8.2" data-path="hypothesis-testing-comparing-two-proportions.html"><a href="hypothesis-testing-comparing-two-proportions.html#comparing-two-binomial-proportions"><i class="fa fa-check"></i><b>8.2</b> Comparing two binomial proportions</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="hypothesis-testing-comparing-two-proportions.html"><a href="hypothesis-testing-comparing-two-proportions.html#a-simulation-method"><i class="fa fa-check"></i><b>8.2.1</b> A simulation method</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="hypothesis-testing-comparing-two-proportions.html"><a href="hypothesis-testing-comparing-two-proportions.html#an-analytical-method"><i class="fa fa-check"></i><b>8.3</b> An analytical method</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="hypothesis-testing-comparing-two-proportions.html"><a href="hypothesis-testing-comparing-two-proportions.html#the-analytical-method-a-summary"><i class="fa fa-check"></i><b>8.3.1</b> The analytical method: a summary</a></li>
<li class="chapter" data-level="8.3.2" data-path="hypothesis-testing-comparing-two-proportions.html"><a href="hypothesis-testing-comparing-two-proportions.html#conclusion"><i class="fa fa-check"></i><b>8.3.2</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="hypothesis-testing-comparing-two-proportions.html"><a href="hypothesis-testing-comparing-two-proportions.html#confidence-intervals-to-measure-the-difference"><i class="fa fa-check"></i><b>8.4</b> Confidence intervals to measure the difference</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="sample-size-and-power-for-a-neyman-pearson-hypothesis-test.html"><a href="sample-size-and-power-for-a-neyman-pearson-hypothesis-test.html"><i class="fa fa-check"></i><b>9</b> Sample size and power for a Neyman-Pearson hypothesis test</a>
<ul>
<li class="chapter" data-level="9.1" data-path="sample-size-and-power-for-a-neyman-pearson-hypothesis-test.html"><a href="sample-size-and-power-for-a-neyman-pearson-hypothesis-test.html#gender-bias-example-re-visited"><i class="fa fa-check"></i><b>9.1</b> Gender bias example re-visited</a></li>
<li class="chapter" data-level="9.2" data-path="sample-size-and-power-for-a-neyman-pearson-hypothesis-test.html"><a href="sample-size-and-power-for-a-neyman-pearson-hypothesis-test.html#the-power-of-a-hypothesis-test"><i class="fa fa-check"></i><b>9.2</b> The power of a hypothesis test</a></li>
<li class="chapter" data-level="9.3" data-path="sample-size-and-power-for-a-neyman-pearson-hypothesis-test.html"><a href="sample-size-and-power-for-a-neyman-pearson-hypothesis-test.html#an-analytical-approach"><i class="fa fa-check"></i><b>9.3</b> An analytical approach</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html"><i class="fa fa-check"></i><b>10</b> <span class="math inline">\(\chi^2\)</span> tests for contingency tables</a>
<ul>
<li class="chapter" data-level="10.1" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#example-customer-ratings-of-restaurants"><i class="fa fa-check"></i><b>10.1</b> Example: customer ratings of restaurants</a></li>
<li class="chapter" data-level="10.2" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#a-model-and-hypotheses"><i class="fa fa-check"></i><b>10.2</b> A model and hypotheses</a></li>
<li class="chapter" data-level="10.3" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#a-test-statistic-1"><i class="fa fa-check"></i><b>10.3</b> A test statistic</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#the-formula-for-the-expected-counts"><i class="fa fa-check"></i><b>10.3.1</b> The formula for the expected counts</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#computing-the-test-statistic-for-the-observed-data"><i class="fa fa-check"></i><b>10.4</b> Computing the test statistic for the observed data</a></li>
<li class="chapter" data-level="10.5" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#a-simulation-method-1"><i class="fa fa-check"></i><b>10.5</b> A simulation method</a></li>
<li class="chapter" data-level="10.6" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#an-analytical-method-1"><i class="fa fa-check"></i><b>10.6</b> An analytical method</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#chi2-tests-in-r"><i class="fa fa-check"></i><b>10.6.1</b> <span class="math inline">\(\chi^2\)</span> tests in R</a></li>
<li class="chapter" data-level="10.6.2" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#row-homogeneity-and-independence"><i class="fa fa-check"></i><b>10.6.2</b> Row homogeneity and independence</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#exercise"><i class="fa fa-check"></i><b>10.7</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="index-of-definitions-and-examples.html"><a href="index-of-definitions-and-examples.html"><i class="fa fa-check"></i><b>11</b> Index of definitions and examples</a>
<ul>
<li class="chapter" data-level="11.1" data-path="index-of-definitions-and-examples.html"><a href="index-of-definitions-and-examples.html#definitions"><i class="fa fa-check"></i><b>11.1</b> Definitions</a></li>
<li class="chapter" data-level="11.2" data-path="index-of-definitions-and-examples.html"><a href="index-of-definitions-and-examples.html#examples-1"><i class="fa fa-check"></i><b>11.2</b> Examples</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MAS109 - An Introduction to Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hypothesis-testing-a-level-recap" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">Chapter 6</span> Hypothesis testing: A-level recap<a href="hypothesis-testing-a-level-recap.html#hypothesis-testing-a-level-recap" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>This chapter recaps the basic ideas in hypothesis testing that are covered at A-level (though we will <em>not</em> assume that you have studied hypothesis testing before). In the next few chapters we will cover some further hypothesis testing problems, as well as studying a general simulation approach, which will give you more insight into how hypothesis testing works.</p>
<p>In a hypothesis test, we make some assumption (the “hypothesis”) about the distribution of the data, typically specifying the values of the parameters of the distribution, and then test whether the data ‘contradict’ this assumption.</p>
<p>There are two general approaches to hypothesis testing, which are very similar, but differ in how the conclusions are reported. We will refer to these as Neyman-Pearson testing, and Fisher’s p-value method<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>.</p>
<div id="hypothesis-testing-with-the-neyman-pearson-approach" class="section level2 hasAnchor" number="6.1">
<h2><span class="header-section-number">6.1</span> Hypothesis testing with the Neyman-Pearson approach<a href="hypothesis-testing-a-level-recap.html#hypothesis-testing-with-the-neyman-pearson-approach" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Suppose a company is developing a vegetarian substitute for minced beef, and is aiming for a product which is indistinguishable from meat. The substitute is to be tested in an experiment. Fifty volunteers will be each be given two portions of lasagna: one made with beef, and one with the vegetarian substitute, and asked to identify which lasagna is meat-free. The company will analyse the results of the experiment with a hypothesis test, and will make a decision about whether to continue with their product based on the results.</p>
<p>This is a scenario in which Neyman-Pearson testing could be used. The general procedure is as follows.</p>
<ol style="list-style-type: decimal">
<li><strong>Choose an appropriate statistical model and hypotheses</strong></li>
</ol>
<p>Define <span class="math inline">\(X\)</span> to be the number of people who correctly identify the meat-free lasagna. We might suppose that
<span class="math display">\[
X\sim Bin(50, \theta)
\]</span>
If the substitute is indistinguishable from minced beef, the volunteers would, in effect, be guessing with a probability of 0.5 of guessing correctly. Suitable null and alternative hypotheses would then be
<span class="math display">\[\begin{align}
H_0 &amp;: \theta = 0.5 \quad \mbox{(null hypothesis),}\\
H_A &amp;: \theta \neq 0.5\quad \mbox{(two-sided alternative hypothesis).}
\end{align}\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Choose the size or significance level of the test</strong></li>
</ol>
<p>When stating the conclusion of the test, we will either state we “reject <span class="math inline">\(H_0\)</span>” (conclude that <span class="math inline">\(H_0\)</span> is false), or we “do not reject <span class="math inline">\(H_0\)</span>” (and then carry on as if <span class="math inline">\(H_0\)</span> is true). There are two ways, therefore, in which we could make the wrong conclusion. These are referred to as type I and type II errors.</p>
<hr>
<div class="definition">
<p><span id="def:defTypeIerror" class="definition"><strong>Definition 6.1  (Type I error) </strong></span>A Type I error is the mistake of <em>rejecting</em> the null hypothesis when the null hypothesis is actually <em>true</em>.</p>
</div>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-127"></span>
<img src="images/type_1_errors.png" alt="A type I error: falsely rejecting \(H_0\). We think we have discovered something ‘interesting’ in our data, but have been deceived by random variation. Artwork by @allison_horst." width="80%" />
<p class="caption">
Figure 6.1: A type I error: falsely rejecting <span class="math inline">\(H_0\)</span>. We think we have discovered something ‘interesting’ in our data, but have been deceived by random variation. Artwork by @allison_horst.
</p>
</div>
<hr>
<div class="definition">
<p><span id="def:defTypeIIerror" class="definition"><strong>Definition 6.2  (Type II error) </strong></span>A Type II error is the mistake of <em>failing to reject</em> the null hypothesis when the null hypothesis is actually <em>false</em>.</p>
</div>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-128"></span>
<img src="images/type_2_errors.png" alt="A type II error: failing to reject \(H_0\) when \(H_0\) is really false. Here, random variation has hidden a potentially interesting discovery. This can result from having too small a sample size. Artwork by @allison_horst." width="80%" />
<p class="caption">
Figure 6.2: A type II error: failing to reject <span class="math inline">\(H_0\)</span> when <span class="math inline">\(H_0\)</span> is really false. Here, random variation has hidden a potentially interesting discovery. This can result from having too small a sample size. Artwork by @allison_horst.
</p>
</div>
<hr>
<div class="definition">
<p><span id="def:defSize" class="definition"><strong>Definition 6.3  (Size / level of significance) </strong></span>The size of a test is the probability, before we get our data, that we would make a Type I error. The size of a test is also known as the level of significance. The size/level of significance is often denoted by <span class="math inline">\(\alpha\)</span>.</p>
</div>
<hr>
<p>In Neyman-Pearson testing we choose, in advance, the size of test. A common choice of size/significance level is 5%, so the probability of a Type I error would be 0.05. Why not choose 0%, so that a Type I error is impossible? The only way to make Type I errors <em>impossible</em> is to refuse ever to reject the null hypothesis, but this then <em>increases</em> the risk of a Type II error; we have to trade off risks of the two error types. Choosing a small value such as 5% is a compromise.</p>
<ol start="3" style="list-style-type: decimal">
<li><strong>Choose a test statistic</strong></li>
</ol>
<div class="rmdnote">
<p>
A test statistic measures ‘how different’ the data are from what we
would expect under <span class="math inline"><span class="math inline">\(H_0\)</span></span>.
</p>
</div>
<p>In our example, we use the test statistic
<span class="math display">\[\begin{equation}
Z = \frac{\frac{X}{n} - \theta_0}{\sqrt{\theta_0(1-\theta_0)/n}},
\end{equation}\]</span>
with <span class="math inline">\(n\)</span> the sample size, and <span class="math inline">\(\theta_0\)</span> the hypothesised values of <span class="math inline">\(\theta\)</span> under <span class="math inline">\(H_0\)</span> (so in the example, we have <span class="math inline">\(n=50\)</span> and <span class="math inline">\(\theta_0=0.5\)</span>). This measures how far the observed proportion of correct responses is from <span class="math inline">\(\theta_0\)</span> (the proportion we’d expect if <span class="math inline">\(H_0\)</span> were true), scaled by the standard deviation of <span class="math inline">\(X/n\)</span> (again, if <span class="math inline">\(H_0\)</span> were true).</p>
<div class="rmdnote">
<p>
We’d expect (the absolute value of) a test statistic to be small if
<span class="math inline"><span class="math inline">\(H_0\)</span></span> is true, and to be relatively
large if <span class="math inline"><span class="math inline">\(H_A\)</span></span> is true.
</p>
</div>
<ol start="4" style="list-style-type: decimal">
<li><strong>Identify the critical region</strong></li>
</ol>
<p>We now find a critical region <span class="math inline">\(C\)</span> such that</p>
<ul>
<li>a value of <span class="math inline">\(Z\)</span> in the critical region would correspond to a large difference between <span class="math inline">\(X/n\)</span> and <span class="math inline">\(\theta_0\)</span>;</li>
<li>the probability of <span class="math inline">\(Z\)</span> falling in the critical region, if <span class="math inline">\(H_0\)</span> were true, would be 0.05 (the size/significance level).</li>
</ul>
<p>Using the normal approximation to the binomial distribution, we suppose that <span class="math inline">\(Z\sim N(0,1)\)</span> and so the critical region is <span class="math inline">\((-\infty, -1.96] \cup [1.96, \infty)\)</span></p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-131"></span>
<img src="MAS109-Data-Science_files/figure-html/unnamed-chunk-131-1.png" alt="The distribution of the test statistic assuming \(H_0\) is true, and the 5% critical region shaded in green. There is only a 5% chance of the test statistic falling in this region if \(H_0\) is true: we will reject \(H_0\) if the test statistic falls in this region." width="864" />
<p class="caption">
Figure 6.3: The distribution of the test statistic assuming <span class="math inline">\(H_0\)</span> is true, and the 5% critical region shaded in green. There is only a 5% chance of the test statistic falling in this region if <span class="math inline">\(H_0\)</span> is true: we will reject <span class="math inline">\(H_0\)</span> if the test statistic falls in this region.
</p>
</div>
<ol start="5" style="list-style-type: decimal">
<li><strong>Compute the test statistic for the observed data, and state the conclusion</strong></li>
</ol>
<p>If the observed value of <span class="math inline">\(Z\)</span> falls in the critical region, we declare that we reject <span class="math inline">\(H_0\)</span> (at the 5% level of significance); otherwise, we declare that we do not reject <span class="math inline">\(H_0\)</span>. For example, if 40 out of 50 people correctly identified the meat-free lasagna, the observed test statistic, denoted by <span class="math inline">\(z_{obs}\)</span> would be
<span class="math display">\[
z_{obs} = \frac{\frac{40}{50}-0.5}{\sqrt{0.5\times(1 - 0.5) / 50}} = 4.24,
\]</span>
which does lie in the critical region, so <span class="math inline">\(H_0\)</span> would be rejected. The company may then decide that their substitute hasn’t achieved the taste they want, and they may try something else.</p>
<div id="one-sided-and-two-sided-alternative-hypotheses" class="section level3 hasAnchor" number="6.1.1">
<h3><span class="header-section-number">6.1.1</span> One-sided and two-sided alternative hypotheses<a href="hypothesis-testing-a-level-recap.html#one-sided-and-two-sided-alternative-hypotheses" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We used an alternative hypothesis</p>
<p><span class="math display">\[
H_A: \theta \neq 0.5.
\]</span>
This is <strong>two-sided</strong> because we would want to reject <span class="math inline">\(H_0:\theta = 0.5\)</span> if either <span class="math inline">\(\theta &gt; 0.5\)</span> or <span class="math inline">\(\theta&lt;0.5\)</span>. <strong>One-sided</strong> alternative hypotheses would be
<span class="math display">\[
H_A: \theta &gt; 0.5,
\]</span>
or
<span class="math display">\[
H_A: \theta &lt; 0.5.
\]</span>
In some situations, it may appear that a one-sided alternative hypothesis is more suitable, e.g. <span class="math inline">\(H_0:\)</span> “the drug has no effect on blood pressure, on average” and <span class="math inline">\(H_A:\)</span> “the drug lowers blood pressure, on average” (if the aim of the drug was to lower blood pressure). However, there is an argument in this situation for <strong>always using a two-sided alternative</strong>.</p>
<ul>
<li><p>If the drug had the opposite effect to that desired, we would still want to know.</p></li>
<li><p>Using a one-sided alternative makes the critical region larger in the area of interest; <span class="math inline">\(H_0\)</span> can be rejected with a smaller observed effect of the drug.</p></li>
</ul>
</div>
</div>
<div id="fishers-p-value-method" class="section level2 hasAnchor" number="6.2">
<h2><span class="header-section-number">6.2</span> Fisher’s <span class="math inline">\(p\)</span>-value method<a href="hypothesis-testing-a-level-recap.html#fishers-p-value-method" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the Neyman-Pearson approach to hypothesis testing, the conclusion is stated in terms of “reject <span class="math inline">\(H_0\)</span>”, or “do not reject <span class="math inline">\(H_0\)</span>”. We would use this where there is a clear <strong>decision</strong> to be made after the test.
Sometimes, however, we are just interested in whether data supports a particular hypothesis or not; there is no decision or action that follows the test.</p>
<div class="rmdnote">
<p>
A hypothesis test can not <strong>prove</strong> whether a hypothesis
or not. Rather than declaring whether a hypothesis been “rejected”, it
might be preferable instead to report the strength of evidence provided
by an experiment.
</p>
</div>
<p>Consider again the example of the vegetarian minced-beef substitute. Suppose the product is already on the market, and a consumer TV show does the same experiment to see if people if can taste the difference. There is no ‘decision’ to be made afterwards; the experiment is done out of public interest.</p>
<p>We have the same model and hypotheses as before. Defining <span class="math inline">\(X\)</span> to be the number of people (out of 50) correctly identifying the vegetarian substitute, we suppose <span class="math inline">\(X\sim Bin(50, \theta)\)</span>, with</p>
<p><span class="math display">\[\begin{align}
H_0 &amp;: \theta = 0.5,\\
H_A &amp;: \theta \neq 0.5,
\end{align}\]</span>
so that under <span class="math inline">\(H_0\)</span>, people are just guessing. Now consider three scenarios:</p>
<table>
<thead>
<tr class="header">
<th align="center">Scenario</th>
<th align="center">Data</th>
<th align="center">Test Statistic</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">A</td>
<td align="center">32 people out of 50 guess correctly</td>
<td align="center">2.06</td>
</tr>
<tr class="even">
<td align="center">B</td>
<td align="center">31 people out of 50 guess correctly</td>
<td align="center">1.75</td>
</tr>
<tr class="odd">
<td align="center">C</td>
<td align="center">40 people out of 50 guess correctly</td>
<td align="center">5.30</td>
</tr>
</tbody>
</table>
<p>If we were using Neyman-Pearson with a test of size 0.05, the critical region for the test statistic would be <span class="math inline">\((-\infty, -1.96]\cup [1.96, \infty)\)</span>; the test statistics would lie in the 5% critical region in scenarios A and C, but not in scenario B.</p>
<ul>
<li>Comparing scenarios A and B, the results were the nearly the same: only one more person correctly identified the meat substitute in scenario A. Should we really be drawing different conclusions in these two scenarios?</li>
<li>Comparing scenarios A and C, the evidence seems more persuasive in scenario C. Shouldn’t we report this somehow?</li>
</ul>
<p>In Fisher’s <span class="math inline">\(p\)</span>-value method, instead of declaring whether <span class="math inline">\(H_0\)</span> is reject or not, we describe <strong>the strength of the evidence against <span class="math inline">\(H_0\)</span></strong>, by reporting the <strong><span class="math inline">\(p\)</span>-value</strong>.</p>
<div class="rmdnote">
<p>
The <span class="math inline"><span class="math inline">\(p\)</span></span>-value is a probability
and, informally, describes how ‘surprising’ the observed data are,
assuming <span class="math inline"><span class="math inline">\(H_0\)</span></span> to be true.
</p>
<ul>
<li>
If the <span class="math inline"><span class="math inline">\(p\)</span></span>-value is small, it
means the data are not what we would expect to see under <span class="math inline"><span class="math inline">\(H_0\)</span></span>. The smaller the <span class="math inline"><span class="math inline">\(p\)</span></span>-value, the stronger the evidence
<em>against</em> <span class="math inline"><span class="math inline">\(H_0\)</span></span>.
</li>
<li>
If the <span class="math inline"><span class="math inline">\(p\)</span></span>-value is large, the
data are consistent with what we’d expect under <span class="math inline"><span class="math inline">\(H_0\)</span></span> (but this is not the same as saying
we have evidence <em>in favour</em> of <span class="math inline"><span class="math inline">\(H_0\)</span></span> being true).
</li>
</ul>
</div>
<hr>
<div class="definition">
<p><span id="def:defpValue" class="definition"><strong>Definition 6.4  (p-value) </strong></span>For a test statistic <span class="math inline">\(T\)</span>, with observed value <span class="math inline">\(t_{obs}\)</span> and a two-sided alternative hypothesis, we define the <span class="math inline">\(p\)</span>-value as
<span class="math display">\[\begin{equation}
P(|T|\ge |t_{obs}|),
\end{equation}\]</span>
calculated for the distribution of <span class="math inline">\(T\)</span> under <span class="math inline">\(H_0\)</span>.</p>
</div>
<hr>
<p>Continuing the example, our test statistic is denoted by <span class="math inline">\(Z\)</span>, assumed to have a <span class="math inline">\(N(0,1)\)</span> distribution if <span class="math inline">\(H_0\)</span> is true. The <span class="math inline">\(p\)</span>-values in the three scenarios would be:</p>
<p><span class="math display">\[\begin{align*}
\mbox {Scenario A:}&amp;\quad P(Z\le -2.06) + P(Z\ge 2.06) \simeq 0.04,\\
\mbox {Scenario B:}&amp;\quad P(Z\le -1.75) + P(Z\ge 1.75) \simeq 0.08,\\
\mbox {Scenario C:}&amp;\quad P(Z\le -5.30) + P(Z\ge 5.30) \simeq 1.2\times 10^{-7}.\\
\end{align*}\]</span></p>
<p>Note that the <span class="math inline">\(p\)</span>-value is much smaller in Scenario C than in A: the evidence against <span class="math inline">\(H_0\)</span> is stronger.</p>
<p>We obtain the numerical probabilities using R, noting that for <span class="math inline">\(Z\sim N(0,1)\)</span>, we have <span class="math inline">\(P(Z\le -x) + P(Z\ge x) = 2P(Z\le -x)\)</span>. For example</p>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="hypothesis-testing-a-level-recap.html#cb141-1" tabindex="-1"></a><span class="dv">2</span> <span class="sc">*</span> <span class="fu">pnorm</span>(<span class="sc">-</span><span class="fl">2.06</span>)</span></code></pre></div>
<pre><code>## [1] 0.0394</code></pre>
<p>The <span class="math inline">\(p\)</span>-value is much smaller in Scenario C, compared with A, and so we can say that the evidence against <span class="math inline">\(H_0\)</span> is much stronger in Scenario C. We visualise the <span class="math inline">\(p\)</span>-value in Scenario A below.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-136"></span>
<img src="MAS109-Data-Science_files/figure-html/unnamed-chunk-136-1.png" alt="The observed test statistic was 2.06. Is this a suprising value of $Z$ under $H_0$? We report how surprising this value is in terms of how likely we are to get an (absolute) value as large as 2.06, assuming $H_0$ to be true. This is the $p$-value, and is represented by the red shaded area." width="864" />
<p class="caption">
Figure 6.4: The observed test statistic was 2.06. Is this a suprising value of <span class="math inline">\(Z\)</span> under <span class="math inline">\(H_0\)</span>? We report how surprising this value is in terms of how likely we are to get an (absolute) value as large as 2.06, assuming <span class="math inline">\(H_0\)</span> to be true. This is the <span class="math inline">\(p\)</span>-value, and is represented by the red shaded area.
</p>
</div>
<div id="what-counts-as-a-small-p-value" class="section level3 hasAnchor" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> What counts as a small <span class="math inline">\(p\)</span>-value?<a href="hypothesis-testing-a-level-recap.html#what-counts-as-a-small-p-value" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>This varies between scientific fields. In medical research, a <span class="math inline">\(p\)</span>-value of 0.05 or smaller would typically count as ‘significant’ evidence against the null hypothesis. If a scientist wants to claim a new discovery, and publish the results of his/her experiment in an academic journal, some journals will require a <span class="math inline">\(p\)</span>-value less than 0.05 for the article to be published, although one journal banned this practice<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>. Particle physicists are rather more demanding! They require a <span class="math inline">\(p\)</span>-value smaller than 0.003 for “evidence of a particle”, and smaller than 0.0000003 for a “discovery”<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>.</p>
<p><strong>For this module</strong> we will use the following convention</p>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(p\)</span>-value</th>
<th>Interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(p &gt; 0.05\)</span></td>
<td>No evidence against <span class="math inline">\(H_0\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(0.05 \ge p &gt; 0.01\)</span></td>
<td>Weak evidence against <span class="math inline">\(H_0\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(0.01 \ge p &gt; 0.001\)</span></td>
<td>Strong evidence against <span class="math inline">\(H_0\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(0.001 \ge p\)</span></td>
<td>Very strong evidence against <span class="math inline">\(H_0\)</span></td>
</tr>
</tbody>
</table>
<p>In particular, for <span class="math inline">\(p\)</span>-values just below 0.05, a recommendation would be to repeat the experiment to look for confirmation.</p>
</div>
</div>
<div id="relationship-between-the-neyman-pearson-and-p-value-methods" class="section level2 hasAnchor" number="6.3">
<h2><span class="header-section-number">6.3</span> Relationship between the Neyman-Pearson and <span class="math inline">\(p\)</span>-value methods<a href="hypothesis-testing-a-level-recap.html#relationship-between-the-neyman-pearson-and-p-value-methods" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Note that if the <span class="math inline">\(p\)</span>-value is less than 0.05, we can deduce that the test statistic must lie in the 5% critical region. Hence some people use a combination of both methods, and say things like, “The <span class="math inline">\(p\)</span>-value is less than 0.05, so we have statistically significant evidence against <span class="math inline">\(H_0\)</span> at the 5% level.” Reporting the <span class="math inline">\(p\)</span>-value gives a little more information: we are saying how strong the evidence is against <span class="math inline">\(H_0\)</span>, and not simply whether <span class="math inline">\(H_0\)</span> is rejected or not. We illustrate this in Figure <a href="hypothesis-testing-a-level-recap.html#fig:NPpVal">6.5</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:NPpVal"></span>
<img src="MAS109-Data-Science_files/figure-html/NPpVal-1.png" alt="Suppose our observed test statistic was 1.41, as shown by the blue cross. For the Neyman-Pearson method, with a test of size 0.05, we determine the critical region which has a 5% chance of containing the test statistic \(T\), assuming \(H_0\) is true. This is shown as the green shaded area; this area is 0.05. For the \(p\)-value method, we calculate the probability that \(T\) would be as or more extreme as our observed test statistic \(t_{obs}\), assuming \(H_0\) is true. This is shown as the red shaded area. If the \(p\)-value (red shaded area) is greater than 0.05, we can deduce that the test statistic \(t_{obs}\) cannot lie in the 5% critical region." width="768" />
<p class="caption">
Figure 6.5: Suppose our observed test statistic was 1.41, as shown by the blue cross. For the Neyman-Pearson method, with a test of size 0.05, we determine the critical region which has a 5% chance of containing the test statistic <span class="math inline">\(T\)</span>, assuming <span class="math inline">\(H_0\)</span> is true. This is shown as the green shaded area; this area is 0.05. For the <span class="math inline">\(p\)</span>-value method, we calculate the probability that <span class="math inline">\(T\)</span> would be as or more extreme as our observed test statistic <span class="math inline">\(t_{obs}\)</span>, assuming <span class="math inline">\(H_0\)</span> is true. This is shown as the red shaded area. If the <span class="math inline">\(p\)</span>-value (red shaded area) is greater than 0.05, we can deduce that the test statistic <span class="math inline">\(t_{obs}\)</span> cannot lie in the 5% critical region.
</p>
</div>
</div>
<div id="which-hypothesis-test-do-i-use-for" class="section level2 hasAnchor" number="6.4">
<h2><span class="header-section-number">6.4</span> Which hypothesis test do I use for…?<a href="hypothesis-testing-a-level-recap.html#which-hypothesis-test-do-i-use-for" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>There are a large number of hypothesis tests covering a range of situations. Over the next few chapters we will consider three (studying more than this would be tedious!):</p>
<ol style="list-style-type: decimal">
<li>comparing two means;</li>
<li>comparing two proportions;</li>
<li>analysing contingency table data.</li>
</ol>
<p>You will see that the general approach is the same in each case. All that change are</p>
<ul>
<li>the test statistic that is computed;</li>
<li>the distribution of the test statistic under the null hypothesis.</li>
</ul>
<p>Once you have understood how things work in general, you should be confident in tackling any hypothesis testing problem: search for the problem online (or in a textbook), identify the choice of test statistic and its distribution under <span class="math inline">\(H_0\)</span>, and then you should find the implementation straightforward.</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="3">
<li id="fn3"><p>devised by the statisticians <a href="https://en.wikipedia.org/wiki/Jerzy_Neyman">Jerzy Neyman</a> (1894-1981), <a href="https://en.wikipedia.org/wiki/Egon_Pearson">Egon Pearson</a> (1895-1980) and <a href="https://en.wikipedia.org/wiki/Ronald_Fisher">Sir Ronald Fisher</a> (1890-1962).<a href="hypothesis-testing-a-level-recap.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p><a href="https://www.statslife.org.uk/news/2116-academic-journal-bans-p-value-significance-test">https://www.statslife.org.uk/news/2116-academic-journal-bans-p-value-significance-test</a><a href="hypothesis-testing-a-level-recap.html#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p><a href="https://blogs.scientificamerican.com/observations/five-sigmawhats-that/">https://blogs.scientificamerican.com/observations/five-sigmawhats-that/</a><a href="hypothesis-testing-a-level-recap.html#fnref5" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="interval-estimates-and-confidence-intervals.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="hypothesis-testing-comparing-two-population-means.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
