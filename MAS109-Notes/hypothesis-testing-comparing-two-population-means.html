<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Hypothesis testing: comparing two population means | MAS109 - An Introduction to Data Science</title>
  <meta name="description" content="Lecture notes for MAS109" />
  <meta name="generator" content="bookdown 0.42 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Hypothesis testing: comparing two population means | MAS109 - An Introduction to Data Science" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Lecture notes for MAS109" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Hypothesis testing: comparing two population means | MAS109 - An Introduction to Data Science" />
  
  <meta name="twitter:description" content="Lecture notes for MAS109" />
  

<meta name="author" content="Dr Jill Johnson" />


<meta name="date" content="2025-02-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="hypothesis-testing-a-level-recap.html"/>
<link rel="next" href="hypothesis-testing-comparing-two-proportions.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">MAS109 - Introduction to Data Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About these notes</a></li>
<li class="chapter" data-level="1" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html"><i class="fa fa-check"></i><b>1</b> Exploratory Data Analysis using R</a>
<ul>
<li class="chapter" data-level="1.1" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#case-study-what-makes-a-country-good-at-maths"><i class="fa fa-check"></i><b>1.1</b> Case study: what makes a country good at maths?</a></li>
<li class="chapter" data-level="1.2" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#the-tidyverse"><i class="fa fa-check"></i><b>1.2</b> The “Tidyverse”</a></li>
<li class="chapter" data-level="1.3" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#importing-data-into-r-csv-and-.xlsx-files"><i class="fa fa-check"></i><b>1.3</b> Importing data into R: <code>csv</code> and <code>.xlsx</code> files</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#importing-excel-.xlsx-files"><i class="fa fa-check"></i><b>1.3.1</b> Importing Excel <code>.xlsx</code> files</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#data-frames-and-tibbles-in-r"><i class="fa fa-check"></i><b>1.4</b> Data frames and tibbles in R</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#ordering-the-rows-by-a-variable-with-the-arrange-command"><i class="fa fa-check"></i><b>1.4.1</b> Ordering the rows by a variable with the <code>arrange()</code> command</a></li>
<li class="chapter" data-level="1.4.2" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#selecting-rows-with-the-filter-command"><i class="fa fa-check"></i><b>1.4.2</b> Selecting rows with the <code>filter()</code> command</a></li>
<li class="chapter" data-level="1.4.3" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#viewing-and-extracting-data-from-a-column"><i class="fa fa-check"></i><b>1.4.3</b> Viewing and extracting data from a column</a></li>
<li class="chapter" data-level="1.4.4" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#creating-new-columns-in-a-data-frame-with-the-mutate-command"><i class="fa fa-check"></i><b>1.4.4</b> Creating new columns in a data frame with the <code>mutate()</code> command</a></li>
<li class="chapter" data-level="1.4.5" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#chaining-commands-together-with-the-pipe-operator"><i class="fa fa-check"></i><b>1.4.5</b> Chaining commands together with the pipe operator <code>%&gt;%</code></a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#calculating-summary-statistics-with-the-summary-command"><i class="fa fa-check"></i><b>1.5</b> Calculating summary statistics with the <code>summary()</code> command</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#calculating-individual-summary-statistics"><i class="fa fa-check"></i><b>1.5.1</b> Calculating individual summary statistics</a></li>
<li class="chapter" data-level="1.5.2" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#calculating-other-quantilespercentiles"><i class="fa fa-check"></i><b>1.5.2</b> Calculating other quantiles/percentiles</a></li>
<li class="chapter" data-level="1.5.3" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#computing-summaries-per-group"><i class="fa fa-check"></i><b>1.5.3</b> Computing summaries per group</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#plotting-a-distribution-using-a-histogram"><i class="fa fa-check"></i><b>1.6</b> Plotting a distribution using a histogram</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#describing-the-shape-of-a-distribution-skewness"><i class="fa fa-check"></i><b>1.6.1</b> Describing the shape of a distribution: skewness</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#introducing-ggplot2"><i class="fa fa-check"></i><b>1.7</b> Introducing <code>ggplot2</code></a></li>
<li class="chapter" data-level="1.8" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#drawing-a-histogram-in-r"><i class="fa fa-check"></i><b>1.8</b> Drawing a histogram in R</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#customising-a-histogram-plot-in-r"><i class="fa fa-check"></i><b>1.8.1</b> Customising a histogram plot in R</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#covariance-and-correlation"><i class="fa fa-check"></i><b>1.9</b> Covariance and correlation</a>
<ul>
<li class="chapter" data-level="1.9.1" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#calculating-a-covariance-in-r"><i class="fa fa-check"></i><b>1.9.1</b> Calculating a covariance in R</a></li>
<li class="chapter" data-level="1.9.2" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#pearsons-correlation-coefficient"><i class="fa fa-check"></i><b>1.9.2</b> Pearson’s correlation coefficient</a></li>
<li class="chapter" data-level="1.9.3" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#calculating-pearsons-correlation-coefficient-in-r"><i class="fa fa-check"></i><b>1.9.3</b> Calculating Pearson’s correlation coefficient in R</a></li>
<li class="chapter" data-level="1.9.4" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#spearmans-correlation-coefficient"><i class="fa fa-check"></i><b>1.9.4</b> Spearman’s correlation coefficient</a></li>
<li class="chapter" data-level="1.9.5" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#calculating-spearmans-correlation-coefficient-in-r"><i class="fa fa-check"></i><b>1.9.5</b> Calculating Spearman’s correlation coefficient in R</a></li>
<li class="chapter" data-level="1.9.6" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#interpreting-correlation-coefficients"><i class="fa fa-check"></i><b>1.9.6</b> Interpreting correlation coefficients</a></li>
<li class="chapter" data-level="1.9.7" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#correlations-for-the-maths-data-set"><i class="fa fa-check"></i><b>1.9.7</b> Correlations for the <code>maths</code> data set</a></li>
</ul></li>
<li class="chapter" data-level="1.10" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#drawing-a-scatter-plot-in-r"><i class="fa fa-check"></i><b>1.10</b> Drawing a scatter plot in R</a>
<ul>
<li class="chapter" data-level="1.10.1" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#customising-a-scatter-plot-in-r"><i class="fa fa-check"></i><b>1.10.1</b> Customising a scatter plot in R</a></li>
<li class="chapter" data-level="1.10.2" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#adding-a-nonlinear-trend-to-a-scatter-plot-in-r"><i class="fa fa-check"></i><b>1.10.2</b> Adding a nonlinear trend to a scatter plot in R</a></li>
<li class="chapter" data-level="1.10.3" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#adding-a-linear-trend-to-a-scatter-plot-in-r"><i class="fa fa-check"></i><b>1.10.3</b> Adding a linear trend to a scatter plot in R</a></li>
</ul></li>
<li class="chapter" data-level="1.11" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#box-plots"><i class="fa fa-check"></i><b>1.11</b> Box plots</a></li>
<li class="chapter" data-level="1.12" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#scatter-plots-to-represent-three-variables"><i class="fa fa-check"></i><b>1.12</b> Scatter plots to represent three variables</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="machine-learning.html"><a href="machine-learning.html"><i class="fa fa-check"></i><b>2</b> Machine Learning</a>
<ul>
<li class="chapter" data-level="2.1" data-path="machine-learning.html"><a href="machine-learning.html#can-we-teach-a-computer-to-identify-handwritten-digits"><i class="fa fa-check"></i><b>2.1</b> Can we teach a computer to identify handwritten digits?</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="machine-learning.html"><a href="machine-learning.html#step-1-converting-an-image-into-data"><i class="fa fa-check"></i><b>2.1.1</b> Step 1: converting an image into data</a></li>
<li class="chapter" data-level="2.1.2" data-path="machine-learning.html"><a href="machine-learning.html#step-2-assembling-the-training-data-set"><i class="fa fa-check"></i><b>2.1.2</b> Step 2: assembling the training data set</a></li>
<li class="chapter" data-level="2.1.3" data-path="machine-learning.html"><a href="machine-learning.html#step-3-an-algorithm-for-estimating-the-digit-in-a-new-image"><i class="fa fa-check"></i><b>2.1.3</b> Step 3: an algorithm for estimating the digit in a new image</a></li>
<li class="chapter" data-level="2.1.4" data-path="machine-learning.html"><a href="machine-learning.html#the-k-nearest-neighbour-algorithm-knn"><i class="fa fa-check"></i><b>2.1.4</b> The <span class="math inline">\(K\)</span> nearest neighbour algorithm (KNN)</a></li>
<li class="chapter" data-level="2.1.5" data-path="machine-learning.html"><a href="machine-learning.html#using-k-nearest-neighbours-in-r"><i class="fa fa-check"></i><b>2.1.5</b> Using <span class="math inline">\(K\)</span> nearest neighbours in R</a></li>
<li class="chapter" data-level="2.1.6" data-path="machine-learning.html"><a href="machine-learning.html#the-performance-of-the-algorithm"><i class="fa fa-check"></i><b>2.1.6</b> The performance of the algorithm</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="populations-samples-and-statistical-models.html"><a href="populations-samples-and-statistical-models.html"><i class="fa fa-check"></i><b>3</b> Populations, samples and statistical models</a>
<ul>
<li class="chapter" data-level="3.1" data-path="populations-samples-and-statistical-models.html"><a href="populations-samples-and-statistical-models.html#statistical-models"><i class="fa fa-check"></i><b>3.1</b> Statistical models</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="populations-samples-and-statistical-models.html"><a href="populations-samples-and-statistical-models.html#objectives"><i class="fa fa-check"></i><b>3.1.1</b> Objectives</a></li>
<li class="chapter" data-level="3.1.2" data-path="populations-samples-and-statistical-models.html"><a href="populations-samples-and-statistical-models.html#comment-infinite-and-finite-populations"><i class="fa fa-check"></i><b>3.1.2</b> Comment: infinite and finite populations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="point-estimation.html"><a href="point-estimation.html"><i class="fa fa-check"></i><b>4</b> Point estimation</a>
<ul>
<li class="chapter" data-level="4.1" data-path="point-estimation.html"><a href="point-estimation.html#estimating-the-parameters-of-a-normal-distribution"><i class="fa fa-check"></i><b>4.1</b> Estimating the parameters of a normal distribution</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="point-estimation.html"><a href="point-estimation.html#problem-setup-and-notation"><i class="fa fa-check"></i><b>4.1.1</b> Problem setup and notation</a></li>
<li class="chapter" data-level="4.1.2" data-path="point-estimation.html"><a href="point-estimation.html#the-sample-mean-and-sample-variance"><i class="fa fa-check"></i><b>4.1.2</b> The sample mean and sample variance</a></li>
<li class="chapter" data-level="4.1.3" data-path="point-estimation.html"><a href="point-estimation.html#point-estimates-for-the-mean-and-variance"><i class="fa fa-check"></i><b>4.1.3</b> Point estimates for the mean and variance</a></li>
<li class="chapter" data-level="4.1.4" data-path="point-estimation.html"><a href="point-estimation.html#testing-the-method"><i class="fa fa-check"></i><b>4.1.4</b> Testing the method</a></li>
<li class="chapter" data-level="4.1.5" data-path="point-estimation.html"><a href="point-estimation.html#estimators-and-estimates"><i class="fa fa-check"></i><b>4.1.5</b> Estimators and estimates</a></li>
<li class="chapter" data-level="4.1.6" data-path="point-estimation.html"><a href="point-estimation.html#the-chi2-distribution"><i class="fa fa-check"></i><b>4.1.6</b> The <span class="math inline">\(\chi^2\)</span> distribution</a></li>
<li class="chapter" data-level="4.1.7" data-path="point-estimation.html"><a href="point-estimation.html#the-distribution-of-the-estimators"><i class="fa fa-check"></i><b>4.1.7</b> The distribution of the estimators</a></li>
<li class="chapter" data-level="4.1.8" data-path="point-estimation.html"><a href="point-estimation.html#unbiased-estimators"><i class="fa fa-check"></i><b>4.1.8</b> Unbiased estimators</a></li>
<li class="chapter" data-level="4.1.9" data-path="point-estimation.html"><a href="point-estimation.html#the-standard-error-of-an-estimator"><i class="fa fa-check"></i><b>4.1.9</b> The standard error of an estimator</a></li>
<li class="chapter" data-level="4.1.10" data-path="point-estimation.html"><a href="point-estimation.html#consistent-estimators"><i class="fa fa-check"></i><b>4.1.10</b> Consistent estimators</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="point-estimation.html"><a href="point-estimation.html#estimating-the-probability-parameter-in-a-binomial-distribution"><i class="fa fa-check"></i><b>4.2</b> Estimating the probability parameter in a Binomial distribution</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="interval-estimates-and-confidence-intervals.html"><a href="interval-estimates-and-confidence-intervals.html"><i class="fa fa-check"></i><b>5</b> Interval estimates and confidence intervals</a>
<ul>
<li class="chapter" data-level="5.1" data-path="interval-estimates-and-confidence-intervals.html"><a href="interval-estimates-and-confidence-intervals.html#the-student-t-distribution"><i class="fa fa-check"></i><b>5.1</b> The Student <span class="math inline">\(t\)</span> distribution</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="interval-estimates-and-confidence-intervals.html"><a href="interval-estimates-and-confidence-intervals.html#mean-and-variance-of-the-t-distribution"><i class="fa fa-check"></i><b>5.1.1</b> Mean and variance of the <span class="math inline">\(t\)</span>-distribution</a></li>
<li class="chapter" data-level="5.1.2" data-path="interval-estimates-and-confidence-intervals.html"><a href="interval-estimates-and-confidence-intervals.html#notation-quantilespercentiles-of-the-t-distribution"><i class="fa fa-check"></i><b>5.1.2</b> Notation: quantiles/percentiles of the <span class="math inline">\(t\)</span> distribution</a></li>
<li class="chapter" data-level="5.1.3" data-path="interval-estimates-and-confidence-intervals.html"><a href="interval-estimates-and-confidence-intervals.html#the-t-distribution-in-r."><i class="fa fa-check"></i><b>5.1.3</b> The <span class="math inline">\(t\)</span> distribution in R.</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="interval-estimates-and-confidence-intervals.html"><a href="interval-estimates-and-confidence-intervals.html#confidence-intervals-for-the-mean-and-the-variance-of-a-normal-distribution"><i class="fa fa-check"></i><b>5.2</b> Confidence intervals for the mean and the variance of a normal distribution</a></li>
<li class="chapter" data-level="5.3" data-path="interval-estimates-and-confidence-intervals.html"><a href="interval-estimates-and-confidence-intervals.html#confidence-interval-for-the-probability-parameter-in-a-binomial-distribution"><i class="fa fa-check"></i><b>5.3</b> Confidence interval for the probability parameter in a binomial distribution</a></li>
<li class="chapter" data-level="5.4" data-path="interval-estimates-and-confidence-intervals.html"><a href="interval-estimates-and-confidence-intervals.html#alpha-confidence-intervals"><i class="fa fa-check"></i><b>5.4</b> <span class="math inline">\(100(1-\alpha)\%\)</span> Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="hypothesis-testing-a-level-recap.html"><a href="hypothesis-testing-a-level-recap.html"><i class="fa fa-check"></i><b>6</b> Hypothesis testing: A-level recap</a>
<ul>
<li class="chapter" data-level="6.1" data-path="hypothesis-testing-a-level-recap.html"><a href="hypothesis-testing-a-level-recap.html#hypothesis-testing-with-the-neyman-pearson-approach"><i class="fa fa-check"></i><b>6.1</b> Hypothesis testing with the Neyman-Pearson approach</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="hypothesis-testing-a-level-recap.html"><a href="hypothesis-testing-a-level-recap.html#one-sided-and-two-sided-alternative-hypotheses"><i class="fa fa-check"></i><b>6.1.1</b> One-sided and two-sided alternative hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="hypothesis-testing-a-level-recap.html"><a href="hypothesis-testing-a-level-recap.html#fishers-p-value-method"><i class="fa fa-check"></i><b>6.2</b> Fisher’s <span class="math inline">\(p\)</span>-value method</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="hypothesis-testing-a-level-recap.html"><a href="hypothesis-testing-a-level-recap.html#what-counts-as-a-small-p-value"><i class="fa fa-check"></i><b>6.2.1</b> What counts as a small <span class="math inline">\(p\)</span>-value?</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="hypothesis-testing-a-level-recap.html"><a href="hypothesis-testing-a-level-recap.html#relationship-between-the-neyman-pearson-and-p-value-methods"><i class="fa fa-check"></i><b>6.3</b> Relationship between the Neyman-Pearson and <span class="math inline">\(p\)</span>-value methods</a></li>
<li class="chapter" data-level="6.4" data-path="hypothesis-testing-a-level-recap.html"><a href="hypothesis-testing-a-level-recap.html#which-hypothesis-test-do-i-use-for"><i class="fa fa-check"></i><b>6.4</b> Which hypothesis test do I use for…?</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html"><i class="fa fa-check"></i><b>7</b> Hypothesis testing: comparing two population means</a>
<ul>
<li class="chapter" data-level="7.1" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#example-can-imagining-eating-food-make-you-eat-less"><i class="fa fa-check"></i><b>7.1</b> Example: can imagining eating food make you eat less?</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#the-hypotheses"><i class="fa fa-check"></i><b>7.1.1</b> The hypotheses</a></li>
<li class="chapter" data-level="7.1.2" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#a-test-statistic"><i class="fa fa-check"></i><b>7.1.2</b> A test statistic</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#hypothesis-testing-using-simulation"><i class="fa fa-check"></i><b>7.2</b> Hypothesis testing using simulation</a></li>
<li class="chapter" data-level="7.3" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#the-two-sample-t-test"><i class="fa fa-check"></i><b>7.3</b> The two-sample <span class="math inline">\(t\)</span> test</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#the-two-sample-t-test-with-the-neyman-pearson-method"><i class="fa fa-check"></i><b>7.3.1</b> The two-sample <span class="math inline">\(t\)</span>-test with the Neyman-Pearson method</a></li>
<li class="chapter" data-level="7.3.2" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#an-illustrated-guide"><i class="fa fa-check"></i><b>7.3.2</b> An illustrated guide</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#confidence-interval-for-the-difference-between-two-means"><i class="fa fa-check"></i><b>7.4</b> Confidence interval for the difference between two means</a></li>
<li class="chapter" data-level="7.5" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#equivalence-of-confidence-intervals-and-neyman-pearson-testing"><i class="fa fa-check"></i><b>7.5</b> Equivalence of confidence intervals and Neyman-Pearson testing</a></li>
<li class="chapter" data-level="7.6" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#the-two-sample-t-test-in-r"><i class="fa fa-check"></i><b>7.6</b> The two-sample <span class="math inline">\(t\)</span> test in R</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#t-tests-with-data-frames-in-r"><i class="fa fa-check"></i><b>7.6.1</b> <span class="math inline">\(t\)</span>-tests with data frames in R</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#examples"><i class="fa fa-check"></i><b>7.7</b> Examples</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#using-the-p-value-method"><i class="fa fa-check"></i><b>7.7.1</b> Using the <span class="math inline">\(p\)</span>-value method</a></li>
<li class="chapter" data-level="7.7.2" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#using-neyman-pearson-testing"><i class="fa fa-check"></i><b>7.7.2</b> Using Neyman-Pearson testing</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="hypothesis-testing-comparing-two-proportions.html"><a href="hypothesis-testing-comparing-two-proportions.html"><i class="fa fa-check"></i><b>8</b> Hypothesis testing: comparing two proportions</a>
<ul>
<li class="chapter" data-level="8.1" data-path="hypothesis-testing-comparing-two-proportions.html"><a href="hypothesis-testing-comparing-two-proportions.html#example-an-investigation-into-gender-bias"><i class="fa fa-check"></i><b>8.1</b> Example: an investigation into gender bias</a></li>
<li class="chapter" data-level="8.2" data-path="hypothesis-testing-comparing-two-proportions.html"><a href="hypothesis-testing-comparing-two-proportions.html#comparing-two-binomial-proportions"><i class="fa fa-check"></i><b>8.2</b> Comparing two binomial proportions</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="hypothesis-testing-comparing-two-proportions.html"><a href="hypothesis-testing-comparing-two-proportions.html#a-simulation-method"><i class="fa fa-check"></i><b>8.2.1</b> A simulation method</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="hypothesis-testing-comparing-two-proportions.html"><a href="hypothesis-testing-comparing-two-proportions.html#an-analytical-method"><i class="fa fa-check"></i><b>8.3</b> An analytical method</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="hypothesis-testing-comparing-two-proportions.html"><a href="hypothesis-testing-comparing-two-proportions.html#the-analytical-method-a-summary"><i class="fa fa-check"></i><b>8.3.1</b> The analytical method: a summary</a></li>
<li class="chapter" data-level="8.3.2" data-path="hypothesis-testing-comparing-two-proportions.html"><a href="hypothesis-testing-comparing-two-proportions.html#conclusion"><i class="fa fa-check"></i><b>8.3.2</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="hypothesis-testing-comparing-two-proportions.html"><a href="hypothesis-testing-comparing-two-proportions.html#confidence-intervals-to-measure-the-difference"><i class="fa fa-check"></i><b>8.4</b> Confidence intervals to measure the difference</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="sample-size-and-power-for-a-neyman-pearson-hypothesis-test.html"><a href="sample-size-and-power-for-a-neyman-pearson-hypothesis-test.html"><i class="fa fa-check"></i><b>9</b> Sample size and power for a Neyman-Pearson hypothesis test</a>
<ul>
<li class="chapter" data-level="9.1" data-path="sample-size-and-power-for-a-neyman-pearson-hypothesis-test.html"><a href="sample-size-and-power-for-a-neyman-pearson-hypothesis-test.html#gender-bias-example-re-visited"><i class="fa fa-check"></i><b>9.1</b> Gender bias example re-visited</a></li>
<li class="chapter" data-level="9.2" data-path="sample-size-and-power-for-a-neyman-pearson-hypothesis-test.html"><a href="sample-size-and-power-for-a-neyman-pearson-hypothesis-test.html#the-power-of-a-hypothesis-test"><i class="fa fa-check"></i><b>9.2</b> The power of a hypothesis test</a></li>
<li class="chapter" data-level="9.3" data-path="sample-size-and-power-for-a-neyman-pearson-hypothesis-test.html"><a href="sample-size-and-power-for-a-neyman-pearson-hypothesis-test.html#an-analytical-approach"><i class="fa fa-check"></i><b>9.3</b> An analytical approach</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html"><i class="fa fa-check"></i><b>10</b> <span class="math inline">\(\chi^2\)</span> tests for contingency tables</a>
<ul>
<li class="chapter" data-level="10.1" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#example-customer-ratings-of-restaurants"><i class="fa fa-check"></i><b>10.1</b> Example: customer ratings of restaurants</a></li>
<li class="chapter" data-level="10.2" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#a-model-and-hypotheses"><i class="fa fa-check"></i><b>10.2</b> A model and hypotheses</a></li>
<li class="chapter" data-level="10.3" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#a-test-statistic-1"><i class="fa fa-check"></i><b>10.3</b> A test statistic</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#the-formula-for-the-expected-counts"><i class="fa fa-check"></i><b>10.3.1</b> The formula for the expected counts</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#computing-the-test-statistic-for-the-observed-data"><i class="fa fa-check"></i><b>10.4</b> Computing the test statistic for the observed data</a></li>
<li class="chapter" data-level="10.5" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#a-simulation-method-1"><i class="fa fa-check"></i><b>10.5</b> A simulation method</a></li>
<li class="chapter" data-level="10.6" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#an-analytical-method-1"><i class="fa fa-check"></i><b>10.6</b> An analytical method</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#chi2-tests-in-r"><i class="fa fa-check"></i><b>10.6.1</b> <span class="math inline">\(\chi^2\)</span> tests in R</a></li>
<li class="chapter" data-level="10.6.2" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#row-homogeneity-and-independence"><i class="fa fa-check"></i><b>10.6.2</b> Row homogeneity and independence</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#exercise"><i class="fa fa-check"></i><b>10.7</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="index-of-definitions-and-examples.html"><a href="index-of-definitions-and-examples.html"><i class="fa fa-check"></i><b>11</b> Index of definitions and examples</a>
<ul>
<li class="chapter" data-level="11.1" data-path="index-of-definitions-and-examples.html"><a href="index-of-definitions-and-examples.html#definitions"><i class="fa fa-check"></i><b>11.1</b> Definitions</a></li>
<li class="chapter" data-level="11.2" data-path="index-of-definitions-and-examples.html"><a href="index-of-definitions-and-examples.html#examples-1"><i class="fa fa-check"></i><b>11.2</b> Examples</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MAS109 - An Introduction to Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hypothesis-testing-comparing-two-population-means" class="section level1 hasAnchor" number="7">
<h1><span class="header-section-number">Chapter 7</span> Hypothesis testing: comparing two population means<a href="hypothesis-testing-comparing-two-population-means.html#hypothesis-testing-comparing-two-population-means" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<script type="text/javascript">
$(document).ready(function() {
  $folds = $(".fold");
  $folds.wrapInner("<div class=\"fold-blck\">"); // wrap a div container around content
  $folds.prepend("<button class=\"fold-btn\">Show solution</button>");  // add a button
  $(".fold-blck").toggle();  // fold all blocks
  $(".fold-btn").on("click", function() {  // add onClick event
    $(this).text($(this).text() === "Show solution" ? "Hide solution" : "Show solution");  // if the text equals "Fold", change it to "Unfold"or else to "Fold" 
    $(this).next(".fold-blck").toggle("linear");  // "swing" is the default easing function. This can be further customized in its speed or the overall animation itself.
  })
});
</script>
<p>In this chapter we will use hypothesis testing to compare two populations and see if they have different population means. We will use two different methods: a computer simulation method, and an analytical method known as the <strong>two-sample <span class="math inline">\(t\)</span>-test</strong>.</p>
<div id="example-can-imagining-eating-food-make-you-eat-less" class="section level2 hasAnchor" number="7.1">
<h2><span class="header-section-number">7.1</span> Example: can imagining eating food make you eat less?<a href="hypothesis-testing-comparing-two-population-means.html#example-can-imagining-eating-food-make-you-eat-less" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><a href="http://science.sciencemag.org/content/330/6010/1530">Morewedge et al. (2010)</a><a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> conducted an experiment to test whether imagining eating food can make one eat less, when offered the same food item to eat. The experiment was repeated by <a href="https://rdcu.be/bikKa">Camerer et al. (2018)</a><a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a>, and we use their data here.</p>
<ul>
<li><p>96 student volunteers were recruited, and split into two groups:</p>
<ol style="list-style-type: decimal">
<li><p>In the <strong>control group</strong>, the participants were each shown a picture of a bowl filled with thirty-three 20-cent coins. They were asked to imagine inserting the coins, one at a time, into a parking meter.</p></li>
<li><p>In the <strong>treatment group</strong>, the participants were each shown a picture of a bowl filled with three 20-cent coins. They were asked to imagine inserting the coins, one at a time, into a parking meter. They were then shown a picture a bowl containing 30 M&amp;Ms, and they were asked to imagine eating the M&amp;Ms, one at a time.</p></li>
</ol></li>
<li><p>All the participants were then given an actual bowl of M&amp;Ms to eat (containing 40g in total). They were told they were doing a taste test, and were told to eat as much or a little they liked.</p></li>
<li><p>Each participant did the experiment in a private cubicle, so no-one watched them eat, but the amount eaten was recorded once they had finished.</p></li>
</ul>
<p>Histograms of the amounts eaten for the two groups are shown in Figure <a href="hypothesis-testing-comparing-two-population-means.html#fig:MandM">7.1</a></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:MandM"></span>
<img src="MAS109-Data-Science_files/figure-html/MandM-1.png" alt="Histograms showing the amount of chocolate eaten in each group. The treatment group had to first imagine eating chocolate, before they were given anything to eat. Did it make them want to eat less?" width="384" />
<p class="caption">
Figure 7.1: Histograms showing the amount of chocolate eaten in each group. The treatment group had to first imagine eating chocolate, before they were given anything to eat. Did it make them want to eat less?
</p>
</div>
<div id="the-hypotheses" class="section level3 hasAnchor" number="7.1.1">
<h3><span class="header-section-number">7.1.1</span> The hypotheses<a href="hypothesis-testing-comparing-two-population-means.html#the-hypotheses" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We define <span class="math inline">\(\mu_X\)</span> to be the population mean quantity eaten that would be eaten under the control conditions (<em>not</em> imagining eating M&amp;Ms), and <span class="math inline">\(\mu_Y\)</span> to be the population mean quantity eaten that would be eaten under the treatment conditions (imagining eating M&amp;Ms). The null hypothesis is that imagining eating M&amp;Ms has no effect on consumption:</p>
<p><span class="math display">\[
H_0: \mu_X = \mu_Y
\]</span>
We choose a two-sided alternative
<span class="math display">\[
H_A: \mu_X \neq \mu_Y
\]</span>
as we would be interested if imagining eating M&amp;Ms either resulted in the participants eating more, or eating less on average.</p>
<p>We define:</p>
<ul>
<li><span class="math inline">\(x_1,\ldots,x_n\)</span>: the <span class="math inline">\(n\)</span> control group observations, with sample mean <span class="math inline">\(\bar{x}\)</span> and sample variance <span class="math inline">\(s^2_X\)</span>;</li>
<li><span class="math inline">\(y_1,\ldots,y_m\)</span>: the <span class="math inline">\(m\)</span> treatment group observations, with sample mean <span class="math inline">\(\bar{y}\)</span> and sample variance <span class="math inline">\(s^2_Y\)</span>.</li>
</ul>
<p>In this example, we have <span class="math inline">\(n=49\)</span> and <span class="math inline">\(m=47\)</span>.</p>
</div>
<div id="a-test-statistic" class="section level3 hasAnchor" number="7.1.2">
<h3><span class="header-section-number">7.1.2</span> A test statistic<a href="hypothesis-testing-comparing-two-population-means.html#a-test-statistic" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We measure the difference in mean consumption with the test statistic</p>
<p><span class="math display">\[t_{obs} = \frac{\bar{x} - \bar{y}}{\sqrt{\frac{s^2_X}{n} + \frac{s^2_Y}{m}}}\]</span>
so that we scale the difference in means by how much variation there is in the amounts the individuals ate.</p>
<p>In R, the observations are stored in the vectors <code>control</code> and <code>treatment</code>, and we compute <span class="math inline">\(t_{obs}\)</span> as follows</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="hypothesis-testing-comparing-two-population-means.html#cb143-1" tabindex="-1"></a>(<span class="fu">mean</span>(control) <span class="sc">-</span> <span class="fu">mean</span> (treatment))<span class="sc">/</span></span>
<span id="cb143-2"><a href="hypothesis-testing-comparing-two-population-means.html#cb143-2" tabindex="-1"></a>  <span class="fu">sqrt</span>(<span class="fu">var</span>(control)<span class="sc">/</span><span class="dv">49</span> <span class="sc">+</span> <span class="fu">var</span>(treatment)<span class="sc">/</span><span class="dv">47</span>)</span></code></pre></div>
<pre><code>## [1] 2.398</code></pre>
<p>(We will round this to 2.4 from now on.)</p>
</div>
</div>
<div id="hypothesis-testing-using-simulation" class="section level2 hasAnchor" number="7.2">
<h2><span class="header-section-number">7.2</span> Hypothesis testing using simulation<a href="hypothesis-testing-comparing-two-population-means.html#hypothesis-testing-using-simulation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>All hypothesis testing problems involve understanding what sort of data could arise <em>purely by chance</em>, where “purely by chance” is described by the null hypothesis. In the current example, could the difference in mean consumption have arisen purely by chance?</p>
<p>We will first use a computer simulation technique to investigate this. Let’s look at the first few observations in the treatment group</p>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb145-1"><a href="hypothesis-testing-comparing-two-population-means.html#cb145-1" tabindex="-1"></a>treatment[<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>]</span></code></pre></div>
<pre><code>## [1] 12  7  5  8</code></pre>
<p>We see that person 1 ate 12g, person 2 ate 7g and so on. Suppose the null hypothesis is true, and treatment has no effect. We might then suppose that, had person 1 been allocated to the control group instead, <em>it would have made no difference</em> to how much person 1 ate: he/she would still have eaten 12g. So maybe the difference is purely because more ‘hungry’ volunteers were randomly allocated to the control group than the treatment group.</p>
<p>Could this have happened by chance? We can investigate this as follows, bearing in mind that the randomness we are investigating here is the random allocation of volunteers to groups, and how that could produce unequal mean consumption.</p>
<ol style="list-style-type: decimal">
<li>We first combine all the treatment and control observations into a single vector called <code>everyone</code>.</li>
</ol>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb147-1"><a href="hypothesis-testing-comparing-two-population-means.html#cb147-1" tabindex="-1"></a>everyone <span class="ot">&lt;-</span> <span class="fu">c</span>(treatment, control)</span></code></pre></div>
<p>so to see all the observations:</p>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="hypothesis-testing-comparing-two-population-means.html#cb148-1" tabindex="-1"></a>everyone</span></code></pre></div>
<pre><code>##  [1] 12  7  5  8 40  4  4 11  7  5 13 11 10  4  7  2 13 12  2  2  9 10  3  2  1
## [26]  2  3  4  9  3  3 14  4  9  6  5  2 40  6 11 21  5  2  5  5  6 12  2  8 11
## [51]  0 40 12 40 11 15  2 12  4  9 11 11 13  8 12  9 10 12 10  4  7 10  8  9 14
## [76]  6  7  5  9 17 13  9 10 10 13 34  7 12  6 10 28 15  3 29 40 10</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>We now randomly allocate each person into either the treatment group or the control group.</li>
</ol>
<p>We first jumble up the order of the observations in <code>everyone</code>, using the <code>sample()</code> command</p>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb150-1"><a href="hypothesis-testing-comparing-two-population-means.html#cb150-1" tabindex="-1"></a>everyoneJumbled <span class="ot">&lt;-</span> <span class="fu">sample</span>(everyone)</span></code></pre></div>
<p>This is what we got:</p>
<div class="sourceCode" id="cb151"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb151-1"><a href="hypothesis-testing-comparing-two-population-means.html#cb151-1" tabindex="-1"></a>everyoneJumbled</span></code></pre></div>
<pre><code>##  [1] 11  5  3 12 10 21 11  2 14  5 13  7 12  1  8  9  3 10 11  3  5  9  8 12  7
## [26] 11 12 10  8  2 10  6 40  4 40  4  2  6  9  2  3  9  9 28 14 40 12  9 10  2
## [51]  2 10 12  6 40  9  7 11 10  2  7  4  7 11 12  2 13  5  6 34  5  2  3 13 15
## [76] 10  4 15  5 40 13 11 12  9  7  4 10 29 13  4  8  5  6 17  4  0</code></pre>
<p>and every time we use the <code>sample()</code> command, the observations in <code>everyone</code> will be jumbled up in a different order.</p>
<ol start="3" style="list-style-type: decimal">
<li>We now extract the first 47 elements to be a new set of random treatment observations:</li>
</ol>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb153-1"><a href="hypothesis-testing-comparing-two-population-means.html#cb153-1" tabindex="-1"></a>newTreatment <span class="ot">&lt;-</span> everyoneJumbled[<span class="dv">1</span><span class="sc">:</span><span class="dv">47</span>]</span></code></pre></div>
<p>and the remaining 49 elements to be a new set of random control observations:</p>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb154-1"><a href="hypothesis-testing-comparing-two-population-means.html#cb154-1" tabindex="-1"></a>newControl <span class="ot">&lt;-</span> everyoneJumbled[<span class="dv">48</span><span class="sc">:</span><span class="dv">96</span>]</span></code></pre></div>
<p>We’ve reallocated each person into either the treatment group or the control group, and assuming <span class="math inline">\(H_0\)</span> is true, that the treatment has no effect, ‘switching’ someone from one group to the other <em>wouldn’t change how much that person would eat</em>.</p>
<ol start="4" style="list-style-type: decimal">
<li>Now we’ll see how different the mean consumptions would have been (scaled by the standard deviations)</li>
</ol>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb155-1"><a href="hypothesis-testing-comparing-two-population-means.html#cb155-1" tabindex="-1"></a>(<span class="fu">mean</span>(newTreatment) <span class="sc">-</span> <span class="fu">mean</span>(newControl))<span class="sc">/</span></span>
<span id="cb155-2"><a href="hypothesis-testing-comparing-two-population-means.html#cb155-2" tabindex="-1"></a>    <span class="fu">sqrt</span>(<span class="fu">var</span>(newTreatment)<span class="sc">/</span><span class="dv">47</span> <span class="sc">+</span> <span class="fu">var</span>(newControl)<span class="sc">/</span><span class="dv">49</span>)</span></code></pre></div>
<pre><code>## [1] 0.2098</code></pre>
<p>This gives a much smaller test statistic.</p>
<p>Now we’ll repeat the process lots of times, and see how easy it is to generate a test statistic as large as the one we got (<span class="math inline">\(t_{obs}=2.4\)</span>):</p>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb157-1"><a href="hypothesis-testing-comparing-two-population-means.html#cb157-1" tabindex="-1"></a>testStatistics <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, <span class="dv">100000</span>)</span>
<span id="cb157-2"><a href="hypothesis-testing-comparing-two-population-means.html#cb157-2" tabindex="-1"></a>everyone <span class="ot">&lt;-</span> <span class="fu">c</span>(treatment, control)</span>
<span id="cb157-3"><a href="hypothesis-testing-comparing-two-population-means.html#cb157-3" tabindex="-1"></a></span>
<span id="cb157-4"><a href="hypothesis-testing-comparing-two-population-means.html#cb157-4" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100000</span>){</span>
<span id="cb157-5"><a href="hypothesis-testing-comparing-two-population-means.html#cb157-5" tabindex="-1"></a>  everyoneJumbled <span class="ot">&lt;-</span> <span class="fu">sample</span>(everyone)</span>
<span id="cb157-6"><a href="hypothesis-testing-comparing-two-population-means.html#cb157-6" tabindex="-1"></a>  newTreatment <span class="ot">&lt;-</span> everyoneJumbled[<span class="dv">1</span><span class="sc">:</span><span class="dv">47</span>]</span>
<span id="cb157-7"><a href="hypothesis-testing-comparing-two-population-means.html#cb157-7" tabindex="-1"></a>  newControl <span class="ot">&lt;-</span> everyoneJumbled[<span class="dv">48</span><span class="sc">:</span><span class="dv">96</span>]</span>
<span id="cb157-8"><a href="hypothesis-testing-comparing-two-population-means.html#cb157-8" tabindex="-1"></a>  testStatistics[i] <span class="ot">&lt;-</span> (<span class="fu">mean</span>(newTreatment) <span class="sc">-</span> <span class="fu">mean</span>(newControl))<span class="sc">/</span></span>
<span id="cb157-9"><a href="hypothesis-testing-comparing-two-population-means.html#cb157-9" tabindex="-1"></a>    <span class="fu">sqrt</span>(<span class="fu">var</span>(newTreatment)<span class="sc">/</span><span class="dv">47</span> <span class="sc">+</span> <span class="fu">var</span>(newControl)<span class="sc">/</span><span class="dv">49</span>)</span>
<span id="cb157-10"><a href="hypothesis-testing-comparing-two-population-means.html#cb157-10" tabindex="-1"></a>}</span></code></pre></div>
<p>We now count how many times we got a test statistic larger (in absolute) value than 2.4:</p>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb158-1"><a href="hypothesis-testing-comparing-two-population-means.html#cb158-1" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">abs</span>(testStatistics) <span class="sc">&gt;=</span> <span class="fl">2.4</span>)</span></code></pre></div>
<pre><code>## [1] 1650</code></pre>
<p>We see that about only 1650 times out of 100,000 did we generate test statistics (scaled differences between the sample means) as large as 2.4: the probability of producing a difference between the groups as large as this <em>purely by random chance</em> is about 2%.</p>
<p>To visualise this, we’ll plot a histogram of our random test statistics:</p>
<p>We’ll draw a histogram of the randomly generated test statistics:</p>
<p><img src="MAS109-Data-Science_files/figure-html/unnamed-chunk-148-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>We can see a symmetrical distribution around 0, with most smaller in absolute value than 2.4</p>
<div class="rmdnote">
<p>
In effect, we’ve computed a <span class="math inline"><span class="math inline">\(p\)</span></span>-value: we’ve used simulation to
estimate the probability, assuming <span class="math inline"><span class="math inline">\(H_0\)</span></span> to be true, of getting a test
statistic as large as the one we observed.
</p>
</div>
</div>
<div id="the-two-sample-t-test" class="section level2 hasAnchor" number="7.3">
<h2><span class="header-section-number">7.3</span> The two-sample <span class="math inline">\(t\)</span> test<a href="hypothesis-testing-comparing-two-population-means.html#the-two-sample-t-test" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As an alternative to the computer simulation, we can use an analytical approach, known as the two-sample <span class="math inline">\(t\)</span>-test.</p>
<p>Before the experiment has been conducted define <span class="math inline">\(X_i\)</span> to be the amount that the <span class="math inline">\(i\)</span>-th participant in the control group will eat, and <span class="math inline">\(Y_i\)</span> to be the amount <span class="math inline">\(i\)</span>-th participant in the treatment group will eat. Before the experiment has been conducted, we can think of <span class="math inline">\(X_i\)</span> and <span class="math inline">\(Y_i\)</span> as random variables: their values are not yet known.</p>
<ol style="list-style-type: decimal">
<li><strong>The model and hypotheses</strong></li>
</ol>
<p>We now suppose that</p>
<p><span class="math display">\[\begin{align*}
X_1,\ldots,X_{n} &amp;\stackrel{i.i.d}{\sim}N(\mu_X, \sigma^2_X),\\
Y_1,\ldots,Y_{m} &amp;\stackrel{i.i.d}{\sim}N(\mu_Y, \sigma^2_Y),
\end{align*}\]</span>
so that the population mean amounts eaten under the treatment and control conditions would be <span class="math inline">\(\mu_X\)</span> and <span class="math inline">\(\mu_Y\)</span>. We consider the hypotheses
<span class="math display">\[\begin{align*}
H_0:\mu_X = \mu_Y,\\
H_A:\mu_X \neq \mu_Y,
\end{align*}\]</span>
so the null hypothesis is that there is no difference between the mean amount eaten under either condition (it doesn’t matter what the participants imagine doing before they eat.)</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>The test statistic, and its distribution under <span class="math inline">\(H_0\)</span></strong></li>
</ol>
<p>We use the test statistic</p>
<p><span class="math display">\[\begin{equation}
T = \frac{\bar{X} - \bar{Y} }{\sqrt{\frac{S^2_X}{n} + \frac{S^2_Y}{m} }}
\end{equation}\]</span></p>
<p>Assuming <span class="math inline">\(H_0\)</span> is true, then approximately
<span class="math display">\[
T \sim t_\nu,
\]</span>
i.e <span class="math inline">\(T\)</span> has a student <span class="math inline">\(t\)</span> distribution with <span class="math inline">\(\nu\)</span> degrees of freedom.</p>
<div class="rmdnote">
<p>
As long as the sample sizes are moderately large (say at least 30 per
group), this approximation is usually safe to use, even if the
individual observations are <em>not</em> normally distributed (the
Central Limit Theorem comes into play here).
</p>
</div>
<p>We will determine <span class="math inline">\(\nu\)</span> from the data: we use what is known as the <strong>Welch approximation</strong>
<span class="math display" id="eq:Welch">\[\begin{equation}
\nu = \frac {\left(\frac{s^2_X}{n} + \frac{s^2_Y}{m}\right)^2}
            {\frac{(s_X^2/n)^2}{n-1} + \frac{(s_Y^2/m)^2}{m-1}}.\tag{7.1}
\end{equation}\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li><strong>Computing the <span class="math inline">\(p\)</span>-value</strong></li>
</ol>
<p>We compute the value of the test statistic for the observed data</p>
<p><span class="math display">\[t_{obs} = \frac{\bar{x} - \bar{y}}{\sqrt{\frac{s^2_x}{49} + \frac{s^2_y}{47}}} = 2.389.\]</span>
and, using the Welch approximation <a href="hypothesis-testing-comparing-two-population-means.html#eq:Welch">(7.1)</a>, we compute the degrees of freedom to be
<span class="math display">\[
\nu = \frac {\left(\frac{s^2_X}{49} + \frac{s^2_Y}{47}\right)^2}
            {\frac{(s_X^2/49)^2}{49-1} + \frac{(s_Y^2/47)^2}{47-1}} \simeq 93.
\]</span></p>
<p>To calculate the <span class="math inline">\(p\)</span>-value, we calculate
<span class="math display">\[\begin{align*}
&amp; P(|T| \ge |t_{obs} |\, | \mbox{$H_0$ true})\\
&amp;= P(|T| \ge 2.4 | \mbox{$H_0$ true})\\
&amp; = P(T \le  -2.4  | \mbox{$H_0$ true})\\
&amp;+ P(T \ge  2.4  | \mbox{$H_0$ true}),
\end{align*}\]</span>
where <span class="math inline">\(T\)</span> has the <span class="math inline">\(t_{93}\)</span> distribution under <span class="math inline">\(H_0\)</span>. The <span class="math inline">\(p\)</span>-value is shown as the red shaded area below. We also show the histogram of test statistics obtained using the simulation method.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-151"></span>
<img src="MAS109-Data-Science_files/figure-html/unnamed-chunk-151-1.png" alt="The observed test statistic (shown as the blue cross) was -2.4. For the $p$-value, we want the probability that $T$ would be as extreme as this: either less than -2.4, or greater than 2.4. This probability is shown as the red shaded area. For comparison, we also show the histogram of test statistics from the simulation method. Note the close agreement with the $t$-distribution." width="576" />
<p class="caption">
Figure 7.2: The observed test statistic (shown as the blue cross) was -2.4. For the <span class="math inline">\(p\)</span>-value, we want the probability that <span class="math inline">\(T\)</span> would be as extreme as this: either less than -2.4, or greater than 2.4. This probability is shown as the red shaded area. For comparison, we also show the histogram of test statistics from the simulation method. Note the close agreement with the <span class="math inline">\(t\)</span>-distribution.
</p>
</div>
<p>To calculate the <span class="math inline">\(p\)</span>-value using R: we want
<span class="math display">\[\begin{align}
&amp;P(T\le - 2.4) + P(T\ge 2.4)\\
&amp;= 2\times P(T\le -2.4)
\end{align}\]</span>
so the R command to get the <span class="math inline">\(p\)</span>-value is</p>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb160-1"><a href="hypothesis-testing-comparing-two-population-means.html#cb160-1" tabindex="-1"></a><span class="dv">2</span> <span class="sc">*</span> <span class="fu">pt</span>(<span class="sc">-</span><span class="fl">2.4</span>, <span class="dv">93</span>)</span></code></pre></div>
<pre><code>## [1] 0.01839</code></pre>
<p>hence the <span class="math inline">\(p\)</span>-value approximately 0.02.</p>
<p>To interpret this, we can say that the experiment has provide some evidence that imagining eating food can reduce how much you want to eat! The evidence is not very strong, but this experiment was a <em>replication</em> of an earlier study: two independent studies found the same effect, so taken together, the evidence is more convincing.</p>
<div id="the-two-sample-t-test-with-the-neyman-pearson-method" class="section level3 hasAnchor" number="7.3.1">
<h3><span class="header-section-number">7.3.1</span> The two-sample <span class="math inline">\(t\)</span>-test with the Neyman-Pearson method<a href="hypothesis-testing-comparing-two-population-means.html#the-two-sample-t-test-with-the-neyman-pearson-method" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If using the Neyman-Pearson method, we would instead (after choosing the size of the test) identify the critical region. For a test of size 0.05, and a two-sided alternative hypothesis, we would need the 2.5th and 97.5th percentiles of the <span class="math inline">\(t_\nu\)</span> distribution. Continuing the example, in R, we would do</p>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb162-1"><a href="hypothesis-testing-comparing-two-population-means.html#cb162-1" tabindex="-1"></a><span class="fu">qt</span>(<span class="fl">0.975</span>, <span class="dv">93</span>)</span></code></pre></div>
<pre><code>## [1] 1.986</code></pre>
<p>so the critical region would be <span class="math inline">\((-\infty, -1.99]\cup [1.99, \infty)\)</span>, as shown below.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-154"></span>
<img src="MAS109-Data-Science_files/figure-html/unnamed-chunk-154-1.png" alt="The critical region for a test of size 0.05 is shown as by the green shaded area. (The observed test statistic was 2.4, which does fall in this region, so if using the Neyman-Pearson framework, we would conclude that \(H_0\) is rejected at the 5% level of significance." width="384" />
<p class="caption">
Figure 7.3: The critical region for a test of size 0.05 is shown as by the green shaded area. (The observed test statistic was 2.4, which does fall in this region, so if using the Neyman-Pearson framework, we would conclude that <span class="math inline">\(H_0\)</span> is rejected at the 5% level of significance.
</p>
</div>
</div>
<div id="an-illustrated-guide" class="section level3 hasAnchor" number="7.3.2">
<h3><span class="header-section-number">7.3.2</span> An illustrated guide<a href="hypothesis-testing-comparing-two-population-means.html#an-illustrated-guide" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>With thanks again to @allison_horst, below is an illustrated guide to two-sample <span class="math inline">\(t\)</span> tests.</p>
<p><img src="images/t_test_1.jpg" width="80%" style="display: block; margin: auto;" /><img src="images/t_test_2.jpg" width="80%" style="display: block; margin: auto;" /><img src="images/t_test_3.jpg" width="80%" style="display: block; margin: auto;" /><img src="images/t_test_4.jpg" width="80%" style="display: block; margin: auto;" /><img src="images/t_test_5.jpg" width="80%" style="display: block; margin: auto;" /><img src="images/t_test_6.jpg" width="80%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="confidence-interval-for-the-difference-between-two-means" class="section level2 hasAnchor" number="7.4">
<h2><span class="header-section-number">7.4</span> Confidence interval for the difference between two means<a href="hypothesis-testing-comparing-two-population-means.html#confidence-interval-for-the-difference-between-two-means" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In addition to reporting the <span class="math inline">\(p\)</span>-value, we should also report a confidence interval for <span class="math inline">\(\mu_X - \mu_Y\)</span>: what was the difference in means between the two groups?</p>
<div class="rmdnote">
<p>
Sometimes, two groups may be statistically significantly different,
but the <em>actual</em> difference may be so small as to be unimportant.
Report a confidence interval as well as a <span class="math inline"><span class="math inline">\(p\)</span></span>-value.
</p>
</div>
<p>The formula for the confidence interval is
<span class="math display">\[
\bar{x} - \bar{y} \pm t_{\nu,\, 0.025}\sqrt{\frac{s^2_X}{n} + \frac{s^2_Y}{m}}.
\]</span>
where the degrees of freedom <span class="math inline">\(\nu\)</span> is the same as that used in the hypothesis test. Substituting in the values, we find this confidence interval to be <span class="math inline">\([0.74, 7.8]\)</span>g. One M&amp;M weighs about 1g, so the difference in population mean consumption might be somewhere between 1 and 8 M&amp;Ms (at the lower limit, the effect of imagining eating M&amp;Ms could be very small.)</p>
</div>
<div id="equivalence-of-confidence-intervals-and-neyman-pearson-testing" class="section level2 hasAnchor" number="7.5">
<h2><span class="header-section-number">7.5</span> Equivalence of confidence intervals and Neyman-Pearson testing<a href="hypothesis-testing-comparing-two-population-means.html#equivalence-of-confidence-intervals-and-neyman-pearson-testing" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A <span class="math inline">\(100(1-\alpha)\%\)</span> confidence interval for <span class="math inline">\(\mu_X = \mu_Y\)</span> contains 0 if and only if the null hypothesis <span class="math inline">\(H_0:\mu_X = \mu_Y\)</span> (with a two-sided alternative) is <em>not</em> rejected in a Neyman Pearson test of size <span class="math inline">\(\alpha\)</span>.</p>
<div class="rmdnote">
<p>
If we have already calculated a <span class="math inline"><span class="math inline">\(100(1-\alpha)\%\)</span></span> confidence interval for
<span class="math inline"><span class="math inline">\(\mu_X - \mu_Y\)</span></span>, there is <strong>no
need</strong> to do a separate calculation to perform a Neyman Pearson
test (of size <span class="math inline"><span class="math inline">\(\alpha\)</span></span>) of the
hypothesis <span class="math inline"><span class="math inline">\(H_0:\mu_X = \mu_Y\)</span></span>: we
simply look to see whether the confidence interval contains the value
<span class="math inline"><span class="math inline">\(0\)</span></span> or not.
</p>
</div>
<p>See the tutorial exercises for a proof.</p>
</div>
<div id="the-two-sample-t-test-in-r" class="section level2 hasAnchor" number="7.6">
<h2><span class="header-section-number">7.6</span> The two-sample <span class="math inline">\(t\)</span> test in R<a href="hypothesis-testing-comparing-two-population-means.html#the-two-sample-t-test-in-r" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In R, we use the command <code>t.test()</code>. The two samples we want to compare are stored in the vectors <code>treatment</code> and <code>control</code>, so we do</p>
<div class="sourceCode" id="cb164"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb164-1"><a href="hypothesis-testing-comparing-two-population-means.html#cb164-1" tabindex="-1"></a><span class="fu">t.test</span>(control, treatment)</span></code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  control and treatment
## t = 2.4, df = 93, p-value = 0.02
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  0.7364 7.8263
## sample estimates:
## mean of x mean of y 
##    12.388     8.106</code></pre>
<p>We can see in the output the value of the observed test statistic <code>t</code>, the degrees of freedom in the Welch approximation <code>df</code>, the <span class="math inline">\(p\)</span>-value, as well as a 95% confidence interval for <span class="math inline">\(\mu_X - \mu_Y\)</span>.</p>
<div id="t-tests-with-data-frames-in-r" class="section level3 hasAnchor" number="7.6.1">
<h3><span class="header-section-number">7.6.1</span> <span class="math inline">\(t\)</span>-tests with data frames in R<a href="hypothesis-testing-comparing-two-population-means.html#t-tests-with-data-frames-in-r" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If your data are in a data frame, you can use a different syntax which is more convenient. Suppose the data are stored in a data frame called <code>eating</code>, with the first three and last three rows shown below</p>
<div class="sourceCode" id="cb166"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb166-1"><a href="hypothesis-testing-comparing-two-population-means.html#cb166-1" tabindex="-1"></a><span class="fu">head</span>(eating, <span class="at">n =</span> <span class="dv">3</span>)</span></code></pre></div>
<pre><code>## # A tibble: 3 × 2
##   group   amount
##   &lt;chr&gt;    &lt;dbl&gt;
## 1 Control      2
## 2 Control      8
## 3 Control     11</code></pre>
<div class="sourceCode" id="cb168"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb168-1"><a href="hypothesis-testing-comparing-two-population-means.html#cb168-1" tabindex="-1"></a><span class="fu">tail</span>(eating, <span class="at">n =</span> <span class="dv">3</span>)</span></code></pre></div>
<pre><code>## # A tibble: 3 × 2
##   group     amount
##   &lt;chr&gt;      &lt;dbl&gt;
## 1 Treatment      5
## 2 Treatment      6
## 3 Treatment     12</code></pre>
<p>The column <code>group</code> indicated which group each participant was in. We can then use the command</p>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb170-1"><a href="hypothesis-testing-comparing-two-population-means.html#cb170-1" tabindex="-1"></a><span class="fu">t.test</span>(amount <span class="sc">~</span> group, <span class="at">data =</span> eating)</span></code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  amount by group
## t = 2.4, df = 93, p-value = 0.02
## alternative hypothesis: true difference in means between group Control and group Treatment is not equal to 0
## 95 percent confidence interval:
##  0.7364 7.8263
## sample estimates:
##   mean in group Control mean in group Treatment 
##                  12.388                   8.106</code></pre>
<p>which we can see has produced the same result. (Read the command <code>t.test(amount ~ group, data = eating)</code> as, “do a two-sample <span class="math inline">\(t\)</span>-test to see if the mean value of the <code>amount</code> variable is different between the groups labelled by the <code>group</code> column, using the data frame <code>eating</code>”).</p>
</div>
</div>
<div id="examples" class="section level2 hasAnchor" number="7.7">
<h2><span class="header-section-number">7.7</span> Examples<a href="hypothesis-testing-comparing-two-population-means.html#examples" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="using-the-p-value-method" class="section level3 hasAnchor" number="7.7.1">
<h3><span class="header-section-number">7.7.1</span> Using the <span class="math inline">\(p\)</span>-value method<a href="hypothesis-testing-comparing-two-population-means.html#using-the-p-value-method" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Can social media be bad for your mental health and well-being? This is not a question we would expect to answer definitely with a single experiment; we would not attempt to “reject” or “not reject” a suitable hypothesis once-and-for-all. Rather, we might use hypothesis testing with the <span class="math inline">\(p\)</span>-value method to help understand the strength of evidence provided by any single experiment.</p>
<div class="example">
<p><span id="exm:exampleFacebook" class="example"><strong>Example 7.1  (Is quitting Facebook good for you?) </strong></span><br> <a href="https://www.liebertpub.com/doi/full/10.1089/cyber.2016.0259">Tromholt (2016)</a><a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a> investigated whether quitting Facebook can improve your well-being.</p>
</div>
<p>In the experiment, about a thousand volunteers (all Facebook users) were randomly allocated to either a treatment group, in which they told not to use Facebook for one week, or a control group, in which they carried on using Facebook as normal. At the end of the week, all participants completed a questionnaire. One of the questions asked them to record, “In general, how satisfied are you with your life today?” on a scale of 1 (very dissatisfied) to 10 (very satisfied). Let <span class="math inline">\(x_1,\ldots,x_n\)</span> be the observed responses in the treatment group, and <span class="math inline">\(y_1,\ldots,y_m\)</span> be the observed responses in the control group. Results from those who repsponded were as follows.</p>
<p><span class="math display">\[
\bar{x} = 8.11,\, \bar{y} = 7.74,\, s^2_X = 1.23^2,\, s^2_Y = 1.43^2,\,n = 516, \,m=372
\]</span>
with</p>
<p><span class="math display">\[
\nu = \frac {\left(\frac{s^2_X}{516} + \frac{s^2_Y}{372}\right)^2}
            {\frac{(s_X^2/516)^2}{516-1} + \frac{(s_Y^2/372)^2}{372-1}} \simeq 726.
\]</span></p>
<ol style="list-style-type: decimal">
<li>Defining your notation carefully, state suitable hypotheses for the experiment.</li>
<li>Conduct an appropriate hypothesis test, reporting the <span class="math inline">\(p\)</span>-value.</li>
<li>Report a 95% confidence interval for the difference in population means.</li>
<li>In plain English, summarise your results.</li>
</ol>
<p>Some R output to help is as follows:</p>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb172-1"><a href="hypothesis-testing-comparing-two-population-means.html#cb172-1" tabindex="-1"></a><span class="fu">pt</span>(<span class="sc">-</span><span class="fl">4.03</span>, <span class="dv">726</span>)</span></code></pre></div>
<pre><code>## [1] 3.083e-05</code></pre>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb174-1"><a href="hypothesis-testing-comparing-two-population-means.html#cb174-1" tabindex="-1"></a><span class="fu">qt</span>(<span class="fl">0.975</span>, <span class="dv">726</span>)</span></code></pre></div>
<pre><code>## [1] 1.963</code></pre>
<div class="fold">
<p><strong>Solution</strong></p>
<ol style="list-style-type: decimal">
<li>Define <span class="math inline">\(\mu_X\)</span> to be the population mean “life satisfaction score” under the treatment group condition, and <span class="math inline">\(\mu_Y\)</span> to be the population mean score under the control group condition. Our hypotheses are</li>
</ol>
<p><span class="math display">\[\begin{align*}
H_0: \mu_X &amp;= \mu_Y,\\
H_A: \mu_X &amp;\neq \mu_Y.
\end{align*}\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Using the two-sample <span class="math inline">\(t\)</span>-test, we compute
<span class="math display">\[t_{obs} = \frac{\bar{x} - \bar{y}}{\sqrt{\frac{s^2_x}{516} + \frac{s^2_y}{372}}} = 4.03.\]</span>
For the degrees of freedom parameter, we are given <span class="math inline">\(\nu\simeq726\)</span>, so under <span class="math inline">\(H_0\)</span>, the test statistic would have (approximately) a <span class="math inline">\(t_{726}\)</span> distribution.. The observed test statistic is right out in the tail of this distribution, so the <span class="math inline">\(p\)</span>-value will be small.</li>
</ol>
<p>The <span class="math inline">\(p\)</span>-value is given by
<span class="math display">\[
2 \times P(T_{726} \le -4.03) \simeq 6\times 10^{-5}
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li><p>An approximate 95% confidence interval for the difference in population means is
<span class="math display">\[
\bar{x} - \bar{y} \pm t_{726,\, 0.025}\sqrt{\frac{s^2_X}{n} + \frac{s^2_Y}{m}}.
\]</span>
From the R output, we have <span class="math inline">\(t_{726,\, 0.025}=1.963\)</span>, so the confidence interval is <span class="math inline">\([0.2, 0.6]\)</span>, to 1 decimal place.</p></li>
<li><p>The experiment found very strong evidence against the null hypothesis of equal mean life satisfaction scores, with the particants who did not use Facebook for one week giving higher scores. However, the effect of not using Facebook was small: the difference in means is likely less than a single point on the 10 point response scale.</p></li>
</ol>
</div>
</div>
<div id="using-neyman-pearson-testing" class="section level3 hasAnchor" number="7.7.2">
<h3><span class="header-section-number">7.7.2</span> Using Neyman-Pearson testing<a href="hypothesis-testing-comparing-two-population-means.html#using-neyman-pearson-testing" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Neyman-Pearson testing is used is in medical research, specifically, clinical trials for new drugs. The scenario would be something like this:</p>
<ul>
<li>A pharmaceutical company has developed a new drug, and will test it using a hypothesis test.</li>
<li>The null hypothesis is that the drug has no effect.</li>
<li>The action to be taken following the test is either to license the drug for use on patients, or to decide that it cannot be used; the pharmaceutical company would then abandon that drug, and move onto to developing a different drug.</li>
<li>If the null hypothesis is “rejected”, we conclude that the drug <em>does</em> has an effect, and the drug gets its license (assuming the drug effect is beneficial for patients).</li>
<li>If the null hypothesis is “not rejected”, we conclude that there is no evidence the drug works, and it is not licensed for further use.</li>
</ul>
<div class="example">
<p><span id="exm:exampleNPttest" class="example"><strong>Example 7.2  (Testing a new diabetes treatment.) </strong></span><br> Patients with type-2 diabetes may use drugs to control their blood sugar levels. A pharmaceutical company (Merck) conducted a clinical trial to compare the efficacy of a combination of two drugs, sitagliptin and metformin, with using metformin alone. The product name for this combination of drugs is “Efficib”. 190 patients were recruited to the trial, and were randomly allocated to one of two treatments:</p>
</div>
<ul>
<li>treatment 1: 100mg sitagliptin per day, and at least 1500mg metformin per day</li>
<li>treatment 2: a daily placebo, made to look like a dose of 100mg sitagliptin, and at least 1500mg metformin per day.</li>
</ul>
<p>The study was “double-blinded”: neither the patients nor their doctors knew which treatment they were getting (though the trial investigators did know.) A1C (a measure of blood sugar level) was recorded for each patient at the start and after 18 weeks, and the change in A1C was recorded for each patient.</p>
<p>We model this as follows.</p>
<p>Let <span class="math inline">\(X_i\)</span> denote the change in A1C for the <span class="math inline">\(i\)</span>-th patient on the treatment 1, and <span class="math inline">\(Y_i\)</span> denote the change in A1C the <span class="math inline">\(i\)</span>-th patient on treatment 2. We suppose
<span class="math display">\[\begin{align*}
X_1,\ldots,X_{95}&amp;\stackrel{i.i.d}{\sim}N(\mu_X, \sigma^2_X),\\
Y_1,\ldots,Y_{92}&amp;\stackrel{i.i.d}{\sim}N(\mu_Y, \sigma^2_Y).
\end{align*}\]</span></p>
<p>We denote the corresponding observed values by <span class="math inline">\(x_1,\ldots,x_{95}\)</span> and <span class="math inline">\(y_1, \ldots, y_{92}\)</span>. The trial results are published at <a href="https://clinicaltrials.gov/ct2/show/results/NCT00337610">clinicaltrials.gov</a>. Individual patient data are not normally published, and we can infer (approximately) what the summary statistics were: we have</p>
<p><span class="math display">\[\begin{align}
\bar{x} &amp;= \frac{1}{95}\sum_{i=1}^{95}x_i = -1.00,\\
s^2_X &amp;= \frac{1}{94}\sum_{i=1}^{95}(x_i - \bar{x})^2= 1.5456,\\
\bar{y} &amp;= \frac{1}{92}\sum_{i=1}^{92}y_i = 0.02,\\
s^2_Y &amp;= \frac{1}{91}\sum_{i=1}^{92}(y_i - \bar{y})^2= 1.4968.
\end{align}\]</span></p>
<ol style="list-style-type: decimal">
<li>State appropriate null and hypotheses, in terms of your model parameters, to test whether the addition of sitagliptin had an effect</li>
<li>Conduct an appropriate Neyman-Pearson test, of size 0.05, stating the conclusions clearly.</li>
</ol>
<p>Some R output to help is as follows.</p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="hypothesis-testing-comparing-two-population-means.html#cb176-1" tabindex="-1"></a><span class="fu">qt</span>(<span class="fu">c</span>(<span class="fl">0.9</span>, <span class="fl">0.95</span>, <span class="fl">0.975</span>, <span class="fl">0.99</span>), <span class="dv">185</span>)</span></code></pre></div>
<pre><code>## [1] 1.286 1.653 1.973 2.347</code></pre>
<div class="fold">
<p><strong>Solution</strong></p>
<p>We consider the hypotheses
<span class="math display">\[\begin{align*}
H_0 &amp;: \mu_X = \mu_Y,\\
H_A &amp;: \mu_X \neq \mu_Y,
\end{align*}\]</span>
so that the null hypothesis is that there is no effect from the additional treatment with sitagliptin</p>
<p>For our two-sample <span class="math inline">\(t\)</span>-test, we have
<span class="math display">\[
t_{obs}=\frac{\bar{x} - \bar{y}}{\sqrt{\frac{s^2_X}{95} + \frac{s^2_Y}{92}}} = -5.655,
\]</span></p>
<p><span class="math display">\[
\nu =  \frac {\left(\frac{s^2_X}{95} + \frac{s^2_Y}{92}\right)^2}
            {\frac{(s_X^2/95)^2}{94} + \frac{(s_Y^2/92)^2}{91}} \simeq 185.
\]</span>
Hence, for a test of size 0.05, our critical region is anything above <span class="math inline">\(t_{185;\, 0.025}\)</span> or anything below <span class="math inline">\(t_{185;\, 0.975}\)</span> (anything above the 97.5th percentile, or anything below the 2.5th percentile, for the student-<span class="math inline">\(t\)</span> distribution with 185 degrees of freedom.) From the R output, we have <span class="math inline">\(t_{17.7;\, 0.025}=1.97\)</span> and so <span class="math inline">\(t_{17.7;\, 0.975}=-1.97\)</span>. The critical region and observed test statistic are plotted below.</p>
<p>As <span class="math inline">\(t_{obs}\)</span> does lie in the critical region, we conclude that we reject <span class="math inline">\(H_0\)</span>. We say that there is evidence (at the 5% level of significance) that there is an effect of combining sitagliptin with metformin, and that this effect is an increased reduction in A1c (adding sitagliptin has a beneficial effect.)</p>
<p>There have been other studies to test the effect of sitagliptin and metformin (the “Efficib” drug). Based on these studies, <a href="https://www.ema.europa.eu/en/medicines/human/EPAR/efficib">the European Medicines Agency approved Efficib for use in the European Union</a>.</p>
</div>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="6">
<li id="fn6"><p>Morewedge, C. K., Huh, Y. E. &amp; Vosgerau, J. Thought for food: imagined consumption reduces actual consumption. Science 330, 1530–1533 (2010).<a href="hypothesis-testing-comparing-two-population-means.html#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>Camerer, C. F., Dreber, A., Holzmeister, F., Ho, T.-H., Huber, J., Johannesson, M.,… Wu, H. (2018). Evaluating the replicability of social science experiments in Nature and Science between 2010 and 2015. Nature Human Behaviour, 2(9), 637–644. <a href="https://doi.org/10.1038/s41562-018-0399-z" class="uri">https://doi.org/10.1038/s41562-018-0399-z</a><a href="hypothesis-testing-comparing-two-population-means.html#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>Morten Tromholt
Cyberpsychology, Behavior, and Social Networking 2016 19:11, 661-666.<a href="hypothesis-testing-comparing-two-population-means.html#fnref8" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="hypothesis-testing-a-level-recap.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="hypothesis-testing-comparing-two-proportions.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
