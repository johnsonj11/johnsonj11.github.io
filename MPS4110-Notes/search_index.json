[["index.html", "Data handling, exploratory analysis, and reporting in R Section 1 Introduction 1.1 About these notes 1.2 Books 1.3 Acknowledgements", " Data handling, exploratory analysis, and reporting in R Author: Jeremy Oakley Section 1 Introduction These notes are written for students on MPS4110: The Statistician’s Toolkit. Topics covered include working with R and RStudio; importing data, and getting data into a suitable format for analyses with R; making plots with ggplot2; writing reports with R Markdown; making web apps with shiny. We do not cover R programming (e.g. writing your own functions); this is included in MPS4111: Bayesian Statistics and Computational Methods. 1.1 About these notes These notes will get you started on various topics, but are not intended to cover everything you might need to know. There are lots of excellent free, online resources for learning R, and links to further reading will be given where appropriate. After studying these notes, you should be able to find things out quickly for yourself, if necessary. You don’t need to know everything straight away! Try to get a basic understanding of how things work, and what sorts of things are possible, and then search/study the details when you start working on a particular project. 1.2 Books Although it can be easy to search for and find help online, you have to know what you are looking for. I strongly recommend that you browse some of the following books (the graphics/data visualisation books in particular), to get a broader understanding of what you could do with your data. All the following books can be read online for free. (I have hard copies of most of these, which I prefer to study. I do not recommend buying books just for this module, but if a particular book looks useful to you more widely, I would recommend buying a hard copy.) A good general reference book for MPS4110 is Wickham, H. and Grolemund, G. (2017), R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. O’Reilly Media, Inc. For R Markdown, I recommend Xie, Y., Allaire, J. J. and Grolemund G. (2019), R Markdown: The Definitive Guide. Chapman and Hall/CRC. Xie, Y., Dervieux, C. and Riederer, E. (2020), The R Markdown Cookbook. Chapman and Hall/CRC. and if you plan to use R Markdown for your dissertation Xie, Y. (2017), bookdown: Authoring Books and Technical Documents with R Markdown. Chapman and Hall/CRC. For graphics/data visualisation, I recommend Chang, W. (2018), R Graphics Cookbook (2nd edition). O’Reilly Media, Inc. Wilke, C. O. (2019), Fundamentals of Data Visualization: A Primer on Making Informative and Compelling Figures. O’Reilly Media, Inc. Healy, K. (2019). Data Visualization: A Practical Introduction. Princeton University Press Healy (2019) is a beautiful looking book (thereby proving his point!) and covers ggplot2. Wilke (2019) purposefully doesn’t include any code, but the discussion and advice is excellent. (He has made all the R code used to produce the book available here). 1.3 Acknowledgements The bookdown package by Yihui Xie has been invaluable for producing these notes. The content of this course is dependent on the work of the R Core team, RStudio and numerous package developers, who have all made their work available for free; if I didn’t appreciate and enjoy using all these tools, I would not be teaching this course! I will cite authors as I go along, and a reference list is given at the end. Many thanks also to Allison Horst, for generously sharing her artwork. "],["r-and-rstudio.html", "Section 2 R and RStudio 2.1 Starting RStudio on the university network 2.2 The RStudio interface 2.3 Inputs and outputs 2.4 Get comfortable! 2.5 Change your Workspace settings", " Section 2 R and RStudio The programming language that we are using is called R (R Core Team 2020), but we will use a separate program, called RStudio (RStudio Team 2020), known as an “Integrated Development Environment”, to work with R. You can use R without using RStudio, but you can’t use RStudio without using R. R and RStudio are available on the university network, and you can download RStudio and R for free on your own computer. Download R Download RStudio 2.1 Starting RStudio on the university network Click on the Windows 10 icon in the bottom left corner of the screen, then search the list of programs and click on RStudio. 2.2 The RStudio interface When you first start RStudio, you should see something like this: There are three windows (a fourth will appear later), and for now, we’ll just use the one on the left, which is called the Console. The red circle drawn in the console window shows the command prompt: this is where you type in commands. 2.3 Inputs and outputs In these notes, input will be displayed in shaded boxes like this: 2 + 3 and output from R will be shown like this: ## [1] 5 (Ignore the ## symbols and the [1] for now: the output we want is the number 5: the result of the command 2 + 3.) You can copy and paste input directly from these pages into RStudio (it’s helpful to know the keyboard shortcuts for copy and paste: these are usually ctrl c and ctrl v on windows PCs, and cmd c and cmd v on macs.) You should try the commands you see here directly in RStudio, to check that they work and that you get the same results. 2.4 Get comfortable! You will be using RStudio quite a lot, so you may wish to change the appearance. Some people find dark backgrounds more comfortable for reading. From the menu bar, go to Tools &gt; Global Options Click on Appearance Change the Editor font size if you want to Try out a few themes in the Editor theme box. (The default is Textmate. I prefer Pastel on Dark). Once you find something you like (or just stick with Textmate if you are happy with the default appearance), click on OK, and continue with this tutorial. 2.5 Change your Workspace settings R has an optional setting, in which any variables and functions that you have defined are saved and reloaded each time you quit and restart. I suggest you don’t use this setting. To make sure it is switched off, go to Tools &gt; Global Options… Make sure the box Restore .RData into workspace on startup is not ticked; Set Save workspace to .RData on exit to Never The settings should look like this: References R Core Team. 2020. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/. RStudio Team. 2020. RStudio: Integrated Development Environment for r. Boston, MA: RStudio, PBC. http://www.rstudio.com/. "],["using-r-as-a-calculator.html", "Section 3 Using R as a calculator 3.1 Scientific notation 3.2 Order of operations", " Section 3 Using R as a calculator To do addition, subtraction, multiplication and division, use the symbols +, -, *, / respectively. For example, if you type 5 * 6 at the command prompt, and press return, you will see 5 * 6 ## [1] 30 The symbol ^ is used for raising a number to a power. For example, to calculate \\(2^4\\), try the following 2 ^ 4 ## [1] 16 3.1 Scientific notation Large numbers may be displayed using “scientific notation”. For example, if we calculate \\(500^3\\) in R, instead of displaying 125000000 as the result, we see 500 ^ 3 ## [1] 1.25e+08 When you see e appear within a number, read it as “multiplied by 10 to the power of”. So 1.25e+08 is read as “1.25 multiplied by 10 to the power of 8”. Exercise 3.1 Replace x with a suitable number in the following command 1 / 1000 ^ x to produce the output ## [1] 1e-09 Check your answer by trying the calculation in R. 3.2 Order of operations R will follow the BODMAS (Brackets, Orders (powers/roots), Division, Multiplication, Addition, Subtraction) rule for the order in which it will carry out calculations. Exercise 3.2 First, predict what result you would get from each of these commands. Then try them in R. 4 / 2*2 4 / (2*2) 16 ^ 1/2 16 ^ (1/2) "],["variables-and-vectors.html", "Section 4 Variables and vectors 4.1 Vectors 4.2 Subsetting vectors 4.3 Character strings 4.4 Factors 4.5 The Environment window 4.6 Further reading", " Section 4 Variables and vectors We can assign a numerical value to what we refer to as a variable, and then use the variable within various R commands. For example x &lt;- 3 defines a variable called x, which takes the value 3. We won’t see any output when you type this command, but if we type the variable name on its own, R will tell us its value: x ## [1] 3 We can then use the variable in other commands, e.g.: 2 * x ## [1] 6 4.1 Vectors We can define a vector variable using the command c(), with a list of the elements in your vector, separated by commas, inside the brackets. For example, to create a vector of the numbers 2, 4, 6, 8, 10, and assign it to a variable y type y &lt;- c(2, 4, 6, 8, 10) We can do element-wise operations with two vectors. For example: z &lt;- c(3, 5, 7, 9, 11) y + z ## [1] 5 9 13 17 21 4.1.1 Sequences of integers A convenient way to create a sequence of integers (as a vector) is to use :, for example 3:10 ## [1] 3 4 5 6 7 8 9 10 and we can assign the result to a vector variable in the usual way. x &lt;- 3:10 4.2 Subsetting vectors Suppose we have first defined a vector x: x &lt;- c(12, 14, 16, 18, 20) We use square brackets [] to extract elements of x. For example, to get the third element we do x[3] ## [1] 16 Exercise 4.1 If x has been defined as x &lt;- c(12, 14, 16, 18, 20) predict which elements of x would be returned with the following, then try these commands in R: x[2:4] x[c(1, 3, 5)] x[-4] We can also replace elements of x, for example x[2] &lt;- 0 x ## [1] 12 0 16 18 20 4.2.1 Logical subsetting Given our definition of x, if we first do x &lt;- c(12, 14, 16, 18, 20) x &lt; 15 ## [1] TRUE TRUE FALSE FALSE FALSE We see that TRUE is returned in position i, if the i-th element of x is less than 15. We can use this to extract the elements of x that satisfy the condition of being less than 15: x[x &lt; 15] ## [1] 12 14 4.3 Character strings We can make vectors whose elements are text (known as strings or character strings) rather than numbers. x &lt;- c(&quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Wednesday&quot;) x ## [1] &quot;Monday&quot; &quot;Tuesday&quot; &quot;Wednesday&quot; The quote marks \" \" are important here: if, for examle, we tried y &lt;- Monday We would get the message Error: object 'Monday' not found: R would attempt to find a variable with the name Monday, rather than assigning the string \"Monday\" to the variable y. 4.4 Factors In statistical modelling, we often work with categorical variables, for example, a patient’s symptoms might be recorded as one of “none”, “mild”, “moderate”, or “severe”. In R, we can have factor variables that are similar to strings, but which carry additional information about the possible levels. We create these with the factor() command. For example x &lt;- factor(c(&quot;mild&quot; ,&quot;mild&quot;, &quot;none&quot;, &quot;severe&quot;)) x ## [1] mild mild none severe ## Levels: mild none severe Note that when we display our vector of factors x, we do not see quotes, and the levels are are also displayed. When defining a factor, it may be helpful to specify all the possible levels, even if some levels have not been observed. We specify these in the factor command: x &lt;- factor(c(&quot;mild&quot; ,&quot;mild&quot;, &quot;none&quot;, &quot;severe&quot;), levels = c(&quot;none&quot;, &quot;mild&quot; ,&quot;moderate&quot;, &quot;severe&quot;)) x ## [1] mild mild none severe ## Levels: none mild moderate severe (Note that the first two lines in the input display are a single command: the line break after the first comma is ignored by R.) 4.5 The Environment window In RStudio, you can see all the variables defined in your workspace in the Environment window. The Environment window will also list any data sets and functions that you have created; you can click on these for more details. Exercise 4.2 Suppose we want to create a vector called responses with three elements: yes, no and no. Create the vector responses as a vector of character strings. How would you define responses, if you instead wanted it to be a factor, with levels yes, no and undecided? 4.6 Further reading Strings can be quite difficult to work with. For example, the character strings \"Monday\", \"monday\", \"Mon\" might all be intended to mean the same thing, but R will not treat them as being equal to each other: &quot;Monday&quot; == &quot;monday&quot; ## [1] FALSE We will study working with strings in a later section, but see also Chapter 14 of R for Data Science "],["functions.html", "Section 5 Functions 5.1 Introducing functions 5.2 Arguments 5.3 Help files", " Section 5 Functions 5.1 Introducing functions (We’ve been using some functions already, but we’ll now discuss these explicitly). R has lots of functions we can use for doing various things (and you can even create your own). For example, the function mean() will calculate the arithmetic mean of the elements of a vector: x &lt;- 1:10 mean(x) ## [1] 5.5 5.2 Arguments Functions typically have various arguments that we can either specify, or leave unspecified, in which case they will take default values. For example, if we do y &lt;- c(5, 10, 6, 11, 7, 12) sort(y) ## [1] 5 6 7 10 11 12 then we can see that sort(y) has sorted the elements of y into increasing order. To sort them into decreasing order, we add an argument decreasing = TRUE: sort(y, decreasing = TRUE) ## [1] 12 11 10 7 6 5 5.2.1 Experiment! It’s a good idea to experiment with function arguments, to understand how a function works. For example, try this command seq(from = 0, to = 10, length = 11) ## [1] 0 1 2 3 4 5 6 7 8 9 10 then experiment with changing the numbers for the three arguments from, to and length. Try to predict what the effect of any change will be, before running the command. 5.3 Help files All functions have help files, which tell you a bit more about how the function works, and often provide examples. Use a ? with the function name: ?sort Help files can be a little overwhelming! If you scroll to the end of a help file, there are usually some examples you can try: trying the examples can often help you to understand how a function works. Exercise 5.1 Suppose a 6-sided dice is rolled once. Try the command sample(1:6, size = 1) to get R to simulate the dice roll. Use the up arrow key on your keyboard to bring up the command again, and press return. Do this a few times to check that you get different results each time. Now suppose the 6-sided dice is rolled six times. Try changing the size argument to 6: sample(1:6, size = 6) Run the command above a few times (again, use the up arrow on your keyboard, so you don’t have to keep typing it.) Something about the results you get should look odd. Look at the help file for sample, and see what that default arguments are. What do you need to change, to get more ‘realistic’ behaviour when simulating 6 dice rolls? "],["data-frames-tibbles-and-lists.html", "Section 6 Data frames, tibbles and lists 6.1 Data frames 6.2 tibbles 6.3 Inspecting large data frames and tibbles 6.4 Lists 6.5 Further reading", " Section 6 Data frames, tibbles and lists 6.1 Data frames Data sets in R are organised in data frames. R has various built-in data frames that we can use as illustrations, for example, mtcars. The full data set has 32 rows, but we will just display the first 6, using the head() function head(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 Each column has a name (mpg, cyl, etc.) which can be used to access the values in that column. The rows in this data frame are also named, but that is optional, and we usually select particular rows by their row number. The mtcars data frame has columns of numeric quantities only (though some columns are really dummy variables to represent factors), but is common for data frames to have a mix of variable types, for example, in the CO2 data frame we have head(CO2) ## Plant Type Treatment conc uptake ## 1 Qn1 Quebec nonchilled 95 16.0 ## 2 Qn1 Quebec nonchilled 175 30.4 ## 3 Qn1 Quebec nonchilled 250 34.8 ## 4 Qn1 Quebec nonchilled 350 37.2 ## 5 Qn1 Quebec nonchilled 500 35.3 ## 6 Qn1 Quebec nonchilled 675 39.2 The built-in data frames have help files with more information: try ?mtcars for example. Built-in data frames are useful when giving examples, or asking for help online: everyone will have them, so code using a built-in data frame can be easy for others to run. 6.1.1 Making data frames A data frame can be made within R using the function data.frame(), but more commonly, we’ll be making data frames by importing data into R (e.g. .csv files). We’ll cover this in a later section. 6.1.2 Extracting rows and columns Extracting data from data frames can be confusing, in that there are multiple ways to do it, and the format of the result (e.g. a vector or another data frame) can vary. For now, one syntax for extracting a column is dataframe-name$column-name, for example: mtcars$cyl ## [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4 and a complete row can be extracted using its position (row number): mtcars[2, ] ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 Wag 21 6 160 110 3.9 2.875 17.02 0 1 4 4 We’ll look more at extracting subsets of data frames later on. 6.2 tibbles A tibble is a special type of data frame (Müller and Wickham 2020). When we view a tibble, R will normally only show the first 10 rows, and as many columns as can be fitted in the screen (but R will tell us if there are more columns). For example, a tibble version of the mtcars data frame would look like this: ## # A tibble: 32 × 11 ## mpg cyl disp hp drat wt qsec vs am gear carb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 ## 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 ## 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 ## 4 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 ## 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 ## 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 ## 7 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 ## 8 24.4 4 147. 62 3.69 3.19 20 1 0 4 2 ## 9 22.8 4 141. 95 3.92 3.15 22.9 1 0 4 2 ## 10 19.2 6 168. 123 3.92 3.44 18.3 1 0 4 4 ## # ℹ 22 more rows Line three tells us what data type we have in each column. (&lt;dbl&gt; is short for “double precision”, a numeric variable type). In this module, it won’t make any difference whether our data are in a tibble format or ‘standard’ data frame, but there are some situations where they behave differently. If we want to force R to display all the rows of a tibble, we can use the print function: mtcarsTibble &lt;- tibble::tibble(mtcars) print(mtcarsTibble, n = nrow(mtcarsTibble)) 6.3 Inspecting large data frames and tibbles If we have a large number of columns in a data frame or tibble in R, it can be difficult to see exactly what data we’ve got. (The default display of a large tibble can still be overwhelming.) The str() function can be useful here (and will work with any type of R object): str(mtcars) ## &#39;data.frame&#39;: 32 obs. of 11 variables: ## $ mpg : num 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ... ## $ cyl : num 6 6 4 6 8 6 8 4 4 6 ... ## $ disp: num 160 160 108 258 360 ... ## $ hp : num 110 110 93 110 175 105 245 62 95 123 ... ## $ drat: num 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ... ## $ wt : num 2.62 2.88 2.32 3.21 3.44 ... ## $ qsec: num 16.5 17 18.6 19.4 17 ... ## $ vs : num 0 0 1 1 0 1 0 1 1 1 ... ## $ am : num 1 1 1 0 0 0 0 0 0 0 ... ## $ gear: num 4 4 4 3 3 3 3 4 4 4 ... ## $ carb: num 4 4 1 1 2 1 4 2 2 4 ... A similar function, with slightly different output, is tibble::glimpse(mtcars) ## Rows: 32 ## Columns: 11 ## $ mpg &lt;dbl&gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,… ## $ cyl &lt;dbl&gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8,… ## $ disp &lt;dbl&gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16… ## $ hp &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180… ## $ drat &lt;dbl&gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,… ## $ wt &lt;dbl&gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.… ## $ qsec &lt;dbl&gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18… ## $ vs &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,… ## $ am &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,… ## $ gear &lt;dbl&gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3,… ## $ carb &lt;dbl&gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2,… 6.4 Lists We’ll briefly mention another type of object known as a list. Whereas a data frame is essentially a table, combining columns of the same length, a list is a more general collection of objects, which can vary in size and type. For example, we can create a list as follows: mylist &lt;- list(a = 1:10, b = &quot;Monday&quot;) We can view the names of the objects inside a list with the command names(mylist) ## [1] &quot;a&quot; &quot;b&quot; and access objects inside the list with the $ operator: mylist$b ## [1] &quot;Monday&quot; A data frame behaves like a list: it is a list of columns (although there are extra things you can do with data frames that you can’t do with lists.) Exercise 6.1 The data frame morley contains data from experiments measuring the speed of light. Find the mean recorded speed of light, for all 100 observations. 6.5 Further reading At some point, it is worth understanding in more detail how subsetting works. A good reference is Chapter 4 of Advanced R (Wickham, 2019). References Müller, Kirill, and Hadley Wickham. 2020. Tibble: Simple Data Frames. https://CRAN.R-project.org/package=tibble. "],["scripts.html", "Section 7 Scripts 7.1 Creating a new script 7.2 Entering and running commands 7.3 Adding comments and sections in scripts 7.4 Line breaks in scripts 7.5 Saving a script", " Section 7 Scripts We’re reaching the point of wanting to use multiple commands in one go, and typing commands directly into the command prompt won’t be very convenient: it will be difficult to save your work; it’s awkward if you make any mistakes. A more convenient way to work with R is to use scripts. A script file is a list of commands, that is easier to edit, save, and run. 7.1 Creating a new script You can either select File &gt; New File &gt; R Script from the menu bar, or you can click on the icon in the top left corner and select R script. A new blank window will appear: this is your script window, where you can now enter commands. 7.2 Entering and running commands You can type R commands in to your script window, as you did in the console, but when you press return, nothing will happen. To get R to run a single line, click on that line so that the cursor is on that line, then click on Run at the top of the script window. To get R to run multiple lines at once, highlight all the lines with the mouse, then click on Run. To see what value a particular variable is, after you have run the line in which the variable is defined, highlight the variable name only, and then click on Run. Output will appear in the Console window, as before. 7.3 Adding comments and sections in scripts Use the # symbol to start a ‘comment line’: any text on that line will be ignored by R. Adding comments to your script can make it a little easier to read. You can also make a ‘section’ by adding four minus signs after your comment. These sections can be ‘collapsed’ and expanded again in RStudio, by clicking on the little arrow next to the line number. From now on, put all your solutions to the exercises in a script, and start each section with a comment giving the exercise number 7.4 Line breaks in scripts If we use a function with several arguments, and some of the arguments are quite long, it may be easier to read if we use a new line for each argument. The previous line must end with a comma , and then R will understand that the function continues on to the next line. For example, sample(1:6, size = 6, replace = TRUE) can be written as sample(1:6, size = 6, replace = TRUE) 7.5 Saving a script Go to File &gt; Save As.. to save your script. Exercise 7.1 First, outside of RStudio, create a new folder with this module code on your computer (use your U: drive if you are on the university network). Create a new script file Copy and paste these commands into the script x &lt;- sample(2 * 1:10, size = 1) y &lt;- sample(2 * 1:10, size = 1) x * y Run these three commands in the script window. Without typing any more commands into the script or console windows, find out the values of x and y (highlight something appropriate and click on the run button.) Save your script in your folder. I suggest you make one new script file per section for the exercises in Sections 11-15. "],["a-tip-for-understanding-r-code.html", "Section 8 A tip for understanding R code", " Section 8 A tip for understanding R code When you see a section of R code, it may not be obvious what the code does (although you can sometimes guess from the function names). Consider x &lt;- rep(2:4, each = 3) sum(unique(x)) ## [1] 9 How did R get the result 9? It can sometimes help to run sections of the code, to see what each bit does: you can then see the individual steps that get to the result. In particular, you might run sections within a single line. We first see what the variable x is: x ## [1] 2 2 2 3 3 3 4 4 4 We can see that the numbers 2, 3, 4 have been repeated (using rep()) three times each. Then we can see what unique(x) does unique(x) ## [1] 2 3 4 This gets rid of the duplicates in the vector x. So we can see that the last line is working out the sum of 2, 3, 4. "],["packages.html", "Section 9 Packages 9.1 Installing a package 9.2 Updating packages 9.3 Using packages 9.4 Is there a package for…?", " Section 9 Packages R has a large number of packages available (over 16,000 at the time of writing). R packages typically contain extra functions based around some theme (e.g. a collection of functions to enable you to fit a particular type of statistical model.) Some packages come pre-installed with R, and others need to be installed manually. 9.1 Installing a package Use the command install.packages() to install a package. If the package you want requires other packages, R will install them too, so installation can take a while! During the installation process, you may get a message along the lines of ...There are binary versions available but the source versions are later. Do you want to install from sources the package which needs compilation? Answering n (for no) is usually safe, in case your computer isn’t set up for installing packages ‘from source’. As an example, we’ll install the zoo package, which has some helpful functions for working with time series data. install.packages(&quot;zoo&quot;) Do not put an install.packages() command in a script or R Markdown document: use the command in the console only. (You do not want to be repeatedly installing a package, or should you share a script/R Markdown document with someone else, for your documents to be installing software on other people’s computers.) 9.2 Updating packages It’s worth occasionally checking for package updates. In particular, if a package you’re using doesn’t appear to be working properly, look to see if there’s an update. In RStudio, click on the Packages tab, and then click on Update to see what’s available. 9.3 Using packages A package only needs to be installed once, but you need to load the package every time you start R, or use the :: syntax. For example, the zoo package has a function rollmean() for computing rolling means (e.g. mean at time \\(t\\) of the most recent 4 observations up to time \\(t\\)). As an example, suppose we have a vector x: x &lt;- 10:20 We can either use the syntax package-name::function. zoo::rollmean(x, k = 4) ## [1] 11.5 12.5 13.5 14.5 15.5 16.5 17.5 18.5 or we can first do library(zoo) ## Warning: package &#39;zoo&#39; was built under R version 4.4.2 ## ## Attaching package: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric and then any function within the package can be used directly: rollmean(x, k = 4) ## [1] 11.5 12.5 13.5 14.5 15.5 16.5 17.5 18.5 For some packages (e.g. ggplot2), it will be obvious from the commands what package is being used. Otherwise, I recommend you use the :: syntax as it will make your code easier to read; it can be helpful to be explicit about which package a function has come from. 9.4 Is there a package for…? If you’re searching for a package to do something, one simple approach is to include “R CRAN” in your web search, e.g. you might search for R CRAN lasso if you were looking for a package to implement the lasso. (CRAN is the main repository for R packages). You could also try browsing the CRAN Task Views. These discuss some of the packages that are available for particular topics (e.g Bayesian inference, machine learning, time series analysis etc.) "],["rstudio-projects.html", "Section 10 RStudio Projects 10.1 File paths and working directories 10.2 Creating a new project 10.3 Opening an existing project 10.4 Using your project folder", " Section 10 RStudio Projects RStudio Projects can be helpful for organising your files. If you are working on more than one project using R, RStudio Projects make it easier to keep your work for each project separate, and to find the files you need each time you start up R. 10.1 File paths and working directories We’ll discuss importing data in a later section, but it’s helpful at this point to understand the idea of a working directory in relation to your data files (RStudio Projects make the whole process easier to manage.) Suppose you have a data file myData.csv you want to import. How will R find this file? R will have a current working directory, which you can see with the command getwd() If your file myData.csv is in this folder, you can import it with the command read_csv(&quot;myData.csv&quot;) R will look in the current working directory, and find your file. If your data files is in a different folder, three options are Specify the full file path to your data file, e.g. something like read_csv(&quot;/Users/Jeremy/Documents/MPS4110/myData.csv&quot;) Change your working directory to the folder containing the data file, using Session &gt; Set Working Directory &gt; Choose Directory… from the RStudio menu bar. If possible, specify the file path relative to your current working directory, e.g. if your current working directory is /Users/Jeremy/Documents, and the data file is in a subfolder of Documents called MPS4110, you could use the command read_csv(&quot;MPS4110/myData.csv&quot;) Option 3 is recommended, as it make things a bit easier if you want to transfer your work between different computers, or share code and data with others. But this all gets messy if you’re working on different projects, and you want to keep your files nicely organised on your computer. As we’ll see, RStudio projects become useful here. 10.2 Creating a new project You can create different types of projects, but for a ‘basic’ one, go to File &gt; New Project…&gt; New Directory &gt; New Project &gt; Browse then choose a folder on your computer in which you wish to locate your project, then choose a project name and click create project. This will create a subfolder, within your selected folder. The subfolder will have your project name. The subfolder will contain a .Rproj file, which identifies the project. From a file explorer, you should be able to click on this and launch RStudio with the project open. You can also use the Project menu of the right hand side of the RStudio window. 10.3 Opening an existing project You can either go to File &gt; Open Project… and find your .Rproj file, or you can use the Project menu at the top right. When you open a project, RStudio will set the working directory to that project folder, and open any files you were working on the last time you worked on that project. The Files tab in RStudio will display your project folder, and there are various tools in this tab for working with your files. Depending on your settings, RStudio may open your most recent project, if you were working on it the last time you used RStudio. You can close a project using the Project menu. 10.4 Using your project folder In your new project folder, you should keep all files associated with that project. You might create further subfolders within your project folder. For example, it’s a good idea to have a ‘data’ folder, containing any data sets used in your project. You might have another subfolder for R scripts. These will all be subfolders of the project working directory, which makes them Exercise 10.1 If you don’t have one already, create a folder on your computer for this module. (I suggest you name it MPS4110.) Within that folder, create a new RStudio Project with the name R Tutorial. In your project folder, create a new folder called data. Download the tutorial data sets zip file, and put the contents of this zip file in your data folder. (Do this in a file explorer, outside of RStudio) Use the Files tab in RStudio to check that the data files are there. In the Console window, check the current working directory that RStudio is using, by running the command getwd() If you’ve completed the exercise correctly you should be able to open your project and see something like the following. "],["the-tidyverse.html", "Section 11 The Tidyverse", " Section 11 The Tidyverse The Tidyverse (Wickham et al. 2019), (Wickham 2019b) is a collection of R packages designed for data science. (Artwork by @allison_horst) We’ll be using tidyverse packages quite a lot from now on. Install the package with the command install.packages(&quot;tidyverse&quot;) When you run the command library(tidyverse) ## Warning: package &#39;tidyverse&#39; was built under R version 4.4.2 ## Warning: package &#39;ggplot2&#39; was built under R version 4.4.2 ## Warning: package &#39;tibble&#39; was built under R version 4.4.2 ## Warning: package &#39;tidyr&#39; was built under R version 4.4.2 ## Warning: package &#39;readr&#39; was built under R version 4.4.2 ## Warning: package &#39;purrr&#39; was built under R version 4.4.2 ## Warning: package &#39;dplyr&#39; was built under R version 4.4.2 ## Warning: package &#39;stringr&#39; was built under R version 4.4.2 ## Warning: package &#39;forcats&#39; was built under R version 4.4.2 ## Warning: package &#39;lubridate&#39; was built under R version 4.4.2 this will load the packages ggplot2, dplyr, tidyr, readr, purr, tibble, stringr, forcats. There are other packages included in the tidyverse installation which need loading explicitly if you want to use them, e.g. readxl. If you want to use the :: syntax with a ‘tidyverse function’, you have to know which package within the tidyverse the function belongs to. For example, the command library(tidyverse) will enable you to use the read_csv() command, but this command is actually part of the readr package within the tidyverse, so the correct syntax would be readr::read_csv(), not tidyverse::read_csv(). References ———. 2019b. Tidyverse: Easily Install and Load the ’Tidyverse’. https://CRAN.R-project.org/package=tidyverse. Wickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686. "],["importing-combining-and-reshaping-data.html", "Section 12 Importing, combining, and reshaping data 12.1 Importing a .csv file 12.2 Importing an Excel .xlsx file 12.3 Importing a plain text file 12.4 Importing online data 12.5 Working with column names 12.6 Combining data frames 12.7 Renaming columns 12.8 Importing data from other statistical packages 12.9 Reshaping data frames 12.10 Exercises 12.11 Data sources 12.12 Further reading", " Section 12 Importing, combining, and reshaping data In this section we look at how to import data such as Excel spreadsheets and .csv files; combine different data sets into a single data frame; reshape data frames between ‘long’ and ‘wide’ formats (this is useful for plots with ggplot2) When working with someone else’s data, the data almost certainly won’t be in the format that you need; you’ll need to do some editing/re-arranging of the data. If possible, do not make any edits to the original data file: do any editing you need inside R. That way, you will have a record of how you got from the original data file to the data you actually worked with in your analysis. As an example, we’ll import the two files RIOolympics.csv and population.xlsx, and make a single data frame with medal results and population size for each country. We suppose that in your current working directory, you have a folder called data, and the two files we want to import are in that folder. First load the tidyverse library library(tidyverse) 12.1 Importing a .csv file Use the command read_csv(), with the path to your target file in quotes (if you can, use the path relative to your project directory). This command is from the readr package (Wickham, Hester, and Francois 2018). We’ll import the RIOolympics.csv file and store it as a data frame called medals. medals &lt;- read_csv(&quot;data/RIOolympics.csv&quot;) ## Rows: 87 Columns: 6 ## ── Column specification ───────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (2): code, country ## dbl (4): gold, silver, bronze, total ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. To view the first few rows: head(medals) ## # A tibble: 6 × 6 ## code country gold silver bronze total ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 USA UNITED STATES 46 37 38 121 ## 2 GBR GREAT BRITAIN 27 23 17 67 ## 3 CHN CHINA 26 18 26 70 ## 4 RUS RUSSIAN FEDERATION 19 18 19 56 ## 5 DEU GERMANY 17 10 15 42 ## 6 JPN JAPAN 12 8 21 41 12.1.1 Additional arguments Use ?read_csv to see the full list of arguments. Two useful ones are skip: use this to skip lines at the start of the .csv file, for example if there’s some text that you need to ignore; col_names: you will normally use the default value TRUE, but you can specify a character vector of column names if you want/need to. 12.2 Importing an Excel .xlsx file We can import Excel files with the command readxl::read_excel(). The readxl package (Wickham and Bryan 2019) is installed as part of the tidyverse, but not loaded by the command library(tidyverse). We’ll import the population.xlsx file and store it as a data frame called population: population &lt;- readxl::read_excel(&quot;data/population.xlsx&quot;) head(population) ## # A tibble: 6 × 3 ## `Country Name` `Country Code` `2015` ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Aruba ABW 103889 ## 2 Andorra AND 70473 ## 3 Afghanistan AFG 32526562 ## 4 Angola AGO 25021974 ## 5 Albania ALB 2889167 ## 6 Arab World ARB 392022276 12.2.1 Additional arguments Again, there are lots of extra arguments, but two particularly useful ones are sheet, for specifying which sheet to import, if the Excel file contains multiple sheets; range, for specifying which cells to import, e.g. \"B3:G10\", if we want to ignore the first column and first two rows. 12.3 Importing a plain text file We can import plain text files (typically files with a .txt extension) with the command read_table(). For example, in the MPS4110Data.zip file, there is a file flintsdata.txt. Although the file is a plain text file, the data appear formatted as a two-column table, with headers breadth and length. We import the data (and create a new data frame called flints) as follows. flints &lt;- read_table(&quot;data/flintsdata.txt&quot;) ## ## ── Column specification ───────────────────────────────────────────────────────────────────────────────────── ## cols( ## breadth = col_double(), ## length = col_double() ## ) head(flints) ## # A tibble: 6 × 2 ## breadth length ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1.97 4.37 ## 2 2.44 5.43 ## 3 2.22 5 ## 4 2.1 4.38 ## 5 2.43 5.45 ## 6 2.5 5.8 As with the other functions for importing data, there are useful arguments for skipping lines, defining column names and so on. See ?read_table for details. 12.4 Importing online data If you are online, R can read in data directly from the web: you just give the full web address as the file name, e.g. maths &lt;- read_csv(&quot;https://oakleyj.github.io/exampledata/maths.csv&quot;) This can be convenient, though it may slow down your code if the file is large, and there is a risk that your code won’t run in the future: you can’t be sure that the file will always be there! Nevertheless, downloading a data file via R (or another language) is preferable to clicking buttons/links on a website, as you will have a record of where you got the data from. We recommend that you download your data with R, but then save a copy on your computer, and that your analysis uses your copied version. We can export data from R to a external file, e.g. csv format with the write_csv() command, e.g. write_csv(maths, path = &quot;data/myCopyOfMaths.csv&quot;) We can also use the download.file() command, which downloads and saves the file, but doesn’t keep the data within R: download.file(url = &quot;https://oakleyj.github.io/exampledata/maths.csv&quot;, destfile = &quot;data/myCopyOfMaths.csv&quot;) 12.5 Working with column names All three column names in population are awkward to work with! Two of them have spaces in, and third is a number. If we wanted to access individual columns, none of the following commands would work! population$Country Name population$Country Code population$2015 Use backticks around any awkward column names: population$`Country Name` population$`Country Code` population$`2015` 12.6 Combining data frames When we combine two data frames, we will either be adding variables to a data set; we add columns to a data frame; adding observations of the same variables to a data set; we add rows to a data frame. 12.6.1 Adding columns Suppose we want to add the population sizes to the data in the medal table: we want to combine the olympics and population data frames. To do this, we need one column in each data frame where the same values are used to identify the countries. We can use the columns population$`Country Code` medals$code (both columns use “ISO 3166-1 alpha-3” for identifying countries). We will use the function inner_join() which will look for countries present in both data frames (there are variations: see ?inner_join for details), storing the result in a new data frame called olympics: olympics &lt;- inner_join(medals, population, by = c(&quot;code&quot; = &quot;Country Code&quot;)) head(olympics) ## # A tibble: 6 × 8 ## code country gold silver bronze total `Country Name` `2015` ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 USA UNITED STATES 46 37 38 121 United States 3.21e8 ## 2 GBR GREAT BRITAIN 27 23 17 67 United Kingdom 6.51e7 ## 3 CHN CHINA 26 18 26 70 China 1.37e9 ## 4 RUS RUSSIAN FEDERATION 19 18 19 56 Russian Federation 1.44e8 ## 5 DEU GERMANY 17 10 15 42 Germany 8.14e7 ## 6 JPN JAPAN 12 8 21 41 Japan 1.27e8 We used the argument by = c(“code” = “Country Code”) to specify which columns in the two data frames to use for matching the observations. If both columns already had the same name, e.g. code, we could just use the argument by = “code”. 12.6.2 Adding rows The rbind() function can be used to combine data frames with the same column headings. Here’s a simple example: df1 &lt;- data.frame(x = c(10, 11), y = c(100, 101)) df2 &lt;- data.frame(x = c(12, 13), y = c(102, 103)) rbind(df1, df2) ## x y ## 1 10 100 ## 2 11 101 ## 3 12 102 ## 4 13 103 12.6.3 Data frames from lists Continuing the example above, if we have a list of data frames, again with the same column headings, these can be assembled into a data frame as follows. myList &lt;- list(df1, df1) do.call(rbind.data.frame, myList) ## x y ## 1 10 100 ## 2 11 101 ## 3 10 100 ## 4 11 101 12.7 Renaming columns The column name 2015 isn’t very descriptive, so we may wish to change the name, for example to population2015. We can do this with the rename() command. olympics &lt;- rename(olympics, population2015 = `2015`) head(olympics) ## # A tibble: 6 × 8 ## code country gold silver bronze total `Country Name` population2015 ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 USA UNITED STATES 46 37 38 121 United States 321418820 ## 2 GBR GREAT BRITAIN 27 23 17 67 United Kingdom 65138232 ## 3 CHN CHINA 26 18 26 70 China 1371220000 ## 4 RUS RUSSIAN FEDERAT… 19 18 19 56 Russian Feder… 144096812 ## 5 DEU GERMANY 17 10 15 42 Germany 81413145 ## 6 JPN JAPAN 12 8 21 41 Japan 126958472 (Note that in assigning the result to a data frame called olympics, we’ve overwritten our earlier version of the olympics data frame. In general, be careful when you do this: the command will work the first time we use it, but not the second!) 12.8 Importing data from other statistical packages You may come across data sets stored in a format specific to another statistical package (SAS, SPSS, Stata). The haven package (Wickham and Miller 2020) can be used to import these. See https://haven.tidyverse.org/ for more details. 12.9 Reshaping data frames Sometimes a data set may be in the wrong ‘shape’ for the analysis or plot that we want to do. As an example, we’ll use an extended data set on populations, with observations in multiple years: countries &lt;- read_csv(&quot;data/populationMultiple.csv&quot;) ## Rows: 264 Columns: 4 ## ── Column specification ───────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (1): Country Name ## dbl (3): 2013, 2014, 2015 ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. head(countries) ## # A tibble: 6 × 4 ## `Country Name` `2013` `2014` `2015` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Aruba 102921 103441 103889 ## 2 Andorra 75902 72786 70473 ## 3 Afghanistan 30682500 31627506 32526562 ## 4 Angola 23448202 24227524 25021974 ## 5 Albania 2896652 2893654 2889167 ## 6 Arab World 376504253 384222592 392022276 For our analysis, we may need all population values in a single column, with another column indicating the year. We can use the function pivot_longer() from the tidyr package (Wickham and Henry 2020) to change the data frame from ‘wide’ to ‘long’ format: countriesLong &lt;- pivot_longer(countries, cols = -`Country Name`, names_to = &quot;year&quot;, values_to = &quot;population&quot;) head(countriesLong) ## # A tibble: 6 × 3 ## `Country Name` year population ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Aruba 2013 102921 ## 2 Aruba 2014 103441 ## 3 Aruba 2015 103889 ## 4 Andorra 2013 75902 ## 5 Andorra 2014 72786 ## 6 Andorra 2015 70473 If we think of population as our ‘dependent variable’, the cols argument specifies which columns are used to create this dependent variable. Here, putting the - sign before Country Name means “use all columns except this one”. If every column represented a ‘dependent variable’, we could use the argument cols = everything(). names_to and values_to refer to the column names we want to use in the new data frame, not column names in the current data frame we are reshaping. It’s worth looking at the help file for pivot_longer() to see more examples. We can go back from ‘long’ to ‘wide’ with the function pivot_wider() countriesWide &lt;- pivot_wider(countriesLong, names_from = year, values_from = population) head(countriesWide) ## # A tibble: 6 × 4 ## `Country Name` `2013` `2014` `2015` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Aruba 102921 103441 103889 ## 2 Andorra 75902 72786 70473 ## 3 Afghanistan 30682500 31627506 32526562 ## 4 Angola 23448202 24227524 25021974 ## 5 Albania 2896652 2893654 2889167 ## 6 Arab World 376504253 384222592 392022276 12.10 Exercises Exercise 12.1 Merging and reshaping data. The files BrexitVotes.csv and education.csv contain, respectively, data from the 2016 UK referendum on leaving the European Union, and data on proportions of adults with educational qualifications at ‘level 4’ and above (qualifications above A-level). Data are given for local authorities within the UK. Import these two files into R, and combine them into a single data frame called Brexit, matching the observations by area codes. The file cancer.xlsx contains survival times for patients with cancers in different organs. Each number in each column corresponds to a different patient; the row number has no meaning here. Note that all columns are ‘dependent variables’ here. Import the data into R. Reshape the data into ‘long format’: one column indicating the organ, and one column indicating the survival time. For any online data set you work with, make an R script/R Markdown document with a name such as makeData.R that imports the data file and does all the cleaning/editing. In this file, include the website details and url, and the date you accessed the data: you’ll need these for referencing. 12.11 Data sources Brexit results obtained from the Electoral Commission (https://www.electoralcommission.org.uk/find-information-by-subject/elections-and-referendums/past-elections-and-referendums/eu-referendum), and Level 4 qualification data obtained from the Office for National Statistics (https://www.nomisweb.co.uk/). Accessed 12th December 2017. I downloaded the cancer data a long time ago (2009?) from the “Data and Story Library” at http://lib.stat.cmu.edu/DASL/DataArchive.html. This link no longer works; I think the Data and Story Library has migrated to https://dasl.datadescription.com/, but I couldn’t find this data set there. Population data obtained from The World Bank. Accessed 6th October 2015. Medal table obtained from https://www.rio2016.com/en/medal-count-country [Accessed on 6th October 2016, but this link is no longer active.] 12.12 Further reading The concepts of “long” and “wide” data formats are related to the idea of tidy data, which is an important theme in the Tidyverse. For more discussion, see this vignette, and Chapter 12 of R for Data Science. References Wickham, Hadley, and Jennifer Bryan. 2019. Readxl: Read Excel Files. https://CRAN.R-project.org/package=readxl. Wickham, Hadley, and Lionel Henry. 2020. Tidyr: Tidy Messy Data. https://CRAN.R-project.org/package=tidyr. Wickham, Hadley, Jim Hester, and Romain Francois. 2018. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr. Wickham, Hadley, and Evan Miller. 2020. Haven: Import and Export ’SPSS’, ’Stata’ and ’SAS’ Files. https://CRAN.R-project.org/package=haven. "],["data-handling-with-dplyr.html", "Section 13 Data handling with dplyr 13.1 Chaining commands together with the pipe operator %&gt;% 13.2 Example 13.3 Ordering the rows by a variable with the arrange() command 13.4 Selecting rows with the filter() command 13.5 Viewing and extracting data from a column 13.6 Creating new columns in a data frame with the mutate() command 13.7 Computing summaries per group 13.8 Counting observations within groups 13.9 Further reading", " Section 13 Data handling with dplyr Once we have our data in a single data frame, we might wish to obtain some simple summary statistics, perhaps within subgroups of the data, and/or understand the structure of the data better (e.g. counting how many observations we have for particular combinations of factors.) This might involve creating new columns, with values dependent on the other columns. The package dplyr (Wickham, François, et al. 2020) has various functions for working with data frames, and we will illustrate some here. (Artwork by @allison_horst) 13.1 Chaining commands together with the pipe operator %&gt;% We’ll first introduce the ‘pipe operator’ %&gt;%. (It’s a matter of personal preference whether you use it in your code or not, but you may find it makes your code easier to read.) The pipe operator %&gt;% takes whatever the output is from the left hand side, and uses it as the first argument in the function on the next line. In general, myfunction(x, y) can be written using the pipe operator as x %&gt;% myfunction(y) so, for example, from the previous chapter inner_join(medals, population, by = c(&quot;code&quot; = &quot;Country Code&quot;)) would be written as medals %&gt;% inner_join(population, by = c(&quot;code&quot; = &quot;Country Code&quot;)) Code with pipes can be easier to read, particularly when multiple functions are chained together. For example, this code x0 %&gt;% func1(x1) %&gt;% func2(x2) %&gt;% func3(x3) %&gt;% func4(x4) would be read as start with x0, then apply function func1() to it with additional argument x1, then apply the function func2() to the result, using additional argument x2, and so on Alternatives without pipes would be func4(func3(func2(func1(x0, x1), x2), x3), x4) which would be harder to read, or y1 &lt;- func1(x0, x1) y2 &lt;- func2(y1, x2) y3 &lt;- func3(y2, x3) func4(y3, x4) which may be undesirable if we don’t want to store all the intermediate variables y1, y2, y3. 13.2 Example We’ll be using the data maths.csv, which is included in the data sets zip file: maths &lt;- read_csv(&quot;data/maths.csv&quot;) This is a data set of maths scores from the PISA 2015 maths tests, with data obtained from OECD and the World Bank1. In addition to country and continent, there are the following columns. score: the mean mathematics score in the 2015 PISA test; gdp: the gross domestic product per capita (GDP divided by the estimated population size), measured in US\\(\\$\\); gini: the Gini coefficient (as a percentage). This is an estimate of income inequality, with larger values indicating more income inequality; homework: an estimate of the average number of hours per week spent on homework by 15 year-olds, from a survey in 2012; start.age: the age (in years) in which children start school. 13.3 Ordering the rows by a variable with the arrange() command Suppose we want to see which countries got the highest score: we want to arrange the rows in the data frame maths in order according to the values in the column score. To do this we use the command maths %&gt;% arrange(score) ## # A tibble: 70 × 7 ## country continent score gdp gini homework start.age ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Dominican Republic North America 328 6722 44.9 NA 6 ## 2 Algeria Africa 360 3844 27.6 NA 6 ## 3 Tunisia Africa 367 3689 35.8 3.5 6 ## 4 Macedonia, FYR Europe 371 5237 35.6 NA 6 ## 5 Brazil South America 377 8650 51.3 3.3 6 ## 6 Jordan Asia 380 4088 33.7 4.2 6 ## 7 Indonesia Asia 386 3570 39.5 4.9 7 ## 8 Peru South America 387 6046 44.3 5.5 6 ## 9 Colombia South America 390 5806 51.1 5.3 6 ## 10 Lebanon Asia 396 7914 31.8 3.3 6 ## # ℹ 60 more rows This has arranged the rows in ascending order of score. To see them in descending order, we include the desc() command: maths %&gt;% arrange(desc(score)) ## # A tibble: 70 × 7 ## country continent score gdp gini homework start.age ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Singapore Asia 564 52961 NA 9.4 6 ## 2 Hong Kong SAR, China Asia 548 43681 NA 6 6 ## 3 Macao SAR, China Asia 544 73187 NA 5.9 6 ## 4 Japan Asia 532 38894 32.1 3.8 6 ## 5 B-S-J-G (China) Asia 531 8123 42.2 13.8 6 ## 6 Korea, Rep. Asia 524 27539 31.6 2.9 6 ## 7 Switzerland Europe 521 78813 32.5 4 7 ## 8 Estonia Europe 520 17575 34.6 6.9 7 ## 9 Canada North America 516 42158 34 5.5 6 ## 10 Netherlands Europe 512 45295 28.6 5.8 6 ## # ℹ 60 more rows 13.4 Selecting rows with the filter() command If we want to view a subset of the rows, we can use the filter() command. For example, if we want the rows in the data frame maths where start.age takes the value 5 (i.e. children start school at age 5), we can do maths %&gt;% filter(start.age == 5) ## # A tibble: 6 × 7 ## country continent score gdp gini homework start.age ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Australia Oceanea 494 49928 34.7 6 5 ## 2 Ireland Europe 504 61606 31.9 7.3 5 ## 3 Malta Europe 479 25058 NA NA 5 ## 4 New Zealand Oceanea 495 39427 NA 4.2 5 ## 5 Trinidad and Tobago North America 417 15377 40.3 NA 5 ## 6 United Kingdom Europe 492 39899 34.1 4.9 5 Note the double equals sign ==. This is used to test whether the left and right hand sides are equal: each country is included if its corresponding start.age is equal to 5. The UK is included above, but we’ll give an example of selecting it anyway: maths %&gt;% filter(country == &quot;United Kingdom&quot;) ## # A tibble: 1 × 7 ## country continent score gdp gini homework start.age ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 United Kingdom Europe 492 39899 34.1 4.9 5 13.5 Viewing and extracting data from a column For larger data frames (with many columns), we may wish to view a subset only. For example, to select the score and country columns only from the maths data frame, we do maths %&gt;% select(score, country) ## # A tibble: 70 × 2 ## score country ## &lt;dbl&gt; &lt;chr&gt; ## 1 413 Albania ## 2 360 Algeria ## 3 409 Argentina ## 4 494 Australia ## 5 497 Austria ## 6 531 B-S-J-G (China) ## 7 507 Belgium ## 8 377 Brazil ## 9 441 Bulgaria ## 10 516 Canada ## # ℹ 60 more rows If we want to extract the values from a column, we can use the syntax dataframe-name$column-name. For example, to extract the column score from the data frame maths, we do maths$score ## [1] 413 360 409 494 497 531 507 377 441 516 423 390 400 464 437 492 511 328 520 ## [20] 511 493 404 506 454 548 477 488 386 504 470 490 532 380 460 524 482 396 478 ## [39] 486 544 371 446 479 408 420 418 512 495 502 387 504 492 402 444 494 564 475 ## [58] 510 486 494 521 415 417 367 420 427 492 470 418 495 We could then, for example, calculate the average (mean) of all the scores: mean(maths$score) ## [1] 460.9714 13.6 Creating new columns in a data frame with the mutate() command About half the countries have a GDP per capita greater than $17000. If we try the command maths$gdp &gt; 17000 ## [1] FALSE FALSE FALSE TRUE TRUE FALSE TRUE FALSE FALSE TRUE FALSE FALSE ## [13] FALSE FALSE TRUE TRUE TRUE FALSE TRUE TRUE TRUE FALSE TRUE TRUE ## [25] TRUE FALSE TRUE FALSE TRUE TRUE TRUE TRUE FALSE FALSE TRUE FALSE ## [37] FALSE FALSE TRUE TRUE FALSE FALSE TRUE FALSE FALSE FALSE TRUE TRUE ## [49] TRUE FALSE FALSE TRUE TRUE FALSE FALSE TRUE FALSE TRUE TRUE TRUE ## [61] TRUE FALSE FALSE FALSE FALSE TRUE TRUE TRUE FALSE FALSE this creates a new vector, in which the \\(i\\)th element will be TRUE if the gdp value for country \\(i\\) is greater than 17000, and FALSE otherwise. We will add this vector to the data frame, under the column name wealthiest. The command to create the new column is mutate(wealthiest = maths$gdp &gt; 17000) but this doesn’t store the result. To put the new column in the maths data frame, we do maths &lt;- maths %&gt;% mutate(wealthiest = maths$gdp &gt; 17000) You may now have too many columns to see in your console, so to check this has worked, we will do maths %&gt;% select(country, gdp, wealthiest) ## # A tibble: 70 × 3 ## country gdp wealthiest ## &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt; ## 1 Albania 4147 FALSE ## 2 Algeria 3844 FALSE ## 3 Argentina 12449 FALSE ## 4 Australia 49928 TRUE ## 5 Austria 44177 TRUE ## 6 B-S-J-G (China) 8123 FALSE ## 7 Belgium 41096 TRUE ## 8 Brazil 8650 FALSE ## 9 Bulgaria 7351 FALSE ## 10 Canada 42158 TRUE ## # ℹ 60 more rows 13.7 Computing summaries per group Suppose we want to know the mean score within particular groups, for example, continents. We can do this by chaining together the group_by() and summarise() commands. maths %&gt;% group_by(continent) %&gt;% summarise(meanscore = mean(score)) ## # A tibble: 6 × 2 ## continent meanscore ## &lt;chr&gt; &lt;dbl&gt; ## 1 Africa 364. ## 2 Asia 471. ## 3 Europe 476. ## 4 North America 423. ## 5 Oceanea 494. ## 6 South America 401. We read the command as, “Start with the maths data frame, organise into groups based on the continent column, then create a new variable called meanscore, which is the mean of the score variable within each group.” We can group by multiple variables: maths %&gt;% group_by(continent, wealthiest) %&gt;% summarise(meanscore = mean(score)) ## `summarise()` has grouped output by &#39;continent&#39;. You can override using the ## `.groups` argument. ## # A tibble: 9 × 3 ## # Groups: continent [6] ## continent wealthiest meanscore ## &lt;chr&gt; &lt;lgl&gt; &lt;dbl&gt; ## 1 Africa FALSE 364. ## 2 Asia FALSE 436. ## 3 Asia TRUE 501. ## 4 Europe FALSE 448. ## 5 Europe TRUE 495. ## 6 North America FALSE 388. ## 7 North America TRUE 493 ## 8 Oceanea TRUE 494. ## 9 South America FALSE 401. and as the output of the command is another data frame, we can usepivot_wider() to convert the data frame into ‘wide’ format, making the results a little easier to read: maths %&gt;% group_by(continent, wealthiest) %&gt;% summarise(meanscore = mean(score)) %&gt;% pivot_wider(names_from = wealthiest, values_from = meanscore) ## `summarise()` has grouped output by &#39;continent&#39;. You can override using the ## `.groups` argument. ## # A tibble: 6 × 3 ## # Groups: continent [6] ## continent `FALSE` `TRUE` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Africa 364. NA ## 2 Asia 436. 501. ## 3 Europe 448. 495. ## 4 North America 388. 493 ## 5 Oceanea NA 494. ## 6 South America 401. NA 13.8 Counting observations within groups Suppose we want to know how many observations we have in each continent. We can do maths %&gt;% count(continent) ## # A tibble: 6 × 2 ## continent n ## &lt;chr&gt; &lt;int&gt; ## 1 Africa 2 ## 2 Asia 15 ## 3 Europe 39 ## 4 North America 6 ## 5 Oceanea 2 ## 6 South America 6 This can be extended to groups defined by combinations of variables, e.g maths %&gt;% count(continent, start.age) ## # A tibble: 10 × 3 ## continent start.age n ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Africa 6 2 ## 2 Asia 6 14 ## 3 Asia 7 1 ## 4 Europe 5 3 ## 5 Europe 6 23 ## 6 Europe 7 13 ## 7 North America 5 1 ## 8 North America 6 5 ## 9 Oceanea 5 2 ## 10 South America 6 6 Note that this doesn’t explicitly report combinations of start.age and continent that have 0 observations. Again, pivot_wider() can be used to convert the resulting data frame into ‘wide’ format, in effect giving us a contingency table: maths %&gt;% count(continent, start.age) %&gt;% pivot_wider(names_from = start.age, values_from = n) ## # A tibble: 6 × 4 ## continent `6` `7` `5` ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Africa 2 NA NA ## 2 Asia 14 1 NA ## 3 Europe 23 13 3 ## 4 North America 5 NA 1 ## 5 Oceanea NA NA 2 ## 6 South America 6 NA NA (If we were going to model the data, and wanted to include some sort of interaction effect between continent and start.age, the above table would reveal a problem: that we don’t have sufficient data.) Exercise 13.1 For this exercise, you will need the combined data from Q1 in Exercise ??. Find the 10 areas (the Area column) with the highest remain percentage votes. Find the mean percentage of remain votes within each Region. Create a new column called majorityRemain, which indicates (using TRUE or FALSE) whether or not the percentage of remain votes in each Area was above 50%. Then, find the mean percentage of adults with level 4 qualifications (or higher), separately for areas with a majority in favour of remaining, and with a majority in favour of leaving. 13.9 Further reading From RStudio, if you are online, you can access various “Cheatsheets”, including one on dplyr: go to Help &gt; Cheatsheets &gt; Data Transformation with dplyr. See also Chapter 5 of R for Data Science. References Wickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2020. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr. Data sources: test scores and homework data from [http://pisadataexplorer.oecd.org/ide/idepisa/], accessed 16/11/2017. GDP, Gini coefficient and school start age data from [https://data.worldbank.org/indicator], accessed 16/11/2027.↩︎ "],["strings.html", "Section 14 Strings 14.1 Example: (fictitous) exam mark data 14.2 Importing text data with read_lines() 14.3 Finding (and replacing) characters in strings 14.4 Subsetting strings 14.5 Making a data frame 14.6 Further reading", " Section 14 Strings Here, we’ll look at working with text and strings, which can be more awkward to deal with compared with purely numerical data. In this chapter, as an example, we’ll consider a data set provided as a plain text file, in which there are some formatting problems we’ll need to deal with. 14.1 Example: (fictitous) exam mark data We’ll consider a small text file of fictitious data. The file is called stat101.txt, and looks like this. STAT101 module marks 29/06/20 student cwk exam 12015 55 62 12468 78 84 11560 55 40* 12589 62 -- * denotes resit attempt - capped at 40 Some problems with working with this data in R would be awkward labels attached to numbers (e.g. 40*); handling of missing data: here -- has been used, whereas R uses NA; lines of text both before and after the data. It may be tempting to edit a file such as this by hand in a text editor. Try not to do this! It may not be practical if the file is large, and it’s hard to keep a good record of what edits you made. 14.2 Importing text data with read_lines() If the text file was only contained a table (and so looked like a data frame), we could use readr::read_table() to import it. But if we need to do any processing of the text first, a better option may be to first import the file with readr::read_lines(). This will create a vector of character strings, where each element is one whole line of the text file. read_lines(&quot;data/stat101.txt&quot;) ## [1] &quot;STAT101 module marks&quot; ## [2] &quot;29/06/20&quot; ## [3] &quot;&quot; ## [4] &quot;student cwk exam&quot; ## [5] &quot;12015 55 62&quot; ## [6] &quot;12468 78 84&quot; ## [7] &quot;11560 55 40* &quot; ## [8] &quot;12589 62 -- &quot; ## [9] &quot;&quot; ## [10] &quot;* denotes resit attempt - capped at 40&quot; as with other commands for importing data, read_lines() can import files directly from websites - just give the full url; we can use the argument skip to skip lines at the start (we might skip lines 1-3 here, but I will leave them in for now); the argument skip_empty_rows is FALSE by default, but I will set it to TRUE to skip rows 3 and 9: examTextRaw &lt;- read_lines(&quot;data/stat101.txt&quot;, skip_empty_rows = TRUE) 14.3 Finding (and replacing) characters in strings We can test for equality of entire strings in the usual way, e.g. x &lt;- c(&quot;red house&quot;, &quot;blue car&quot;) x == &quot;red house&quot; ## [1] TRUE FALSE but here, we will want to search within a string for some text, e.g., how to determine which elements of x contain the word red? Here, we will make use of the stringr package (Wickham 2019a). 14.3.1 Finding text with str_which() Suppose we want to find the line with the column headings. Here, will do this by finding which line contains the text student (assuming we know that’s what we need to look for): str_which(examTextRaw, &quot;student&quot;) ## [1] 3 14.3.2 Escape characters and regular expressions Some characters have special meaning, which makes it harder to search for them. If we wanted to find lines containing *, this won’t work: str_which(examTextRaw, &quot;*&quot;) Here, we have to insert two backslash symbols, so that R understands we are searching for a *: str_which(examTextRaw, &quot;\\\\*&quot;) ## [1] 6 8 To do more complicated searches, one can make use of regular expressions. Regular expressions describe particular patterns of text, and can be used in many different programming languages. We won’t cover these here, but further reading is given at the of this chapter. 14.3.3 Replacing or removing text Suppose we want to replace -- by NA, to indicate a missing value. We do str_replace_all(examTextRaw, pattern = &quot;--&quot;, replacement = &quot;NA&quot;) ## [1] &quot;STAT101 module marks&quot; ## [2] &quot;29/06/20&quot; ## [3] &quot;student cwk exam&quot; ## [4] &quot;12015 55 62&quot; ## [5] &quot;12468 78 84&quot; ## [6] &quot;11560 55 40* &quot; ## [7] &quot;12589 62 NA &quot; ## [8] &quot;* denotes resit attempt - capped at 40&quot; To delete text, we can either set replacement = \"\" in the above or use str_remove_all(). For example, to get rid of the asterisks, we would do str_remove_all(examTextRaw, pattern = &quot;\\\\*&quot;) ## [1] &quot;STAT101 module marks&quot; ## [2] &quot;29/06/20&quot; ## [3] &quot;student cwk exam&quot; ## [4] &quot;12015 55 62&quot; ## [5] &quot;12468 78 84&quot; ## [6] &quot;11560 55 40 &quot; ## [7] &quot;12589 62 -- &quot; ## [8] &quot; denotes resit attempt - capped at 40&quot; 14.3.4 Removing white space at start/end of strings Blank spaces at the end of a string can cause problems, as R might think there is an extra column of data. We can get rid of these with str_trim() str_trim(examTextRaw) ## [1] &quot;STAT101 module marks&quot; ## [2] &quot;29/06/20&quot; ## [3] &quot;student cwk exam&quot; ## [4] &quot;12015 55 62&quot; ## [5] &quot;12468 78 84&quot; ## [6] &quot;11560 55 40*&quot; ## [7] &quot;12589 62 --&quot; ## [8] &quot;* denotes resit attempt - capped at 40&quot; 14.4 Subsetting strings We might want to search for some text at a particular place in a string, or just extract part of a string. We can do this with str_sub(). For example, to extract the module code from the data, we could do str_sub(examTextRaw[1], start = 1, end = 7) ## [1] &quot;STAT101&quot; 14.5 Making a data frame We’ll first do some operations to clean up the text: examTextClean &lt;- examTextRaw %&gt;% str_remove_all(pattern = &quot;\\\\*&quot;) %&gt;% str_replace_all(pattern = &quot;--&quot;, replacement = &quot;NA&quot;) %&gt;% str_trim() and then do some searching to see which lines we want to use in our data frame: header &lt;- str_which(examTextClean, pattern = &quot;student&quot;) endLine &lt;- str_which(examTextClean, pattern = &quot;denotes&quot;) We can now make a data frame with read_table(examTextClean[header:(endLine - 1)]) ## # A tibble: 4 × 3 ## student cwk exam ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 12015 55 62 ## 2 12468 78 84 ## 3 11560 55 40 ## 4 12589 62 NA 14.6 Further reading For more on stringr, see Chapter 14 of R for Data Science In particular, see Section 14.3 on regular expressions References ———. 2019a. Stringr: Simple, Consistent Wrappers for Common String Operations. https://CRAN.R-project.org/package=stringr. "],["processing-multiple-files.html", "Section 15 Processing multiple files 15.1 Repeating a process with a for loop 15.2 Example: cleaning two text files 15.3 Exercise", " Section 15 Processing multiple files Sometimes, we may be working with data sets spread across multiple files, where the structure of the data within each file is the same or similar. It can be tempting to copy and paste a block of R code, once for each file, editing each block as necessary. Try to avoid this if you can! Your code may get messy/hard to read if you have lots of data files, and it may lead to bugs if you don’t edit each block correctly. 15.1 Repeating a process with a for loop There are different ways we might get R to run the same block of code multiple times (with small changes each time). It may be a good idea to create your own function, but we’ll consider a simpler solution here, which is to put code inside a for loop. (There are more efficient methods, but for loops are easy to write and read, and will be sufficient for this module.) A for loop has the basic syntax for(i in 1:n){ } Everything inside the curly brackets will be carried out n times; any instance of i will be replaced by 1, then 2, 3,…,n. If, for example, there is an x[i] inside the curly brackets, this code will be run first using x[1], then using x[2] and so on. 15.2 Example: cleaning two text files As an example, we’ll continue with the fictitious student data, but now suppose there are two data files, stat101.txt and stat102.txt. We suppose each data set needs cleaning, and then we’d like to combine the two data frames. 15.2.1 The core code block We have a ‘core’ block of code that we want to use multiple times, making small changes each time. The code to get a single data file into a data frame was as follows. (We’ll add an extra mutate() command to store the module code). examTextRaw &lt;- read_lines(&quot;data/stat101.txt&quot;) examTextClean &lt;- examTextRaw %&gt;% str_remove_all(pattern = &quot;\\\\*&quot;) %&gt;% str_replace_all(pattern = &quot;--&quot;, replacement = &quot;NA&quot;) %&gt;% str_trim() header &lt;- str_which(examTextClean, pattern = &quot;student&quot;) endLine &lt;- str_which(examTextClean, pattern = &quot;denotes&quot;) read_table(examTextClean[header:(endLine - 1)]) %&gt;% mutate(module = &quot;stat101&quot;) We want to run this block twice, once for the file stat101.txt and once for stat102.txt. 15.2.2 Identify the variables we need to specify The code block above needs to run twice, once using the file name stat101.txt, and once using the name stat102.txt. We will have to specify these in advance. We can actually just specify module codes: modules &lt;- c(&quot;stat101&quot;, &quot;stat102&quot;) and construct file paths using paste0(): paste0(&quot;data/&quot;, modules, &quot;.txt&quot;) ## [1] &quot;data/stat101.txt&quot; &quot;data/stat102.txt&quot; 15.2.3 Create an empty list to store the results Lists are useful here, as an element of a list can be any type of object. We make an empty one as follows: moduleResults &lt;- vector(mode = &quot;list&quot;, length = length(modules)) moduleResults ## [[1]] ## NULL ## ## [[2]] ## NULL (we could have just specified length = 2, but try to avoid specifying numerical values like this if they may change at some point, e.g. if another module was to be added.) 15.2.4 Use a for loop to run the code block multiple times The code to be repeated goes inside a for loop, with one element of the list moduleResults filled each time. (We’ll repeat the commands to set up the variables at the start.) modules &lt;- c(&quot;stat101&quot;, &quot;stat102&quot;) filePaths &lt;- paste0(&quot;data/&quot;, modules, &quot;.txt&quot;) moduleResults &lt;- vector(mode = &quot;list&quot;, length = length(modules)) for(i in 1:length(modules)){ examTextRaw &lt;- read_lines(filePaths[i]) examTextClean &lt;- examTextRaw %&gt;% str_remove_all(pattern = &quot;\\\\*&quot;) %&gt;% str_replace_all(pattern = &quot;--&quot;, replacement = &quot;NA&quot;) %&gt;% str_trim() header &lt;- str_which(examTextClean, pattern = &quot;student&quot;) endLine &lt;- str_which(examTextClean, pattern = &quot;denotes&quot;) moduleResults[[i]] &lt;- read_table(examTextClean[header:(endLine - 1)]) %&gt;% mutate(module = modules[i]) } 15.2.5 Convert the list to a data frame As each data frame in the list has the same column headings, we can convert the data frame to a list as follows do.call(rbind.data.frame, moduleResults) ## # A tibble: 7 × 4 ## student cwk exam module ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 12015 55 62 stat101 ## 2 12468 78 84 stat101 ## 3 11560 55 40 stat101 ## 4 12589 62 NA stat101 ## 5 12015 61 69 stat102 ## 6 12468 81 78 stat102 ## 7 11579 51 40 stat102 15.3 Exercise Exercise 15.1 There is a third module data file, stat103.txt. Modify the code above, so that all three files are imported, cleaned, and combined into a single data frame. Unlike the other two files, this file does not end with the line * denotes resit attempt - capped at 40 so some parts of the code above will not work! Modify the code so that the single block inside the for loop will correctly process each text file. "],["apis.html", "Section 16 APIs 16.1 Example: obtaining Covid-19 case data (data in JSON format) 16.2 Example: obtaining an .xlsx file 16.3 Exercise 16.4 Acknowledgements", " Section 16 APIs This is very brief introduction to obtaining data directly from “Application Programming Interfaces” (APIs). This is provided for background reference only: you can skip this chapter! Working with an API can be difficult, and you are typically reliant on appropriate documentation provided at the site hosting the API. If a website provides data via an API, this means that you would make selections for what data you wanted, and then a data set would be built for you to download. If you want R to download the data directly, this causes a problem, as there there may not be a file simply waiting to be downloaded; you can’t provide R with a web address. We’ll give two examples The main R package we need is httr (Wickham 2020) and we will also need jsonlite (Ooms 2014) for the first example. 16.1 Example: obtaining Covid-19 case data (data in JSON format) We will give an example of using the API at https://ukhsa-dashboard.data.gov.uk/ for obtaining Covid-19 data. In particular we will download COVID 19 cases by day From the menu on this site, we navigate to [Access our data; API developer’s guide (https://ukhsa-dashboard.data.gov.uk/access-our-data){target=“_blank”}. The first step is to specify the web address of the API. We have to do a little digging through the documentation. The first example on this page suggests we can use the following, with the last section modified to give the metric we want. endpoint &lt;- &quot;https://api.ukhsa-dashboard.data.gov.uk/themes/infectious_disease/sub_themes/respiratory/topics/COVID-19/geography_types/Nation/geographies/England/metrics/COVID-19_cases_casesByDay&quot; The command to get something from the API is httr::GET(). Arguments include the web address, and any query options, if they are required. Working out how to set the query argument is the tricky part: this is where you need to study the API documentation carefully! The example page suggests we try specifying year and page_size arguments. We’ll set the latter to give the first 10 entries for 2024. response &lt;- httr::GET( url = endpoint, query = list(year = 2024, page_size = 10) ) The data we want is in response$content, but it first needs converting into a format we can use: contentText &lt;- rawToChar(response$content) The data are now in JSON (JavaScript Object Notation) format, which we won’t worry about here, but we can convert this to list format: covid &lt;- jsonlite::fromJSON(contentText) We inspect covid to see what’s there (try str(covid)); we see that there is a data frame covid$results. We can extract the data we want as follows. covid$results$date ## [1] &quot;2024-01-01&quot; &quot;2024-01-02&quot; &quot;2024-01-03&quot; &quot;2024-01-04&quot; &quot;2024-01-05&quot; ## [6] &quot;2024-01-06&quot; &quot;2024-01-07&quot; &quot;2024-01-08&quot; &quot;2024-01-09&quot; &quot;2024-01-10&quot; covid$results$metric_value ## [1] 1080 1395 1272 1107 939 790 787 974 846 877 16.2 Example: obtaining an .xlsx file In this example, we’ll obtain a spreadsheet provided by the Office for Students (OfS): the OfS Register of all English higher education providers. This is provided by an API, but there is no API documentation. From inspecting the download link from the file, we can see that the link is to an API, rather than to the file directly. We try this link as the API address: endpoint &lt;- &quot;https://register-api.officeforstudents.org.uk/api/Download&quot; We try the httr::GET() function with no additional arguments: response &lt;- httr::GET(url = endpoint) If we try httr::http_type(response) ## [1] &quot;application/octet-stream&quot; then this tells us file type hasn’t been determined, but digging around with str(response) suggests there is an .xlsx file sitting in there somewhere! A post on stack overflow suggests exporting an object to a temporary .xlsx file, and then reading it in again. The temporary file will be deleted once you close down your R session. We do raw_xlsx &lt;- httr::content(response) and then tmp &lt;- tempfile(fileext = &#39;.xlsx&#39;) to set up the temporary file. Then to save it: writeBin(raw_xlsx, tmp) To read it back in again (where I already know I want to skip the first two rows) my_excel &lt;- readxl::read_excel(tmp, skip = 2) To check that we’ve got something: my_excel[1:5, c(1, 14) ] ## # A tibble: 5 × 2 ## `Provider’s legal name` `Highest level of degree awarding powers held` ## &lt;chr&gt; &lt;chr&gt; ## 1 Lamda Limited Taught ## 2 The University of Surrey Research ## 3 University of York Research ## 4 Aston University Research ## 5 Royal College of Music Research 16.3 Exercise Exercise 16.1 Try using the API at http://open-notify.org/Open-Notify-API/People-In-Space/ to download a data set on who is currently in space. You can leave the query argument blank in httr::GET(), so you just need the API web address. 16.4 Acknowledgements Data obtained from https://coronavirus.data.gov.uk/. Accessed 2025-09-18. Contains public sector information licensed under the Open Government Licence v3.0. Thanks to Christian Pascual for providing this useful blog post on APIs, hosted at Dataquest. References Ooms, Jeroen. 2014. “The Jsonlite Package: A Practical and Consistent Mapping Between JSON Data and r Objects.” arXiv:1403.2805 [Stat.CO]. https://arxiv.org/abs/1403.2805. ———. 2020. Httr: Tools for Working with URLs and HTTP. https://CRAN.R-project.org/package=httr. "],["missing-data.html", "Section 17 Missing data 17.1 NA 17.2 Functions and NA 17.3 Imputation 17.4 Visualising missing data 17.5 Exercise 17.6 Further reading", " Section 17 Missing data It is common to find missing values when provided with a data set. In this Section, we’ll briefly discuss how R represents and handles missing data, and some simple options for ‘imputing’ (estimating) missing data, should that be appropriate. If we come across missing data, it’s important to try to understand why the data are missing. For example, if in some clinical trial, a patient drops out (resulting in missing data) because the treatment wasn’t working, we can’t just delete the patient from our data set for convenience; we’d be be ignoring something important about how effective the treatment is. 17.1 NA R represents a missing observation with NA. For example, we can create a vector with missing elements as follows, x &lt;- c(2, 4, NA, 6, NA) and we can test to see if there are missing elements with the function is.na(): is.na(x) ## [1] FALSE FALSE TRUE FALSE TRUE If possible, do not remove missing data at the data cleaning/processing stage. Rather, store the missing values as NA, so you have a record of them, and then use appropriate methods to handle missing values inside R. 17.2 Functions and NA Some functions will, by default, return NA if the vector has any missing elements, e.g. mean(x) ## [1] NA however, there is usually an argument to specify whether to remove missing values, e.g. mean(x, na.rm = TRUE) ## [1] 4 Alternatively, the function na.omit() can be used to first remove missing values: mean(na.omit(x)) ## [1] 4 If used with a data frame, na.omit() will exclude rows where any single column has a missing value: y &lt;- 11:15 myData &lt;- data.frame(x, y) na.omit(myData) ## x y ## 1 2 11 ## 2 4 12 ## 4 6 14 Plot commands will typically ignore missing values (although you may get a warning message), for example plot(x) 17.3 Imputation In some cases, it may be desirable to ‘impute’ (estimate) missing values, and there are different options (and R packages) for doing this. We will briefly illustrate one package, imputeTS (Moritz and Bartz-Beielstein 2017). This package has a nice ‘cheat sheet’ which illustrates its functions. Suppose we have a vector with some missing values, which we will create as follows, and treat as a time series. set.seed(123) x &lt;- signif(1:10 + rnorm(10), 3) x[c(3, 4, 8)] &lt;- NA Then, some options for imputing the missing values are impute using the mean of all the non-missing cases imputeTS::na_mean(x) ## [1] 0.440000 1.770000 5.768571 5.768571 5.130000 7.720000 7.460000 5.768571 ## [9] 8.310000 9.550000 impute using the most recent observed value, “last observation carried forward” (e.g. estimate x[3] by x[2]) imputeTS::na_locf(x) ## [1] 0.44 1.77 1.77 1.77 5.13 7.72 7.46 7.46 8.31 9.55 impute using linear interpolation (e.g. linearly interpolate between x[2] and x[5] to get x[3] and x[4], assuming the observations are uniformly separated in time) imputeTS::na_interpolation(x) ## [1] 0.440 1.770 2.890 4.010 5.130 7.720 7.460 7.885 8.310 9.550 impute using a Kalman smoother (see MPS4102: Time Series) imputeTS::na_kalman(x) ## [1] 0.440000 1.770000 2.982747 4.155760 5.130000 7.720000 7.460000 7.985059 ## [9] 8.310000 9.550000 The plot below shows the imputed values (as red circles) in each case. Modelling-based estimates such as those from the Kalman smoother typically involve models in which we observe some process of interest plus noise/measurement error. Estimates obtained from imputation would be of this ‘underlying’ process, not estimates of what would actually be observed. 17.4 Visualising missing data The imputeTS package has some nice plotting functions for missing data. The plots make use of ggplot2 (which we will cover later), but you don’t need to know any ggplot2 syntax to use these functions. We can produce a plot to show clearly where the missing data are using imputeTS::ggplot_na_distribution(x) and if we have used imputation, we can make a plot that clearly displays the imputed values with (using na_kalman() as an example): imputeTS::ggplot_na_imputations(x, imputeTS::na_kalman(x)) 17.5 Exercise Exercise 17.1 The built-in data frame airquality includes time-series data of four variables, and has missing values in the Ozone and Solar.R variables. Produce plots that indicate where these missing observations are, and plots that show imputed values using the last observed observation for each variable. 17.6 Further reading CRAN task view on missing data - discussion of various approaches and R packages for handling missing data. There will be some discussion of missing data in MPS4111: Bayesian Statistics and Computational Methods. References Moritz, Steffen, and Thomas Bartz-Beielstein. 2017. “imputeTS: Time Series Missing Value Imputation in R.” The R Journal 9 (1): 207–18. https://doi.org/10.32614/RJ-2017-009. "],["making-plots-with-ggplot2.html", "Section 18 Making plots with ggplot2 18.1 The general syntax 18.2 Scatter plots 18.3 Histograms 18.4 Box plots 18.5 ‘Global’ aesthetics 18.6 Facets 18.7 Exercises 18.8 Further reading", " Section 18 Making plots with ggplot2 R has different choices available for using plots. Two commonly used options are ‘base graphics’ (e.g. using commands such as plot(), hist(), boxplot()) and the package ggplot2 (Wickham, Chang, et al. 2020), (Wickham 2016). It’s a matter of personal preference which you should use; I like to use both: base graphics for drawing diagrams, and ggplot2 for plotting data from data frames. In these notes we will discuss ggplot2. (Artwork by @allison_horst) In this section, we’ll concentrate on how to make different types of plots. You’ll almost certainly need to customise the appearance of your plot, but we’ll leave that until the next section. We’ll work through some examples in the next sections. To try these out on your own computer, you’ll need to load the tidyverse and import the maths.csv data, and create the wealthiest column. The commands to do this all are below. library(tidyverse) maths &lt;- read_csv(&quot;https://oakleyj.github.io/exampledata/maths.csv&quot;) %&gt;% mutate(wealthiest = gdp &gt; 17000) 18.1 The general syntax As an example, we’ll first produce a scatter plot: ggplot(data = maths, aes(x = gdp, y = score)) + geom_point(size = 2, alpha = 0.5) + labs(x = &quot;GDP per capita (US$)&quot;, y = &quot;Mean PISA mathematics score, 2015&quot;) The syntax can look a little complicated to start but you should get used to it! Some general points are as follows. There is quite a lot to take in here, so just skim read for now, and then have another look once you seen some examples in the following sections. The data we want to plot must be in a data frame. All plots begin with a ggplot() command, specifying the data frame we are using (maths in this case). We use the aes() any time we want something on the plot to represent values in a data frame column, e.g the position of a point on the \\(x\\)-axis or \\(y\\)-axis; the colour of a point (different colours depending on variable values). This is sometimes referred to as ‘mapping a column to an aesthetic’. In the example, we mapped the gdp column onto the \\(x\\)-axis, and the score column to the \\(y\\)-axis. Any feature of the points not related to columns in the data frame are specified outside of an aes() command. Here we used size to make the points a little larger alpha to make the points transparent (helpful when points are overlapping.) The actual type of plot is specified as a “geom”. There will be different geom commands for scatter plots, box plots, histograms etc. We used geom_point() to make a scatter plot. We use the + symbol to combine commands and make a single plot. In the example we’ve added a command to give axes labels. 18.2 Scatter plots We’ve seen a scatter plot already, but we’ll repeat the basic syntax here: ggplot(data = maths, aes(x = gdp, y = score)) + geom_point() Note that, without the labs() command, the axes labels are just the column names. In any report that you write, you will almost certainly need to specify your own axes labels; the column names will not be suitable. In your labels, include the units of measurement, if appropriate. 18.2.1 Annotating a scatter plot We may wish to annotate a plot, e.g. labelling a single observation. Here’s an example of labelling the UK (GDP = 39899, score = 492). We’ll also include proper axes labels. ggplot(data = maths, aes(x = gdp, y = score)) + geom_point() + labs(x = &quot;GDP per capita (US$)&quot;, y = &quot;Mean PISA mathematics score, 2015&quot;) + annotate(&quot;point&quot;, x = 39899, y = 492, colour = &quot;red&quot;, size = 2) + annotate(&quot;text&quot;, label = &quot;UK&quot;, x = 39899, y = 492, colour = &quot;red&quot;, hjust = -0.2, vjust = 1) The first annotate() command adds a red circle (\"point\") at the coordinates \\(x=39899\\), \\(y=492\\) (corresponding to the UK), with the size set to 2 to make it a little larger. The second annotate() command adds some red text (UK) at the coordinates \\(x=39899\\), \\(y=492\\), with the arguments hjust and vjust shifting the text slightly horizontally and vertically, so that it appears next to, rather than on top of the red dot. It can take a little trial and error to find the values for hjust and vjust that you are happy with. Adding text labels to points can be awkward! Fortunately there is a nice package ggrepel (Slowikowski 2020) that does various useful things, such as automatically pushing text labels away from each other, whilst still making clear which labels go with which points. Some examples of using ggrepel are described here. 18.2.2 Adding a trend We can see clearly that maths scores tend to increase as GDP per capita increases, but the relationship doesn’t look linear. If we want to emphasise such a relationship, we can add the trend to the plot, using the extra line geom_smooth() in the plot command: ggplot(data = maths, aes(x = gdp, y = score)) + geom_point() + labs(x = &quot;GDP per capita (US$)&quot;, y = &quot;Mean PISA mathematics score, 2015&quot;) + annotate(&quot;point&quot;, x = 39899, y = 492, colour = &quot;red&quot;, size = 2) + annotate(&quot;text&quot;, label = &quot;UK&quot;, x = 39899, y = 492, colour = &quot;red&quot;, hjust = -0.2, vjust = 1) + geom_smooth() The blue line shows the estimated trend. The grey shaded area indicates uncertainty about this trend (it’s wider on the right hand side, because we have less data there). If we want to plot a linear trend, we add the argument method = \"lm\" to geom_smooth() (we can use various regression methods within geom_smooth()): ggplot(data = maths, aes(x = gini, y = score)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + labs(x = &quot;Gini coeffcient&quot;, y = &quot;Mean PISA mathematics score, 2015&quot;) 18.2.3 Representing more than two variables on a scatter plot We can represent a third variable using colour. Additional variables can be presented using size and shape, although care is needed here; the plot could get difficult to read. 18.2.3.1 Colours for qualitative variables Here’s an example using colour to represent continent ggplot(data = maths, aes(x = gdp, y = score)) + geom_point(aes(colour = continent)) + labs(x = &quot;GDP per capita (US$)&quot;, y = &quot;Mean PISA mathematics score, 2015&quot;) Note that the mapping of continent to colour has to sit inside the aes() command. Colours can be specified manually. ggplot2 will attempt to use distinctive colours by default, but this can be hard if there are too many groups. 18.2.3.2 Colours for quantitative variables Here’s an example using colour to represent start.age ggplot(data = maths, aes(x = gdp, y = score)) + geom_point(aes(colour = start.age)) + labs(x = &quot;GDP per capita (US$)&quot;, y = &quot;Mean PISA mathematics score, 2015&quot;) Note how a ‘continuous’ colour scale has been used. As there were only three distinct starting ages in the data, a ‘qualitative’ colour scale might be better here. To do this, we can convert start.age to a factor variable with the plot commands: ggplot(data = maths, aes(x = gdp, y = score)) + geom_point(aes(colour = factor(start.age))) + labs(x = &quot;GDP per capita (US$)&quot;, y = &quot;Mean PISA mathematics score, 2015&quot;) 18.3 Histograms Here’s an example of a histogram of the score variable. We only map one column to an axis, and produce the histogram with geom_histogram(): ggplot(data = maths, aes(x = score)) + geom_histogram() We can scale the histogram so that the total area equals 1: ggplot(data = maths, aes(x = score, y = ..density..)) + geom_histogram() 18.3.1 Customising a histogram plot in R We’ll redraw the plot with different colours, add a better axis label, specify a histogram bin-width of size 10, and indicate the UK’s score with a red dot: ggplot(data = maths, aes(x = score)) + geom_histogram(colour = &quot;blue&quot;, fill = &quot;white&quot;, binwidth = 10) + labs(x = &quot;Mean PISA mathematics score, 2015&quot;) + annotate(&quot;point&quot;, x = 492, y = 0, size = 4, colour = &quot;red&quot;) The second line now includes extra arguments: fill sets the colour of the interior of the bars, and colour sets the colour of the bar edges. binwidth sets how wide each bar is on the \\(x\\)-axis; the third line (labs) specifies the label on the \\(x\\)-axis; the fourth line (annotate) draws a red circle at the coordinates \\(x=492, y=0\\), and size = 4 increases the size of the circle (the default value for size is 1.) 18.4 Box plots Box plots can be useful for comparing multiple distributions, although you may need to explain to your reader how to interpret them! Here’s an example of a box plot to compare scores between the different continents: ggplot(data = maths, aes(x = continent, y = score)) + geom_boxplot() + labs(y = &quot;Mean PISA mathematics score, 2015&quot;) It can be difficult to fit all the labels in on the \\(x\\)-axis. A simple solution is to draw the box plot ‘horizontally’ (and we’ll specify an empty \\(y\\)-axis label as we don’t really need one) ggplot(data = maths, aes(y = continent, x = score)) + geom_boxplot() + labs(x = &quot;Mean PISA mathematics score, 2015&quot;, y = &quot;&quot;) If we wanted to do a box plot of score by start.age, we have to convert start.age to a factor variable using as.factor() ggplot(data = maths, aes(x = as.factor(start.age), y = score)) + geom_boxplot() + labs(x = &quot;School starting age&quot;, y = &quot;Mean PISA mathematics score, 2015&quot;) 18.4.1 Adding the observations to a box plot It may be helpful to show the individual observations as well, for example, if the distribution of points within a group is bimodal; this wouldn’t be apparent from a box plot. It can help to ‘jitter’ the points on the group axis so that each point can be seen clearly. This can be done as follows. ggplot(data = maths, aes(x = as.factor(start.age), y = score)) + geom_boxplot() + labs(x = &quot;School starting age&quot;, y = &quot;Mean PISA mathematics score, 2015&quot;) + geom_jitter(width = 0.1) 18.4.2 Violin plots An alternative to a box plot is a “violin plot”, which plots (mirrored) density estimates for each group. ggplot(data = maths, aes(x = as.factor(start.age), y = score)) + geom_violin() + labs(x = &quot;School starting age&quot;, y = &quot;Mean PISA mathematics score, 2015&quot;) 18.5 ‘Global’ aesthetics Aesthetics can be defined in different places, and this affects the appearance of the plot. Here’s an example scatter plot, where we map colour to wealthiest within the geom_point() command ggplot(data = maths, aes(x = gini, y = score)) + geom_point(aes(colour = wealthiest)) + labs(x = &quot;Income inequality (Gini coefficient)&quot;, y = &quot;Mean PISA mathematics score, 2015&quot;) + geom_smooth(method = &quot;lm&quot;) Note that the trend specified in geom_smooth() refers to a single trend for all the data. If we instead map wealthiest to colour in the ggplot() command, this now applied ‘globally’ in all the subsequent geom commands: ggplot(data = maths, aes(x = gini, y = score, colour = wealthiest)) + geom_point() + labs(x = &quot;Income inequality (Gini coefficient)&quot;, y = &quot;Mean PISA mathematics score, 2015&quot;) + geom_smooth(method = &quot;lm&quot;) 18.6 Facets In some cases, we may wish to create a figure with multiple plots side-by-side, or arranged in a grid. If the plots are of the same type, with the same axes, we can use facets, which will ensure that the scales on each axes are the same, making comparison between the plots easier. For example, suppose we want a separate scatter plot of score against gdp, for each value of start.age. We can do this as follows. ggplot(maths, aes(x = gdp, y = score)) + geom_point() + facet_grid(cols = vars(start.age)) See ?facet_grid and also ?facet_wrap for more details (look at the examples in particular, for the different ways these plots can be laid out.) 18.7 Exercises Exercise 18.1 For these exercises you will need the Brexit data frame created in Section 12.10. Produce a scatter plot of the percentage voting to remain in the EU (within each local authority), against the percentage of adults with Level 4 qualifications. Specify suitably descriptive axes labels; add a linear trend to your plot; colour each point by its Region variable. Produce a histogram showing the distribution of the percentage voting to remain in the EU across the different local authorities. Specify a suitably descriptive axis label; annotate your plot to indicate the vote in Sheffield. Produce a box plot for the percentage voting to remain in the EU within each region. Experiment with ‘horizontal’ and ‘vertical’ box plots. 18.8 Further reading There is an RStudio Cheatsheet on ggplot2: go to Help &gt; Cheatsheets &gt; Data Visualization with ggplot2. The R Graphics Cookbook (2nd edition) is a good reference for making plots with ggplot2. There is an online tutorial available here: RStudio Primers (Visualize Data) See also R for Data Science (Chapter 3) References Slowikowski, Kamil. 2020. Ggrepel: Automatically Position Non-Overlapping Text Labels with ’Ggplot2’. https://CRAN.R-project.org/package=ggrepel. Wickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org. Wickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2020. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2. "],["presentation-of-plots.html", "Section 19 Presentation of plots 19.1 The basics 19.2 The caption test 19.3 Caption or title? 19.4 Customising the appearance of a plot 19.5 Refining a plot: an example 19.6 Exercises 19.7 Data sources", " Section 19 Presentation of plots You should think carefully about how you present your plots to others. With minimal plotting commands, you can obtain a plot quickly and easily, but it is unlikely it will be suitable for including in a report. For this chapter, you will need to install the MAS6005 package, which is available on GitHub only. Install it with the commands install.packages(&quot;devtools&quot;) devtools::install_github(&quot;OakleyJ/MAS6005&quot;) 19.1 The basics Using the mtcars data frame, we’ll make a scatter plot of miles per gallon against weight. For more information about these variables, use ?mtcars. Suppose we use the following code, and the figure below is used in a written report ggplot(mtcars, aes(x = wt, y = mpg)) + geom_point() Figure 19.1: Fuel economy and weight. This standard of presentation would be unacceptable in any report! To improve the figure, we should include proper axes labels: never simply use the R variable names; specify the units; give sufficiently detailed captions so that the figure can be understood on its own, and include a conclusion: what do we learn from the figure? The first two points are obvious, but the third perhaps less so, so we’ll discuss this a little more. 19.2 The caption test You may be unsure as to whether you should include a particular plot or not. You may be tempted to ‘err on the safe side’, by including the plot, but if the plot doesn’t tell the reader anything useful, this will just lead to a bloated report. A simple test to apply is as follows. State, in your caption, what conclusion the reader should draw from looking at the plot. If you can’t think of anything to say, this probably means that there’s nothing useful to be learned from your plot: leave it out of your report! This doesn’t mean, for example, that a plot must show an interesting relationship between two variables; a plot may suggest that two variables are unrelated; that can still be informative to a reader. There will also be exceptions: it may be helpful to include a plot simply to show what data are available, but it should be obvious when you need to apply the caption test. It’s also good practice to state the data source in the caption. So in summary, the caption should include a title for the plot; a conclusion that can be drawn from the plot; the source of the data, if appropriate. Putting this all together, an improvement would be ggplot(data = mtcars, aes(x = wt, y = mpg)) + geom_point() + labs(x = &quot;Weight (lb/1000)&quot;, y = &quot;Miles / (US) gallon&quot;) Figure 19.2: Fuel economy ) and weight for 32 car models. Heavier cars tend to be less fuel efficient. Source: Motor Trend (1974) 19.3 Caption or title? In a written report, plots will usually be labelled by a figure number, and then the plot information would all go in the caption. It is not recommended to have an additional title at the top: you would then have plot text in two different places. However, if your plot is being presented in a web page, or in some talk slides, then you may not have a figure label and caption. Here, you can use additional ggplot2 commands to produce a title, conclusion and data reference within the plot itself. For example (with subtitle used for the plot conclusion, and caption used for the data source), ggplot(data = mtcars, aes(x = wt, y = mpg)) + geom_point() + labs(x = &quot;Weight (lb/1000)&quot;, y = &quot;Miles / (US) gallon&quot;, title = &quot;Fuel economy and weight for 32 car models&quot;, subtitle = &quot;Heavier cars tend to be less fuel efficient&quot;, caption = &quot;Source: Motor Trend (1974)&quot;) 19.4 Customising the appearance of a plot You can change just about any aspect of the appearance of a plot. If you have a legend in your plot, it’s likely you’ll need to modify it, as the default will use data frame column names. You may also wish to change the grey background used by default in ggplot2. Font sizes will need changing if they are too small in your final report. The R Graphics Cookbook is an excellent reference here. (The format used throughout is to state a “problem”: something you want to do with your plot, and then provide the code solution and discussion). Some chapters in particular to look at are Chapter 9 Controlling the Overall Appearance of Graphs Chapter 10 Legends Chapter 12 Using Colors in Plots 19.5 Refining a plot: an example We’ll now give an example of creating a plot, and then thinking about how we might improve it (assuming we’ve already got ‘the basics’ right, in that the axes titles and caption are satisfactory.) 19.5.1 The data to plot We consider the mvscores data set from the MAS6005 package. The aim is to compare test match batting scores for one player, Michael Vaughan, between the matches he played as captain, and the matches where he was not captain. The hypothesis is players tend to perform less well, if they have the added burden of captaincy. The data set also records whether each score was in the first or second innings; batting can be more difficult in a second innings, due to wear of the pitch. To summaries for those with no interest in/knowledge of cricket: we want to illustrate how/if the values in runs differ depending on the captain variable (a 2-level factor: yes or no) innings (a 2-level factor: first or second) is a ‘blocking variable’: we are more interested in comparing captain/not captain scores within the same innings type than between different innings types. 19.5.2 A first attempt: four histograms We’ll first try producing four histograms of scores: one for each combination of captain and innings. Note that we use the gridExtra package (Auguie 2017) to arrange the plots in a 2x2 grid; plots produces by ggplot2 can be assigned to variables, and used later in other functions. library(MAS6005) p1 &lt;- mvscores %&gt;% filter(innings == &quot;first&quot;, captain == &quot;yes&quot;) %&gt;% ggplot(aes(x = runs))+ labs(x = &quot;First innings runs, captain&quot;) + geom_histogram() p2 &lt;- mvscores %&gt;% filter(innings == &quot;first&quot;, captain == &quot;no&quot;) %&gt;% ggplot(aes(x = runs))+ labs(x = &quot;First innings runs, not captain&quot;) + geom_histogram() p3 &lt;- mvscores %&gt;% filter(innings == &quot;second&quot;, captain == &quot;yes&quot;) %&gt;% ggplot(aes(x = runs))+ labs(x = &quot;Second innings runs, captain&quot;) + geom_histogram() p4 &lt;- mvscores %&gt;% filter(innings == &quot;second&quot;, captain == &quot;no&quot;) %&gt;% ggplot(aes(x = runs))+ labs(x = &quot;Second innings runs, not captain&quot;) + geom_histogram() gridExtra::grid.arrange(p1, p2, p3, p4, nrow = 2) Figure 19.3: Test Match runs scored by the England Cricketer Michael Vaughan, in each innings, and whether or not he played as captain. His scores tended to be higher when he did not play as captain. Source: ESPNcricinfo. The main thing I don’t like about this plot is that the \\(x\\)-axis scales are different for each histogram, which makes comparing the histograms harder. We could set the scale manually (see ?ggplot2::xlim) but facets might work well here. The \\(y\\)-axis scales are also different. This issue is slightly more complicated, in that the numbers of observations used for each histogram are different, so it’s really the shapes of the histograms that we want to compare. One options is to scale each histogram to have total area 1 (so it’s like a density plot.) It’s also worth thinking about the arrangement of the plots within the grid. I would use rows rather than columns to represent the main factor of interest (captain), so that the main comparisons involve looking at histograms aligned vertically, not horizontally: any ‘shift’ in distribution is easier to see. An alternative plot, which I prefer, is as follows. ggplot(mvscores, aes(x = runs, y = ..density..))+ labs(x = &quot;Runs scored&quot;) + geom_histogram() + facet_grid(rows = vars(captain), col = vars(innings), labeller = label_both) Figure 19.4: Test Match runs scored by the England Cricketer Michael Vaughan, in each innings, and whether or not he played as captain. His scores tended to be higher when he did not play as captain. Source: ESPNcricinfo. 19.5.3 Using a box plot Another option is to present the data using a box plot. Although we lose some information compared with the histogram point, comparing summaries of the distributions of scores is easier. ggplot(mvscores, aes(x = innings, y = runs))+ geom_boxplot(aes(color = captain) ) Figure 19.5: Test Match runs scored by the England Cricketer Michael Vaughan, in each innings, and whether or not he played as captain. His scores tended to be higher when he did not play as captain. Source: ESPNcricinfo. I prefer this to the histogram plot. Note that it’s more helpful to map captain to colour and innings to the \\(x\\)-axis than vice-versa, as this makes it easier to compare the effect of ‘treatment’ (captain) within each ‘block’ (innings). 19.6 Exercises Exercise 19.1 Below are three plots. For each plot, run the code in R to reproduce the plot. Think about how each plot might be improved. Modify the R code to achieve a better plot. Hints are given for each plot, but try not to read them until you have had your own ideas! This plot uses the built in data set airquality. Type ?airquality for more details. ggplot(airquality, aes(x = Temp, y = Ozone)) + geom_point() Figure 19.6: Scatter plot of ozone versus temperature This plot fails on all levels regarding The basics and The caption test! Use the help file so you can specify more informative labels. Later, we will be using R Markdown to add captions to plots, so for now, just suggest some text that would be more suitable for the caption. This following plot uses the medals data set from the MAS6005 package, and shows number of gold medals against population size. ggplot(MAS6005::medals, aes(x = population, y = gold)) + geom_point() + labs(x = &quot;population size&quot;, y = &quot;gold medals won&quot;) Figure 19.7: Number of gold medals won against population size for the Rio 2016 Summer Olympics. Although India and China have similar population sizes, China was much more successful. Source (population data): World Bank. The caption refers to India and China. Although the reader might guess which points are these two countries, they shouldn’t have to! Annotations would help. The bunching of most of the points in the bottom left corner doesn’t look very nice. A log-scale \\(x\\)-axis is worth trying. The scientific notation used for the \\(x\\)-axis scale is unfriendly for the general reader. It might help to express population size in units of millions. The following plot uses the inequality data set from the MAS6005 package, and shows income inequality for different countries. ggplot(inequality, aes(y = country, x = gini)) + geom_col() + labs(x = &quot;Gini coefficient&quot;) Figure 19.8: Income inequality as measured by the Gini coefficient for 36 OECD countries, reported in 2016. The UK was ranked 7th worst. Source: OECD. Visualising the rank order is difficult here, as the bars are arranged in alphabetical order of country. Ordering them by Gini coefficient would help. See this example in the R Graphics Cookbook The \\(y\\)-axis label “country” is unnecessary here, and can be removed. As the caption refers to the UK, we could try to make the UK observation more distinctive in the plot. Here, you could try using the fill argument in geom_cols(), specifying it to be a vector of 36 colours: 35 the same, and one different for the UK. Bonus challenge! Tufte (2013)2 suggests having gaps within the bars to create a nice grid effect (“data-ink maximisation”). Try a Google image search for “Tufte bar chart”. Can you create this effect? 19.7 Data sources Air quality data obtained the New York State Department of Conservation (ozone data) and the National Weather Service (temperature data), provided in the R datasets package. Inequality data obtained from OECD (2016), Income inequality (indicator). doi: 10.1787/459aa7f1-en [Accessed on 17 August 2016] Population data obtained from The World Bank. Accessed 6th October 2015. Medal table obtained from https://www.rio2016.com/en/medal-count-country [Accessed on 6th October 2016, but this link is no longer active.] References Auguie, Baptiste. 2017. gridExtra: Miscellaneous Functions for \"Grid\" Graphics. https://CRAN.R-project.org/package=gridExtra. Tufte, Edward R. 2013. The Visual Display of Quantitative Information. Second edition. Graphics Press.↩︎ "],["maps-with-leaflet.html", "Section 20 Maps with leaflet 20.1 A basic map 20.2 Indicating points on a map 20.3 Plotting region boundaries 20.4 Further reading 20.5 Acknowledgement 20.6 References:", " Section 20 Maps with leaflet .leaflet { margin: auto; } For spatial data corresponding to geographical locations, it can be helpful to visualise the data on a map. There are various mapping tools available in R. Here, we will discuss the R package leaflet (Cheng, Karambelkar, and Xie 2019), which is an R implementation of the JavaScript library of the same name. Maps produced using leaflet are best suited for web pages, as you can zoom and scroll a map as you would do with, say, Google maps. These maps can also be used inside shiny apps. You will need to be online to use leaflet. 20.1 A basic map We’ll first load the leaflet package. library(leaflet) To get a basic map, we will normally need to specify the longitude and latitude of the centre of our map, as well the initial zoom level (which may take some trial and error). For example, to obtain a map of Sheffield: leaflet() %&gt;% addTiles() %&gt;% setView(lng = -1.473798, lat = 53.38252, zoom = 13) The addTiles() specifies what is drawn on each map ‘tile’, with the default being streets and points of interest provided by OpenStreetMap. For example, to change to an aerial photo (as in Google Earth), we can instead use the addProviderTiles() command, and specify a different ‘tile provider’: leaflet() %&gt;% setView(lng = -1.473798, lat = 53.38252, zoom = 13) %&gt;% addProviderTiles(providers$Esri.WorldImagery) 20.2 Indicating points on a map If we have vectors of coordinates (latitude and longitude), we can add points with the addMarkers() function (there are variants such as addCircles() and addPopups().) We can include the argument popup so that some text is displayed if the mouse is clicked on the marker. Here’s an example where I’ve marked where I work, and my favourite pub. latitude &lt;- c(53.380909, 53.371566) longitude &lt;- c(-1.486197, -1.577604) placeNames &lt;- c(&quot;Hicks Building&quot;, &quot;The Sportsman&quot;) leaflet() %&gt;% setView(lng = -1.525, lat = 53.38, zoom =12) %&gt;% addTiles() %&gt;% addMarkers(lat = latitude, lng = longitude, popup = placeNames) Exercise 20.1 Use leaflet to make a map that displays a region and two points of interest to you, for example, where you live, and your nearest railway station. 20.3 Plotting region boundaries We can plot region boundaries on maps, and use different colours to make the regions more distinctive, or to indicate different values of some variable in different regions (a “choropleth map”). This can be a little tricky, in that the data sets that indicate region boundaries can be quite complicated. Here’s an example of plotting ‘county and unitary’ authorities in the UK. To start with, we’ll use a base map that uses plainer-looking tiles than OpenStreetMap: leaflet() %&gt;% setView(lng = -3.436, lat = 55.3781, zoom = 5) %&gt;% addProviderTiles(providers$Esri.WorldGrayCanvas) 20.3.1 shapefiles Boundary data can be stored in different formats. We will search for a format called a shapefile. If we try a Google search for “england county boundaries shapefile”, we can find this page at data.gov.uk, and a zip file containing the shapefile can be downloaded from here. 20.3.2 Importing and simplifying shapefiles Shapefiles can be imported using the sf package (Pebesma and Bivand, 2023; Pebesma 2018) with the functions read_sf() and st_transform(). The read_sf() command takes the full file path, including the filename (with the .shp extension), of the shapefile as its argument. We must then use the st_transform() function to convert the obtained sf object so that it has the appropriate ‘coordinate reference system (crs)’ for map plotting with the leaflet package. We’ll suppose here that the path to the folder where the shapefile is stored (after being unzipped from the download) is \"U:/MPS4110/EDA/Counties/\": we do: library(sf) boundaries &lt;- read_sf(&#39;U:/MPS4110/EDA/Counties/CTYUA_MAY_2023_UK_BGC.shp&#39;) %&gt;% st_transform(crs = &#39;+proj=longlat +datum=WGS84&#39;) This creates an object of class sf: it’s more complicated than an ordinary dataframe, and we won’t worry too much about its structure. But if we try print(boundaries) ## Simple feature collection with 218 features and 8 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -8.650007 ymin: 49.8648 xmax: 1.76368 ymax: 60.86074 ## Geodetic CRS: +proj=longlat +datum=WGS84 ## # A tibble: 218 × 9 ## CTYUA23CD CTYUA23NM CTYUA23NMW BNG_E BNG_N LONG LAT GlobalID ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 E06000001 Hartlepool &lt;NA&gt; 447160 531474 -1.27 54.7 3bf4312… ## 2 E06000002 Middlesbrough &lt;NA&gt; 451141 516887 -1.21 54.5 f97de8d… ## 3 E06000003 Redcar and Cleveland &lt;NA&gt; 464361 519597 -1.01 54.6 ef76d83… ## 4 E06000004 Stockton-on-Tees &lt;NA&gt; 444940 518183 -1.31 54.6 05fc23f… ## 5 E06000005 Darlington &lt;NA&gt; 428029 515648 -1.57 54.5 5a21326… ## 6 E06000006 Halton &lt;NA&gt; 354246 382146 -2.69 53.3 f87a98b… ## 7 E06000007 Warrington &lt;NA&gt; 362744 388456 -2.56 53.4 51f4cdf… ## 8 E06000008 Blackburn with Darw… &lt;NA&gt; 369490 422806 -2.46 53.7 11e5f05… ## 9 E06000009 Blackpool &lt;NA&gt; 332819 436635 -3.02 53.8 8ec1c78… ## 10 E06000010 Kingston upon Hull,… &lt;NA&gt; 511894 431650 -0.304 53.8 3fef2d1… ## # ℹ 208 more rows ## # ℹ 1 more variable: geometry &lt;MULTIPOLYGON [°]&gt; we can see we have 218 regions (which sounds right!). The shapefile is a large object; it may help to simplify it, so that our code will run a little more quickly. We can do this with the rmapshaper package (Teucher and Russell 2020). simplifiedBoundaries &lt;- rmapshaper::ms_simplify(boundaries) (It’s worth checking that we get the same-looking map, whether we use boundaries or simplifiedBoundaries.) 20.3.3 Plotting the boundaries We can now add the boundaries to our map, using the command addPolygons(): leaflet() %&gt;% setView(lng = -3.436, lat = 55.3781, zoom = 5) %&gt;% addProviderTiles(providers$Esri.WorldGrayCanvas) %&gt;% addPolygons(data = simplifiedBoundaries, color = &quot;blue&quot;, fillOpacity = 0, weight = 1, popup = ~CTYUA23NM) For the arguments to addPolygons, we include fillOpacity: a number between 0 and 1. Set to 0 for no colouring within each region; weight: the thickness of the boundary lines; popup = ~CTYUA23NM: if the mouse is clicked inside a region, display the value in the CTYUA23NM column in the simplifiedBoundaries data frame. 20.3.4 Using different colours for regions We can use a different colour for each region, depending on some other data value. Here, we will colour the counties by the UK country they are in, where England, Scotland, Wales and Northern Ireland counties are coloured orange, blue, red and green respectively. If we inspect simplifiedBoundaries$CTYUA23NM, we can see the order of the counties and we can create a colour vector and assign the appropriate colours for the regions manually: country = rep(&quot;orange&quot;, times = length(simplifiedBoundaries$CTYUA23NM)) country[154:164] = &quot;green&quot;; country[165:196] = &quot;blue&quot;; country[197:218] = &quot;red&quot; We’ll redraw the map, increasing fillOpacity slightly above 0: leaflet() %&gt;% setView(lng = -3.436, lat = 55.3781, zoom = 5) %&gt;% addProviderTiles(providers$Esri.WorldGrayCanvas) %&gt;% addPolygons(data = simplifiedBoundaries, fillOpacity = 0.05, weight = 1, popup = ~CTYUA23NM, fillColor = country, color = country) 20.4 Further reading The leaflet R package is well documented: a manual is available here. Although not necessary for using the R package, if you want to understand more about leaflet itself, documentation and tutorials are available at The JavaScript leaflet homepage. 20.5 Acknowledgement The shapefile was provided by the Office for National Statistics and obtained from https://www.data.gov.uk/dataset/85228aec-fe0e-49bf-9455-df000d61e731/counties-and-unitary-authorities-may-2023-boundaries-uk-bgc, accessed 27/08/2024. Contains public sector information licensed under the Open Government Licence v3.0. 20.6 References: Pebesma, E., &amp; Bivand, R. (2023). Spatial Data Science: With Applications in R. Chapman and Hall/CRC. https://doi.org/10.1201/9780429459016 Pebesma, E., 2018. Simple Features for R: Standardized Support for Spatial Vector Data. The R Journal 10 (1), 439-446, https://doi.org/10.32614/RJ-2018-009 Teucher, Andy, and Kenton Russell. 2020. Rmapshaper: Client for ’Mapshaper’ for ’Geospatial’ Operations. https://CRAN.R-project.org/package=rmapshaper. References Cheng, Joe, Bhaskar Karambelkar, and Yihui Xie. 2019. Leaflet: Create Interactive Web Maps with the JavaScript ’Leaflet’ Library. https://CRAN.R-project.org/package=leaflet. "],["r-markdown.html", "Section 21 R Markdown 21.1 A five minute video tutorial 21.2 Working directories for R Markdown documents 21.3 Code chunk options 21.4 Tables 21.5 Caching results for slow-running code 21.6 Spell checking 21.7 The YAML header 21.8 LaTeX, Markdown and html 21.9 bookdown 21.10 Quarto", " Section 21 R Markdown R Markdown (Allaire et al. 2020), (Xie, Allaire, and Grolemund 2018) is a system for producing reports. From a single R Markdown document, you can produce your report in a variety of formats including: PDF, Word document, web page (html), slides (including Powerpoint and Beamer). (Artwork by @allison_horst) The main idea is that your text and R code go in the same document. When you compile (or “knit”) your document, the R code is run, and the code input and output can be displayed in your report. This has several advantages. Your analyses will be more transparent and reproducible. If someone else (or even you at some point in the future) want to know, say, what calculations were done to produce a particular result in the report, the R Markdown document can be inspected to see what R code was used to get the result. You will save a lot of time if you need to include plots in your report: you write the code to make your plot, and then R Markdown inserts the plot in your report automatically. If changes are made to the data, or if you make some change early on in your analysis, you can just recompile your report, and the code will be re-run with the new data, and all the new results will appear in the re-compiled report. (You may, of course, need to change your text commentary) 21.1 A five minute video tutorial This video illustrates the basics of how to work with an R Markdown document. 21.2 Working directories for R Markdown documents When we run a code chunk inside an R Markdown document, the working directory is set to be directory containing the document (check this by running the command getwd() inside a code chunk.) If you are using an RStudio project, you may wish your data and R Markdown documents to be in different folders, e.g., if the project directory is myProject, you may have folders myProject/data myProject/reports If your R Markdown document is in the folder myProject/reports, and you want to import a file myData.csv from myProject/data, specify the (relative) file path in your R Markdown document as myData &lt;- read_csv(&quot;../data/myData.csv&quot;) Exercise 21.1 Create an R Markdown document that presents some of your solutions to the exercises in Section 18.7 on the Brexit data. You may need to install RMarkdown first, using the command install.packages(&quot;rmarkdown&quot;) For now, make a document that presents one plot only. Knit your document to html. If you have LaTeX on your computer, try knitting to pdf as well. The goal of this exercise is simply to produce a working document: do not worry about how your document looks. You will change the appearance of your document in later exercises. 21.3 Code chunk options This video illustrates how to use code chunk options to change the appearance of a document (One useful option that I didn’t mention in the video is include = FALSE. This will run the code, but will not display the input or any output, including messages and warnings.) 21.3.1 Code chunk options for figures For reference, here’s an example code chunk with the options you would typically need to use when making a plot. ```{r, fig.align = &#39;center&#39;, fig.cap = &quot;My figure caption&quot;, fig.height = 3, fig.width = 3} ggplot(mtcars, aes(x = wt, y = mpg)) + geom_point() ``` Some trial and error may be needed to find values for fig.height and fig.width that give the figure size you want. If importing a figure rather than generating it in R, you may find the option out.width = \"60%\" easier to work with than fig.height and fig.width. Again, you may need trial and error to decide on the best percentage value. Exercise 21.2 Use suitable code chunk options to change the appearance of your R Markdown document from the previous exercise. Make sure no R code appears in your html/pdf document Include a figure caption, centre-align your figure, and manually set an appropriate figure size. 21.4 Tables There are several options for producing tables in R Markdown. (For general advice on formatting tables, see Section 22.3 of Wilke (2019). 21.4.1 Using Markdown Here’s an example of making a table with the Markdown syntax. Note the use of : for specifying text alignment. | column 1 | column 2 | column 3 | |:---------|:--------:|---------:| | left | centre | right | | aligned | aligned | aligned | This is rendered as follows. column 1 column 2 column 3 this text this text this text is left is centre is right aligned aligned aligned Online tools are available for generating Markdown syntax, for example https://www.tablesgenerator.com/markdown_tables. 21.4.2 Using knitr::kable() The knitr package (Xie 2020b), (Xie 2014), (Xie 2015) has the kable() function which can produce a table from a data frame. Here’s an example. knitr::kable(head(mtcars)) which is rendered (in html) as follows: mpg cyl disp hp drat wt qsec vs am gear carb Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 21.5 Caching results for slow-running code If some of your code takes a long time to run, it is preferable not to re-run it every time you edit your R Markdown document and want to re-compile it. It you use the code chunk option cache = TRUE, R will store (‘cache’) the results, and will only re-run the code chunk if it detects that something has changed. Be careful if you use caching. For example, if you import a file and cache the results, R will not detect if the file contents change. When you knit your final version of your document, switch off all caching. Exercise 21.3 Add one table to your R Markdown document from the previous exercise, to show the mean percentage of the remain vote grouped by area. Use knitr::kable() to produce the table. 21.6 Spell checking RStudio has a spell checker. To use it, click the green tick (with ABC above) button, in the document window. If you wish, you can go to Tools &gt; Global Options… &gt; Spelling and change the Main dictionary language to English (United Kingdom). Using the spell checker will not identify all possible errors. Proofread your work carefully! 21.7 The YAML header The first part of an R Markdown document, the ‘header’ is used to specify information such as author and title, and can include extra commands to change the appearance of the document. These are commands are specified using another language called YAML. Here’s an example of a YAML header, with a few extra commands specified that you might find helpful. --- title: &quot;My Report Title&quot; author: &quot;Jeremy Oakley&quot; date: &quot;2025-09-18&quot; output: pdf_document: number_sections: true html_document: number_sections: true fontsize: 11pt urlcolor: blue header-includes: - \\usepackage{bm} --- Indenting of particular lines does matter in YAML. Keep this is mind when copying YAML examples. The command Sys.Date() is an R command which will insert today’s date (year-month-day format). The commands fontsize and urlcolor affect pdf output only. The final command header-includes: - \\usepackage{bm} can be used to add commands (e.g. \\usepackage{bm}) to the preamble in the LaTeX document for pdf output. 21.8 LaTeX, Markdown and html The Markdown language is broadly the same as LaTeX for typesetting equations/maths notation, and so you can use LaTeX as normal for typesetting maths. You can use any other LaTeX commands throughout your document. When producing pdf output, R Markdown will actually generate an intermediate .tex file, which is then compiled to pdf. However, these commands will be ignored if you knit to html or other formats. Similarly, you can include html commands in your document; these will only work if you knit to html. Try to keep to Markdown commands as far as possible. This will give you the most flexibility regarding your choice of output format (and you may wish to switch your output format in the future.) For example, putting this in your document: \\section{Introduction} will only produce the desired section heading if you knit to pdf, but using this: # Introduction will give the desired section heading for any output format you produce. 21.9 bookdown bookdown (Xie 2020a), (Xie 2017) is an extension to R Markdown, that has extra features helpful for writing books, dissertations and longer reports/articles. (I used bookdown to produce this ‘gitbook’ that you are reading now.) You won’t need bookdown on this module, but we will provide a template and instructions for your dissertation. Exercise 21.4 Using your document from the previous exercise: edit the YAML header to increase the font size for pdf output add a short amount of text to explain the subject of your document; use RStudio’s spell checker. 21.10 Quarto Quarto is a newer system for producing documents, and is described by its authors as “the next generation of R Markdown”. Quarto is designed to work with a greater variety of languages and platforms; it can be used without an installation of R. If you use Quarto within RStudio, you will find it very similar to using R Markdown, and Quarto will render most .Rmd files without modification. R Markdown will be sufficient for this module, but you can use Quarto if you wish. For more details, see the Quarto homepage. References Allaire, JJ, Yihui Xie, Jonathan McPherson, Javier Luraschi, Kevin Ushey, Aron Atkins, Hadley Wickham, Joe Cheng, Winston Chang, and Richard Iannone. 2020. Rmarkdown: Dynamic Documents for r. https://CRAN.R-project.org/package=rmarkdown. Xie, Yihui. 2014. “Knitr: A Comprehensive Tool for Reproducible Research in R.” In Implementing Reproducible Computational Research, edited by Victoria Stodden, Friedrich Leisch, and Roger D. Peng. Chapman; Hall/CRC. http://www.crcpress.com/product/isbn/9781466561595. ———. 2015. Dynamic Documents with R and Knitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. https://yihui.org/knitr/. ———. 2017. Bookdown: Authoring Books and Technical Documents with R Markdown. Boca Raton, Florida: Chapman; Hall/CRC. https://github.com/rstudio/bookdown. ———. 2020a. Bookdown: Authoring Books and Technical Documents with r Markdown. https://CRAN.R-project.org/package=bookdown. ———. 2020b. Knitr: A General-Purpose Package for Dynamic Report Generation in r. https://CRAN.R-project.org/package=knitr. Xie, Yihui, J. J. Allaire, and Garrett Grolemund. 2018. R Markdown: The Definitive Guide. Boca Raton, Florida: Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown. "],["referencing.html", "Section 22 Referencing 22.1 Referencing data sets 22.2 Citing R and R packages 22.3 Using someone else’s figures in your work 22.4 Further reading. 22.5 Exercise", " Section 22 Referencing The reports you write for this module will need to include references. We will give separate guidance on referencing for written reports. Here, we will just comment on some issues likely to arise for reports on this module. For reports on this module, the number of references is likely to be small, and you can construct a references section manually. For reports with larger numbers of references (or your disseration), we recommend using reference management software such as BibTeX (which can be used in combination with bookdown) 22.1 Referencing data sets If you are using data that you have not produced yourself, you need to give a reference. The University Library gives examples here of how to cite data sets (with Harvard referencing). These sorts of citations can be awkward, in that some of the details may be missing on the website - just do the best you can to give a full reference. Do make sure you include the date you accessed the data. 22.1.1 Attribution statements and conditions of use Some data sets are free to use, but only under certain conditions, and you may be required to give an attribution statement. For example, HM Land Registry publishes data on prices paid for houses, but requires you to give this attribution statement if you use it, (and also attaches some conditions for its use). 22.2 Citing R and R packages Use of R in any published work should be cited. Cite also any package that you have used (either with a library() command, or with the :: syntax). You can get citation details for R with the command citation() ## To cite R in publications use: ## ## R Core Team (2024). _R: A Language and Environment for Statistical ## Computing_. R Foundation for Statistical Computing, Vienna, Austria. ## &lt;https://www.R-project.org/&gt;. ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {R: A Language and Environment for Statistical Computing}, ## author = {{R Core Team}}, ## organization = {R Foundation for Statistical Computing}, ## address = {Vienna, Austria}, ## year = {2024}, ## url = {https://www.R-project.org/}, ## } ## ## We have invested a lot of time and effort in creating R, please cite it ## when using it for data analysis. See also &#39;citation(&quot;pkgname&quot;)&#39; for ## citing R packages. and you can get citation details for any package by adding the name in quotes: citation(&quot;ggplot2&quot;) ## To cite ggplot2 in publications, please use ## ## H. Wickham. ggplot2: Elegant Graphics for Data Analysis. ## Springer-Verlag New York, 2016. ## ## A BibTeX entry for LaTeX users is ## ## @Book{, ## author = {Hadley Wickham}, ## title = {ggplot2: Elegant Graphics for Data Analysis}, ## publisher = {Springer-Verlag New York}, ## year = {2016}, ## isbn = {978-3-319-24277-4}, ## url = {https://ggplot2.tidyverse.org}, ## } 22.3 Using someone else’s figures in your work Just because a figure is available on the internet, this does not mean you are allowed to use it in your own work! You need permission to use someone else’s figure; if permission is not stated then you need to contact the author to ask for it. If you redraw the figure yourself, you don’t need permission, but you should then give a citation to make clear that your plot is based on someone else’s work. 22.4 Further reading. There are various University Library tutorials/guides you might find helpful: Guide to Harvard referencing Tutorial on referencing images Tutorial on understanding plagiarism Quiz/tutorial on referencing and plagiarism 22.5 Exercise Exercise 22.1 Using your document from the previous exercise: add a reference to the data set; add references to R and any R packages that you have used. "],["shiny.html", "Section 23 Shiny 23.1 Some example R code, for inclusion in an app 23.2 Putting the code inside an app 23.3 The user interface ui 23.4 The server 23.5 Reactivity 23.6 Customising the appearance of your app 23.7 Shiny with R Markdown 23.8 Further reading", " Section 23 Shiny Shiny (Chang et al. 2020) is an R package for producing apps that can be run from a web-browser. The app will have R running in the background, and so you would either host the app on a suitable server, or you could run the app on your own computer. You might use a shiny app to make your methods/analyses more accessible to others who don’t use R, or you might find the interactivity that shiny offers a more convenient way of working with R. A gallery of examples is available at https://shiny.rstudio.com/gallery/. You will need the packages shiny, tidyverse, and MAS6005. The MAS6005 package is on GitHub only (not CRAN); if you haven’t installed it already then use the commands install.packages(&quot;devtools&quot;) devtools::install_github(&quot;OakleyJ/MAS6005&quot;) You will also need the MPS4110Data.zip file. This contains a shiny folder, with the data and some example code. 23.1 Some example R code, for inclusion in an app We’ll start with some R code to analyse the flint data from the MPS4110Data.zip file. The data are measurements of the length and breadth, in centimetres, of each item in a small group of flint tools, and we suppose there is interest in predicting length given breadth only (e.g. if a tool is damaged). A simple linear regression model will be fitted, with length as the dependent variable, and breadth as the independent variable. Suppose we want to plot the flint data, together with either a confidence interval for the mean, or a prediction interval for a new observation. Some code is as follows (and is also available in the file flint-script.R). We will first load in the data library(tidyverse) flintDf &lt;- read_table(&quot;flintsdata.txt&quot;) and specify as variables the interval type and level. cpLevel &lt;- 0.95 intervalType &lt;- &quot;prediction&quot; Now we’ll compute the desired interval and put everything together in a new data frame. lmFlint &lt;- lm(length ~ breadth, flintDf) intervalDf &lt;- cbind(flintDf, predict(lmFlint, interval = intervalType, level = cpLevel)) Note that we’ve made use of the previously defined variables cplevel and intervalType in the predict() command. Now we’ll draw the plot ggplot(intervalDf, aes(x = breadth, y = length)) + labs(x=&quot;flint tool breadth (cm)&quot;, y=&quot;flint tool length (cm)&quot;) + geom_point() + geom_line(aes(y = fit)) + geom_ribbon(aes(ymin = lwr, ymax = upr), fill = &quot;red&quot;, alpha = 0.1) + ylim(3, 6.5) We’ll also produce a correlation matrix, firstly defining the type of correlation we want corMethod &lt;- &quot;pearson&quot; and then using this variable inside a further command: cor(flintDf, method = corMethod) ## breadth length ## breadth 1.0000000 0.9294603 ## length 0.9294603 1.0000000 Now suppose we want to try a different type/size of interval, or a different correlation method. We would redefine our variables cpLevel, intervalType and/or corMethod, for example, to be cpLevel &lt;- 0.9 intervalType &lt;- &quot;confidence&quot; corMethod &lt;- &quot;spearman&quot; and run the rest of the code again. This may not be very convenient, and if we wanted a ‘client’ to be able to make such changes; he/she would have to know how to use R. 23.2 Putting the code inside an app We’re now going to create a shiny app, where the user can change the three variables cpLevel, intervalType and corMethod at any time. Whenever one of these variables is changed, the new plot or correlation will be displayed as appropriate. A shiny app has two components: a user interface ui, where the controls are specified and the outputs are arranged, and a server, where all the R computation is done. The structure of the code will look like something like this: ui &lt;- fluidPage(# controls and outputs to be specified here ) server &lt;- function(input, output) { # computations to be done here } # Run the application shinyApp(ui = ui, server = server) Open the file flint-app-simple.R and click on Run App to run the app. Try it out, have a look at the code, and then continue below for discussion of how the app works. (You will need to close the app before you can use the R console again.) 23.3 The user interface ui A user interface can have three types of commands: specifying user controls, producing outputs, and modifying the layout/appearance of the app. Commands within ui need to end in a comma, unless they are either the final command in ui, or they are the final command nested within another command This takes a little getting used to, and can be a common source of bugs in shiny apps! Look carefully again at flint-app-simple.R. 23.3.1 Commands (“widgets”) for creating user controls and inputs In our example, we had three variables that we wanted to change easily: cpLevel, intervalType, corMethod. In the app, within the user interface ui, we define a widget where the app user can specify the value of a variable. There are lots of different types of widgets, depending on the type of variable the user is specifying (e.g. numerical or string). For example, to allow the app user to define the cpLevel variable, we define a numericInput widget inside the ui definition: numericInput(inputId = &quot;cpLevel&quot;, label = &quot;Interval level (%)&quot;, min = 0, max = 100, value = 95, step = 1) The variable name is the inputID argument. To use a variable created in ui in the server, we must add the prefix input$. So, for example, to use the variable cpLevel in the server, we must refer to it as input$cpLevel. Figure 23.1: The top image shows part of the ui definition, in which the variables intervalType and cpLevel are defined via the widgets radioButtons and numericInput. The bottom image shows the use of these variables in the server definition. Note the input$ prefix: the variables are referred to as input$intervalType and input$cpLevel. In the app interface, the variable will be described by the text in label. We can also specify a minimum (min), maximum (max), a default value (value), and a step size (step) for increasing/decreasing the variable if clicking on arrows. In the example flint-app-simple.R, we used two other widgets, radioButtons(), and selectInput() to define intervalType and corMethod respectively. The widget gallery at RStudio is a good place to see examples of more widgets. 23.3.2 Commands for producing outputs An output is typically a plot, a table, or a single numerical value. In our example app, we want a plot and a table (correlation matrix), which we produce with these commands plotOutput() and tableOutput() inside our definition of ui. plotOutput(&quot;scatterPlot&quot;), tableOutput(&quot;correlations&quot;) We choose scatterPlot and correlations as labels for use inside server. Commands can also be added for determining the layout and appearance of the app; we haven’t used any of these yet, but will add some in later on. 23.4 The server Here, we put the commands to do the computation and make the various outputs we have declared in our user interface; the commands that will actually draw a plot, for example. Firstly, we put the commands for loading the data and fitting the model inside server: flintDf &lt;- read_table(&quot;flintsdata.txt&quot;) lmFlint &lt;- lm(length ~ breadth, flintDf) These could have gone in the script (before server is defined), but not inside the definition of ui. (In some situations, you will need to think carefully about where exactly commands are placed, but we don’t need to worry about this now.) 23.4.1 Making a plot Firstly, recall that in our ui definition, we had the code plotOutput(&quot;scatterPlot&quot;) so, inside server, we will need to create something called output$scatterPlot, defined with a function renderPlot({}) to make this plot. All our earlier code for making the plot can go inside the renderPlot({}), with one modification: we now refer to the variables cpLevel and intervalType with the syntax input$cpLevel and input$intervalType: output$scatterPlot &lt;- renderPlot({ intervalDf &lt;- cbind(flintDf, predict(lmFlint, interval = input$intervalType, level = input$cpLevel / 100)) ggplot(intervalDf, aes(x = breadth, y = length)) + labs(x = &quot;flint tool breadth (cm)&quot;, y = &quot;flint tool length (cm)&quot;) + geom_line(aes(y = fit)) + geom_point() + geom_ribbon(aes(ymin = lwr, ymax = upr), fill = &quot;red&quot;, alpha = 0.1) + ylim(3, 6.5) }) 23.4.2 Making a table The table is constructed similarly, using the command renderTable({}). We defined our output in ui as correlations, and the user-specified variable we need is corMethod. So within server, we define output$correlations &lt;- renderTable({ cor(flintDf, method = input$corMethod) }) 23.5 Reactivity An important concept to understand, that (within R) is particular to shiny is that of reactivity: this is where the magic happens! How does R know it should redraw the plot/table when an input changes? In the shiny version of the code, cpLevel, intervalType and corMethod are all specially defined as reactive variables. This means that shiny is on the look-out for when these variables change their values: it will know that the current plot/table are ‘invalid’, and need redrawing, using the updated values. Reactive variables can also be defined within the server, but we won’t cover this here. We have to be careful where we try to call a reactive variable: shiny will complain if we try to call one outside a ‘reactive context’. For example, if we move the definition intervalDf &lt;- cbind(flintDf, predict(lmFlint, interval = input$type, level = input$cpLevel / 100))) outside the output$scatterPlot &lt;- renderPlot({}) definition, we will get an error message (try putting the command straight after the definition of lmFlint). Exercise 23.1 Open the script medals-script.R, and first run the code to produce a plot of total medals against population size with either a raw or log 10 transformed \\(x\\)-axis; a medals table, either ranked by number of gold, or number of golds divided by the country’s population size. Now produce an app where the user can switch between axis type and medal ranking format, with an option of how many countries are displayed in the table. You will probably find it easiest to make a copy of flint-app.R and modify that. 23.6 Customising the appearance of your app You can include various commands in ui to change the appearance of your app. A few useful ones are as follows titlePanel() for adding a title; sidebarPanel() and mainPanel() for having the widgets displayed on the left side, and the outputs shown in the right; tabsetPanel() and tabPanel() for splitting up multiple outputs into different tabs. Commands will need to be nested, and you have to be even more careful where to put the commas! Open up the file flint-app-modified.R and run the app to see some examples (and look carefully to see where the commas go!) Exercise 23.2 Try modifying your Olympic medals app to include a title, a sidebar and main panel, and tabs. 23.7 Shiny with R Markdown You can embed a Shiny app inside an R Markdown (html) document. If you want to include text, static images and so on, this may be more convenient that incorporating these directly in the app with html commands. You just need to add an extra argument in the YAML header, and then Shiny commands will work: --- title: &quot;My shiny app&quot; author: &quot;Jeremy Oakley&quot; output: html_document runtime: shiny --- For an example, see the file flint-app-document.Rmd. 23.8 Further reading This section has covered the main ideas you will need for this module (though you may want to try out other widgets). There are some excellent materials for further study available at https://shiny.rstudio.com/tutorial/. In particular some topics for suggested reading/viewing are as follows. shiny modules. If you are designing a more complex app, the length of your code may become awkward to manage and/or you may want to repeated use of the same elements within an app. shiny modules can be useful here. Generating downloadable reports. A disadvantage of using a shiny app is that it can be hard to record how you used it: what values you gave to the inputs and so on. One option is to use R markdown to generate a report for downloading, making use of the input values currently selected in the app. Automated testing. How to test whether your app does what it is supposed to, and if you make changes, how to you check that you haven’t accidentally broken your app. Reactivity (and also part 2) If you really want to get your head around reactivity, I recommend these two videos, that include programming exercises. You will need to be comfortable with the shiny basics. Online textbook: Mastering Shiny A print copy is also available. More on shiny in R Markdown documents from Chapter 19 of R Markdown: The Definitive Guide. References Chang, Winston, Joe Cheng, JJ Allaire, Yihui Xie, and Jonathan McPherson. 2020. Shiny: Web Application Framework for r. https://CRAN.R-project.org/package=shiny. "],["eda-for-logistic-regression.html", "Section 24 EDA for logistic regression 24.1 Example: a balance study 24.2 What to look for in an EDA 24.3 Investigating the experimental design 24.4 Contingency tables 24.5 Checking for identical responses 24.6 Exploratory plots 24.7 Plotting mean proportions 24.8 Plotting fitted logistic regression lines 24.9 Summary", " Section 24 EDA for logistic regression In this section, we will illustrate an exploratory data analysis for a logistic regression modelling exercise. Two aims of an EDA would be to understand what models can be fitted; to see what terms can and cannot be included in a model; to indicate what conclusions we might make from the modelling, so that we can be more alert to mistakes or problems later on. 24.1 Example: a balance study We will use an example given in (Faraway 2016a), Section 13.3. (I have also used some of the code provided there). There is a chain of sources for these data! I obtained the data via the package faraway (Faraway 2016b), which in turn got the data from the “OzDasl”: the Australasian Data and Story Library, and the original source for the data is (Steele 1998). For details, see the help file ?faraway::ctsib. Quoting the description from the help file: An experiment was conducted to study the effects of surface and vision on balance. The balance of subjects were observed for two different surfaces and for restricted and unrestricted vision. Balance was assessed qualitatively on an ordinal four-point scale based on observation by the experimenter. Forty subjects were studied, twenty males and twenty females ranging in age from 18 to 38, with heights given in cm and weights in kg. The subjects were tested while standing on foam or a normal surface and with their eyes closed or open or with a dome placed over their head. Each subject was tested twice in each of the surface and eye combinations for a total of 12 measures per subject. The dependent variable CTSIB was on four point ordinal scale, with 1 meaning ‘stable’ and 4 meaning ‘unstable’. Faraway converted it to binary variable: 1 to represent the original level 1, and 0 to represent the original levels 2-4. I will do the same, and also add in a random, dummy covariate, which we will know for certain is independent of the response. I will also convert the Subject variable (representing the 40 participants in the experiment) to a factor variable: set.seed(123) balance &lt;- faraway::ctsib %&gt;% mutate(Stable = ifelse(CTSIB ==1, 1, 0), Subject = factor(Subject), Dummy = round(rnorm(480), 1)) so the data for our EDA are in the data frame balance: head(balance) ## Subject Sex Age Height Weight Surface Vision CTSIB Stable Dummy ## 1 1 male 22 176 68.2 norm open 1 1 -0.6 ## 2 1 male 22 176 68.2 norm open 1 1 -0.2 ## 3 1 male 22 176 68.2 norm closed 2 0 1.6 ## 4 1 male 22 176 68.2 norm closed 2 0 0.1 ## 5 1 male 22 176 68.2 norm dome 1 1 0.1 ## 6 1 male 22 176 68.2 norm dome 2 0 1.7 24.1.1 Terminology We’ll refer to Stable as the dependent variable, with the observed value referred to as responses. All the other variables are referred to as independent variables, but we will additionally classify Surface and Vision as design variables (these were controlled by the experimenter); Sex, Age, Height and Weight as (participant-specific) covariates; Subject as the grouping variable: we have 40 groups of observations, one group per participant. Note that Surface, Vision, Sex and Subject are all factor independent variables, as they are all qualitative rather than quantitative. 24.2 What to look for in an EDA We’ll aim to develop a general understanding of the data, but there is one critical thing to check: If there is a setting of the factor independent variables, for which the dependent variable is observed always to take the same value (always 1 or always 0), we will have problems modelling that particular factor setting. Suppose we have a model of the form \\[ Y_{ij} \\sim Bernoulli(p_{i}),\\quad \\log\\left(\\frac{p_{i}}{1-p_{i}}\\right) = \\mu_i \\] where \\(i=1,\\ldots,I\\) represents a group, and \\(j=1,\\ldots,n_i\\) represents an observation within a group. If, for example, all our observations in group \\(i=2\\) were 1s (so we have observations \\(y_{2j}=1\\) for all \\(j\\)), then the likelihood function would be maximised at \\(p_2=1\\), i.e. \\(\\mu_2=\\infty\\). We couldn’t fit this model with ordinary maximum likelihood, but a Bayesian approach might work (we’d need to supplement the data with other information about \\(\\mu_2\\).) 24.2.1 What to plot When doing an EDA before ordinary linear modelling, we might make scatter plots of the response variable against each (continuous) independent variable, and box plots of the dependent variable against each factor independent variable. We have to think more carefully about what to plot here; the dependent variable can only be 0 or 1, so basic scatter plots/box plots won’t be helpful. Two possibilities are: box plots of continuous independent variable, with the dependent variable thought of as the group variable. This will help us see if a particular response (1 or 0) tends to be associated with low/high values of an independent variable. a scatter plot of the proportion of ‘1’ responses against a continuous independent variables, if there are groups of observations with the common values of the independent variable. 24.3 Investigating the experimental design Firstly, we might look at the data for a single Subject, and just examine the response and design variables. (The data description in ?faraway::ctsib tells us that we have a complete factorial design with respect to the design factors and participants, with two replications per combination, but we’ll check this anyway.) balance %&gt;% filter(Subject ==1) %&gt;% select(Surface, Vision, Stable) ## Surface Vision Stable ## 1 norm open 1 ## 2 norm open 1 ## 3 norm closed 0 ## 4 norm closed 0 ## 5 norm dome 1 ## 6 norm dome 0 ## 7 foam open 0 ## 8 foam open 0 ## 9 foam closed 0 ## 10 foam closed 0 ## 11 foam dome 0 ## 12 foam dome 0 We’ll check the levels of the factor variables Surface and Vision: levels(balance$Surface) ## [1] &quot;foam&quot; &quot;norm&quot; levels(balance$Vision) ## [1] &quot;closed&quot; &quot;dome&quot; &quot;open&quot; So this confirms that we have each combination of factors, replicated twice, for the first subject. We can check all subjects have same number of observations for each surface and vision level, using the count() function to count the number of observations per combination, and then using the summary() function to check that this number is 2 for all combinations. balance %&gt;% count(Subject, Vision, Surface) %&gt;% pull(n) %&gt;% summary() ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 2 2 2 2 2 2 This confirms that for every Subject, there are two replications for each combination of Vision and Surface. 24.4 Contingency tables We can use the xtabs() function to make contingency tables of responses. If the data were unbalanced we’d need to interpret these a little more cautiously, and be alert to Simpson’s paradox. xtabs( ~ Sex + Stable, data = balance) ## Stable ## Sex 0 1 ## female 193 47 ## male 173 67 xtabs( ~ Surface + Stable, data = balance) ## Stable ## Surface 0 1 ## foam 230 10 ## norm 136 104 xtabs( ~ Vision + Stable, data = balance) ## Stable ## Vision 0 1 ## closed 143 17 ## dome 138 22 ## open 85 75 So in conclusion, there appear to be clear effects of Surface and Vision, in the way that we would expect, but there does not appear to be an effect of Sex. 24.5 Checking for identical responses We will first examine the design factors, and see if there any combinations for which all the responses were stable (or all unstable.) We can compute the proportion of stable responses by calculating the mean of Stable for each combination of Surface and Vision: balance %&gt;% group_by(Surface, Vision) %&gt;% summarise(proportion = mean(Stable), .groups = &#39;drop&#39;) ## # A tibble: 6 × 3 ## Surface Vision proportion ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 foam closed 0 ## 2 foam dome 0 ## 3 foam open 0.125 ## 4 norm closed 0.212 ## 5 norm dome 0.275 ## 6 norm open 0.812 Alternatively, we can obtain a contingency table with the xtabs() command. We can count the total number of 1s for each combination of Surface and Vision levels, by specifying the dependent variable Stable in the formula argument: xtabs(Stable ~ Surface + Vision, data = balance) ## Vision ## Surface closed dome open ## foam 0 0 10 ## norm 17 22 65 All participants were unstable for foam-closed and foam-dome groups: this would cause problems if we tried to include interaction effects between the Vision and Surface variables. We’ll now see if there are any participants (Subject) who were always stable, or always unstable. We have 40 participants, so a contingency table would be quite large, but we can work out the proportion of 1s per Subject, and then make a contingency table of the proportions: balance %&gt;% group_by(Subject) %&gt;% summarise(meanStable = mean(Stable), .groups = &#39;drop&#39;) %&gt;% count(meanStable) ## # A tibble: 8 × 2 ## meanStable n ## &lt;dbl&gt; &lt;int&gt; ## 1 0 5 ## 2 0.0833 4 ## 3 0.167 15 ## 4 0.25 3 ## 5 0.333 4 ## 6 0.417 3 ## 7 0.5 4 ## 8 0.667 2 So there were five subjects who were always unstable. We’d have problems including Subject as a fixed effect, but we could incorporate it as a random effect, as there would be some shrinkage of the random effects towards 0. 24.6 Exploratory plots 24.6.1 A simple box plot For continuous independent variables, we can try box plots of each independent variable with the dependent variable treated as a grouping factor. We will create a new variable Stability: the dependent variable Stable, re-defined as a factor variable; we’ll need this for the box plots. balance &lt;- balance %&gt;% mutate(Stability = factor(balance$Stable)) levels(balance$Stability) &lt;- c(&quot;unstable&quot;, &quot;stable&quot;) We can then make a box plot, for example, of heights: ggplot(balance, aes(x = Stability, y = Height)) + geom_boxplot() 24.6.2 Interactions We can visualise possible interaction effects between a continuous independent variable and a factor independent variable, by setting additional aesthetics. We could map Sex to colour: ggplot(balance, aes(x = Stability, y = Height, colour = Sex)) + geom_boxplot() but this is perhaps a little confusing, because the main result this plot appears to present is the relationship between Sex and Height. It might be better to map the dependent variable onto colour here: ggplot(balance, aes(x = Sex, y = Height, colour = Stability)) + geom_boxplot() We will now draw box plots for all four continuous independent variables, again, split by sex. The plot involving the Dummy variable can be useful here, to give us an idea of what we might see purely by chance. balance &lt;- balance %&gt;% mutate(Stability = factor(balance$Stable)) levels(balance$Stability) &lt;- c(&quot;unstable&quot;, &quot;stable&quot;) p1 &lt;- ggplot(balance, aes(x = Sex, y = Height, colour = Stability)) + geom_boxplot() p2 &lt;- ggplot(balance, aes(x = Sex, y = Weight, colour = Stability)) + geom_boxplot() p3 &lt;- ggplot(balance, aes(x = Sex, y = Age, colour = Stability)) + geom_boxplot() p4 &lt;- ggplot(balance, aes(x = Sex, y = Dummy, colour = Stability)) + geom_boxplot() gridExtra::grid.arrange(p1, p2, p3,p4, ncol = 2) 24.7 Plotting mean proportions If we compute the proportion of stable responses for each subject, that gives us a quantitative dependent variable that we can use in plots involving the participant-specific covariates. We’ll make a new data frame, and include the height variable as an example: balanceGrouped &lt;- balance %&gt;% group_by(Subject) %&gt;% summarise(proportionStable = mean(Stable), Sex = Sex[1], Height = Height[1], .groups = &#39;drop&#39;) head(balanceGrouped) ## # A tibble: 6 × 4 ## Subject proportionStable Sex Height ## &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 1 0.25 male 176 ## 2 2 0.167 male 181 ## 3 3 0 male 176. ## 4 4 0.0833 male 180 ## 5 5 0.0833 female 166 ## 6 6 0.417 male 177 Now we can make a scatter plot (with points coloured by Sex): ggplot(balanceGrouped, aes(x = Height, y = proportionStable, col = Sex))+ geom_point() 24.8 Plotting fitted logistic regression lines 24.8.1 Plots with Bernoulli data We can add fitted regression lines easily with the geom_smooth command. To visualise how this works more easily, we’ll generate a dataset from a logistic regression model \\[ Y_i|x_i \\sim Bernoulli(p_i),\\quad\\quad \\log\\left(\\frac{p_i}{1-p_i}\\right) = x_i. \\] set.seed(1) x &lt;- seq(from = -5, to = 5, length = 100) p &lt;- exp(x) / (1+exp(x)) y &lt;- rbinom(100, 1, p) df1 &lt;- data.frame(x, y, p) We can then draw a scatter plot as normal, and add in some extra arguments to geom_smooth() to specify the model. (This uses the syntax from the glm command: this will be covered in detail in Semester 2.) We’ll also add in the true regression line, as a red dashed line. ggplot(df1, aes(x = x, y = y))+ geom_point()+ geom_smooth(method=&quot;glm&quot;, formula = &#39;y~x&#39;, method.args=list(family=&quot;binomial&quot;), se=TRUE) + geom_line(aes(y = p), col = &quot;red&quot;, linetype = &quot;dashed&quot;) 24.8.2 Plots with Binomial \\((n&gt;1)\\) data If the data can be grouped by the covariate value, it may be preferable to plot proportions on the \\(y\\) axis. Suppose our model is \\[ Y_{ij}|x_i \\sim Bernoulli(p_i),\\quad\\quad \\log\\left(\\frac{p_i}{1-p_i}\\right) = x_i, \\quad j= 1,\\ldots,n_i, \\] so that \\[ \\sum_{j=1}^{n_i}Y_{ij}|x_i \\sim Binomial(n_i, p_i) \\] Given the observations \\(y_{ij}\\), we can plot \\(\\frac{1}{n_i}\\sum_{j=1}^{n_i}y_{ij}\\) against \\(x_i\\). To illustrate this, first, we’ll make an example data set. set.seed(1) x &lt;- seq(from = -5, to = 5, length = 10) p &lt;- exp(x) / (1+exp(x)) y &lt;- rbinom(10, 10, p) df2 &lt;- data.frame(x, proportion = y / 10, p, n = 10) We will need to map the sample sizes \\(n_i\\) to an aesthetic weight. ggplot(df2, aes(x = x, y = proportion, weight = n))+ geom_point()+ geom_smooth(method=&quot;glm&quot;, formula = &#39;y~x&#39;, method.args=list(family=&quot;binomial&quot;), se=TRUE) + geom_line(aes(y = p), col = &quot;red&quot;, linetype = &quot;dashed&quot;) We can try this on the balance data. I’d leave out the standard errors in the geom_smooth(), as the model assumptions are (probably ) not valid here; this plot ignores Subject, Vision and Surface effects. balanceGrouped %&gt;% mutate(w = 12) %&gt;% ggplot(aes(x = Height, y = proportionStable, weight = w, col = Sex)) + geom_point() + geom_smooth(method=&quot;glm&quot;, method.args=list(family=&quot;binomial&quot;), se = FALSE) 24.9 Summary To summarise what we’ve learned from our EDA: Vision and Surface clearly have an effect on the dependent variable; we would have problems fitting a logistic regression model with a Vision-Surface interaction, and/or fixed effects for Subject (unless we tried a Bayesian approach; priors could help here.) there does appear to be variability between Subjects; we should incorporate Subject as a random effect; the Subject specific covariates (Age, Sex, Height, Weight) don’t appear to have significant effects, perhaps with the exception of a Sex-Height interaction, though the evidence is likely to be weak. References Faraway, Julian J. 2016a. Extending the Linear Model with r : Generalized Linear, Mixed Effects and Nonparametric Regression Models. Second edition. A Chapman and Hall Book. Boca Raton, Florida ; London, [England] ; New York: CRC Press. ———. 2016b. Faraway: Functions and Datasets for Books by Julian Faraway. https://CRAN.R-project.org/package=faraway. Steele, R. 1998. “Effect of Surface and Vision on Balance.” PhD thesis, University of Queensland: Department of Physiotherapy. "],["example-working-with-strings.html", "Section 25 Example: working with strings 25.1 Importing the two data files 25.2 Preliminary tidying 25.3 Approximately matching strings 25.4 Assembling the target data frame", " Section 25 Example: working with strings In this section we’ll discuss some code used to create the file universities.csv used in a Case Study. The main features of this example are as follows. We want to extract some data corresponding to universities from a larger dataset of many different employers. We can obtain a separate list of universities, but names in this list may not match precisely the names in the first dataset. For example, in one dataset, the name will be UNIVERSITY OF SHEFFIELD, but in another it will be The University of Sheffield. We’d also like to import all the data directly from the web. One of the files is accessed via an API at the OfS Register, but we have already shown how to import it in Section 16.2. 25.1 Importing the two data files The main data set we are interested in is from the Gender pay gap service. We import the data for the year 2021-22: library(tidyverse) pay22 &lt;- read_csv(&quot;https://gender-pay-gap.service.gov.uk/viewing/download-data/2021&quot;) This file has data for about 10,000 employers. Using the code from Section 16.2, we import the list of universities from the Office for Students. Note that I’ve looked at this file already, and know that I want to skip the first two rows. endpoint &lt;- &quot;https://register-api.officeforstudents.org.uk/api/Download&quot; response &lt;- httr::GET( url = endpoint) raw_xlsx &lt;- httr::content(response) tmp &lt;- tempfile(fileext = &#39;.xlsx&#39;) writeBin(raw_xlsx, tmp) ofs &lt;- readxl::read_excel(tmp, skip = 2) 25.2 Preliminary tidying We need to do a little tidying up of the ofs data frame, and we would also like to create a column to indicate whether a university is a pre-92 or a post-92. We are interested in four columns: colnames(ofs)[c(1, 3, 18, 19)] ## [1] &quot;Provider’s legal name&quot; ## [2] &quot;Provider’s trading name(s)&quot; ## [3] &quot;Does the provider have the right to use ‘university’ in its title?&quot; ## [4] &quot;Date that use of &#39;university&#39; was granted&quot; We will simplify the names: colnames(ofs)[1] &lt;- &quot;legal&quot; colnames(ofs)[3] &lt;- &quot;trading&quot; colnames(ofs)[18] &lt;- &quot;university&quot; colnames(ofs)[19] &lt;- &quot;year&quot; Now we extract the universities from the OfS register: ofs %&gt;% filter(university == &quot;Yes&quot;) %&gt;% select(legal, trading, year) -&gt; universities We clean up the year and legal (name) variable for Oxbridge: tempIndex &lt;- which(nchar(universities$year) &gt; 4) universities$year[tempIndex] &lt;- 1571 universities$year &lt;- as.numeric(universities$year) universities$legal[tempIndex] ## [1] &quot;The Chancellor, Masters, and Scholars of the University of Cambridge&quot; ## [2] &quot;The Chancellor, Masters and Scholars of the University of Oxford&quot; universities$legal[tempIndex] &lt;- c(&quot;The University of Cambridge&quot;, &quot;The University of Oxford&quot;) Now we create a column to record whether each university is a pre-92 or post-92: universities$pre92 &lt;- ifelse(universities$year &lt; 1992, &quot;yes&quot;, &quot;no&quot;) 25.3 Approximately matching strings We want to find the universities in the data frame pay22 according to the names in universities (we’ll look for both the legal and trading names), but these names may not match precisely in the two data frames. We’ll try the following: change all letters to lower case; remove ‘stop words’ (small ‘insignificant’ words such as ‘the’ and ‘of’) using the package tm (Feinerer, Hornik, and Meyer 2008); arranging the words within a name in alphabetical order (thanks to this post on Stack Overflow); removing various characters such as brackets. We’ll write a function to do this: cleanUpNames &lt;- function(x){ # first change to lower case, then remove stopwords tolower(x) %&gt;% tm::removeWords(tm::stopwords()) -&gt; namesTemp # Split string into separate words, sort # words into alphabetical order, then collapse # words back into single string sapply(lapply(strsplit(namesTemp, &quot; &quot;), sort), paste, collapse=&quot; &quot;) %&gt;% str_remove_all(&quot;,&quot;) %&gt;% str_remove_all(&quot;&amp;&quot;) %&gt;% str_remove_all(&quot;\\\\[\\\\]&quot;) %&gt;% str_remove_all(&quot;\\\\(\\\\)&quot;) %&gt;% str_trim() } Now we’ll use the function to clean up each column of names: uNamesLegalClean &lt;- cleanUpNames(universities$legal) uNamesTradingClean &lt;- cleanUpNames(universities$trading) pNamesClean &lt;- cleanUpNames(pay22$EmployerName) We’ll see how many universities we can find in the pay gap data, using both the legal and trading names: sum(is.element(pNamesClean, uNamesLegalClean)) ## [1] 87 sum(is.element(pNamesClean, uNamesTradingClean)) ## [1] 25 25.4 Assembling the target data frame We now add the vector of cleaned names to pay22, find all the universities we can, then extract the original and cleaned names, and also the EmployerId column: pay22 %&gt;% mutate(pNamesClean = pNamesClean) %&gt;% filter(pNamesClean %in% uNamesTradingClean | pNamesClean %in% uNamesLegalClean) %&gt;% select(pNamesClean, EmployerName, EmployerId) -&gt; pay22NameId We’ll add the cleaned names to the universities data frame as well. universities %&gt;% mutate(uNamesTradingClean = uNamesTradingClean, uNamesLegalClean = uNamesLegalClean) -&gt; universities Finally, we’ll merge the two data frames, and get rid of any duplicate rows: uni &lt;- distinct( rbind(inner_join(pay22NameId, universities, by = c(&quot;pNamesClean&quot; = &quot;uNamesTradingClean&quot;)) %&gt;% select(EmployerName, EmployerId, pre92), inner_join(pay22NameId, universities, by = c(&quot;pNamesClean&quot; = &quot;uNamesLegalClean&quot;)) %&gt;% select(EmployerName, EmployerId, pre92))) From inspection, we need to correct the pre-92 status for some London universities: uni[c(5, 46),] ## # A tibble: 2 × 3 ## EmployerName EmployerId pre92 ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Imperial College London 6539 no ## 2 LONDON SOUTH BANK UNIVERSITY 7820 no uni[c(5, 46), &quot;pre92&quot;] &lt;- &quot;yes&quot; Finally, we can output the data to .csv write_csv(uni, &quot;universities.csv&quot;) References Feinerer, Ingo, Kurt Hornik, and David Meyer. 2008. “Text Mining Infrastructure in r.” Journal of Statistical Software 25 (5): 1–54. https://www.jstatsoft.org/v25/i05/. "],["references-1.html", "References", " References Allaire, JJ, Yihui Xie, Jonathan McPherson, Javier Luraschi, Kevin Ushey, Aron Atkins, Hadley Wickham, Joe Cheng, Winston Chang, and Richard Iannone. 2020. Rmarkdown: Dynamic Documents for r. https://CRAN.R-project.org/package=rmarkdown. Auguie, Baptiste. 2017. gridExtra: Miscellaneous Functions for \"Grid\" Graphics. https://CRAN.R-project.org/package=gridExtra. Chang, Winston, Joe Cheng, JJ Allaire, Yihui Xie, and Jonathan McPherson. 2020. Shiny: Web Application Framework for r. https://CRAN.R-project.org/package=shiny. Cheng, Joe, Bhaskar Karambelkar, and Yihui Xie. 2019. Leaflet: Create Interactive Web Maps with the JavaScript ’Leaflet’ Library. https://CRAN.R-project.org/package=leaflet. Faraway, Julian J. 2016a. Extending the Linear Model with r : Generalized Linear, Mixed Effects and Nonparametric Regression Models. Second edition. A Chapman and Hall Book. Boca Raton, Florida ; London, [England] ; New York: CRC Press. ———. 2016b. Faraway: Functions and Datasets for Books by Julian Faraway. https://CRAN.R-project.org/package=faraway. Feinerer, Ingo, Kurt Hornik, and David Meyer. 2008. “Text Mining Infrastructure in r.” Journal of Statistical Software 25 (5): 1–54. https://www.jstatsoft.org/v25/i05/. Moritz, Steffen, and Thomas Bartz-Beielstein. 2017. “imputeTS: Time Series Missing Value Imputation in R.” The R Journal 9 (1): 207–18. https://doi.org/10.32614/RJ-2017-009. Müller, Kirill, and Hadley Wickham. 2020. Tibble: Simple Data Frames. https://CRAN.R-project.org/package=tibble. Ooms, Jeroen. 2014. “The Jsonlite Package: A Practical and Consistent Mapping Between JSON Data and r Objects.” arXiv:1403.2805 [Stat.CO]. https://arxiv.org/abs/1403.2805. R Core Team. 2020. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/. RStudio Team. 2020. RStudio: Integrated Development Environment for r. Boston, MA: RStudio, PBC. http://www.rstudio.com/. Slowikowski, Kamil. 2020. Ggrepel: Automatically Position Non-Overlapping Text Labels with ’Ggplot2’. https://CRAN.R-project.org/package=ggrepel. Steele, R. 1998. “Effect of Surface and Vision on Balance.” PhD thesis, University of Queensland: Department of Physiotherapy. Wickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org. ———. 2019a. Stringr: Simple, Consistent Wrappers for Common String Operations. https://CRAN.R-project.org/package=stringr. ———. 2019b. Tidyverse: Easily Install and Load the ’Tidyverse’. https://CRAN.R-project.org/package=tidyverse. ———. 2020. Httr: Tools for Working with URLs and HTTP. https://CRAN.R-project.org/package=httr. Wickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686. Wickham, Hadley, and Jennifer Bryan. 2019. Readxl: Read Excel Files. https://CRAN.R-project.org/package=readxl. Wickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2020. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2. Wickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2020. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr. Wickham, Hadley, and Lionel Henry. 2020. Tidyr: Tidy Messy Data. https://CRAN.R-project.org/package=tidyr. Wickham, Hadley, Jim Hester, and Romain Francois. 2018. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr. Wickham, Hadley, and Evan Miller. 2020. Haven: Import and Export ’SPSS’, ’Stata’ and ’SAS’ Files. https://CRAN.R-project.org/package=haven. Xie, Yihui. 2014. “Knitr: A Comprehensive Tool for Reproducible Research in R.” In Implementing Reproducible Computational Research, edited by Victoria Stodden, Friedrich Leisch, and Roger D. Peng. Chapman; Hall/CRC. http://www.crcpress.com/product/isbn/9781466561595. ———. 2015. Dynamic Documents with R and Knitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. https://yihui.org/knitr/. ———. 2017. Bookdown: Authoring Books and Technical Documents with R Markdown. Boca Raton, Florida: Chapman; Hall/CRC. https://github.com/rstudio/bookdown. ———. 2020a. Bookdown: Authoring Books and Technical Documents with r Markdown. https://CRAN.R-project.org/package=bookdown. ———. 2020b. Knitr: A General-Purpose Package for Dynamic Report Generation in r. https://CRAN.R-project.org/package=knitr. Xie, Yihui, J. J. Allaire, and Garrett Grolemund. 2018. R Markdown: The Definitive Guide. Boca Raton, Florida: Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
