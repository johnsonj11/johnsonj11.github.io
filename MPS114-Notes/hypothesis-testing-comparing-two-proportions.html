<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Hypothesis testing: comparing two proportions | MPS114 - An Introduction to Data Science</title>
  <meta name="description" content="Lecture notes for MPS114" />
  <meta name="generator" content="bookdown 0.42 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Hypothesis testing: comparing two proportions | MPS114 - An Introduction to Data Science" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Lecture notes for MPS114" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Hypothesis testing: comparing two proportions | MPS114 - An Introduction to Data Science" />
  
  <meta name="twitter:description" content="Lecture notes for MPS114" />
  

<meta name="author" content="Dr Jill Johnson" />


<meta name="date" content="2026-02-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="hypothesis-testing-comparing-two-population-means.html"/>
<link rel="next" href="sample-size-and-power-for-a-neyman-pearson-hypothesis-test.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">MPS114 - Introduction to Data Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About these notes</a></li>
<li class="chapter" data-level="1" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html"><i class="fa fa-check"></i><b>1</b> Exploratory Data Analysis using R</a>
<ul>
<li class="chapter" data-level="1.1" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#case-study-what-makes-a-country-good-at-maths"><i class="fa fa-check"></i><b>1.1</b> Case study: what makes a country good at maths?</a></li>
<li class="chapter" data-level="1.2" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#the-tidyverse"><i class="fa fa-check"></i><b>1.2</b> The “Tidyverse”</a></li>
<li class="chapter" data-level="1.3" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#importing-data-into-r-csv-and-.xlsx-files"><i class="fa fa-check"></i><b>1.3</b> Importing data into R: <code>csv</code> and <code>.xlsx</code> files</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#importing-excel-.xlsx-files"><i class="fa fa-check"></i><b>1.3.1</b> Importing Excel <code>.xlsx</code> files</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#data-frames-and-tibbles-in-r"><i class="fa fa-check"></i><b>1.4</b> Data frames and tibbles in R</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#ordering-the-rows-by-a-variable-with-the-arrange-command"><i class="fa fa-check"></i><b>1.4.1</b> Ordering the rows by a variable with the <code>arrange()</code> command</a></li>
<li class="chapter" data-level="1.4.2" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#selecting-rows-with-the-filter-command"><i class="fa fa-check"></i><b>1.4.2</b> Selecting rows with the <code>filter()</code> command</a></li>
<li class="chapter" data-level="1.4.3" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#viewing-and-extracting-data-from-a-column"><i class="fa fa-check"></i><b>1.4.3</b> Viewing and extracting data from a column</a></li>
<li class="chapter" data-level="1.4.4" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#creating-new-columns-in-a-data-frame-with-the-mutate-command"><i class="fa fa-check"></i><b>1.4.4</b> Creating new columns in a data frame with the <code>mutate()</code> command</a></li>
<li class="chapter" data-level="1.4.5" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#chaining-commands-together-with-the-pipe-operator"><i class="fa fa-check"></i><b>1.4.5</b> Chaining commands together with the pipe operator <code>%&gt;%</code></a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#calculating-summary-statistics-with-the-summary-command"><i class="fa fa-check"></i><b>1.5</b> Calculating summary statistics with the <code>summary()</code> command</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#calculating-individual-summary-statistics"><i class="fa fa-check"></i><b>1.5.1</b> Calculating individual summary statistics</a></li>
<li class="chapter" data-level="1.5.2" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#calculating-other-quantilespercentiles"><i class="fa fa-check"></i><b>1.5.2</b> Calculating other quantiles/percentiles</a></li>
<li class="chapter" data-level="1.5.3" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#computing-summaries-per-group"><i class="fa fa-check"></i><b>1.5.3</b> Computing summaries per group</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#plotting-a-distribution-using-a-histogram"><i class="fa fa-check"></i><b>1.6</b> Plotting a distribution using a histogram</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#describing-the-shape-of-a-distribution-skewness"><i class="fa fa-check"></i><b>1.6.1</b> Describing the shape of a distribution: skewness</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#introducing-ggplot2"><i class="fa fa-check"></i><b>1.7</b> Introducing <code>ggplot2</code></a></li>
<li class="chapter" data-level="1.8" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#drawing-a-histogram-in-r"><i class="fa fa-check"></i><b>1.8</b> Drawing a histogram in R</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#customising-a-histogram-plot-in-r"><i class="fa fa-check"></i><b>1.8.1</b> Customising a histogram plot in R</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#covariance-and-correlation"><i class="fa fa-check"></i><b>1.9</b> Covariance and correlation</a>
<ul>
<li class="chapter" data-level="1.9.1" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#calculating-a-covariance-in-r"><i class="fa fa-check"></i><b>1.9.1</b> Calculating a covariance in R</a></li>
<li class="chapter" data-level="1.9.2" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#pearsons-correlation-coefficient"><i class="fa fa-check"></i><b>1.9.2</b> Pearson’s correlation coefficient</a></li>
<li class="chapter" data-level="1.9.3" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#calculating-pearsons-correlation-coefficient-in-r"><i class="fa fa-check"></i><b>1.9.3</b> Calculating Pearson’s correlation coefficient in R</a></li>
<li class="chapter" data-level="1.9.4" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#spearmans-correlation-coefficient"><i class="fa fa-check"></i><b>1.9.4</b> Spearman’s correlation coefficient</a></li>
<li class="chapter" data-level="1.9.5" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#calculating-spearmans-correlation-coefficient-in-r"><i class="fa fa-check"></i><b>1.9.5</b> Calculating Spearman’s correlation coefficient in R</a></li>
<li class="chapter" data-level="1.9.6" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#interpreting-correlation-coefficients"><i class="fa fa-check"></i><b>1.9.6</b> Interpreting correlation coefficients</a></li>
<li class="chapter" data-level="1.9.7" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#correlations-for-the-maths-data-set"><i class="fa fa-check"></i><b>1.9.7</b> Correlations for the <code>maths</code> data set</a></li>
</ul></li>
<li class="chapter" data-level="1.10" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#drawing-a-scatter-plot-in-r"><i class="fa fa-check"></i><b>1.10</b> Drawing a scatter plot in R</a>
<ul>
<li class="chapter" data-level="1.10.1" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#customising-a-scatter-plot-in-r"><i class="fa fa-check"></i><b>1.10.1</b> Customising a scatter plot in R</a></li>
<li class="chapter" data-level="1.10.2" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#adding-a-nonlinear-trend-to-a-scatter-plot-in-r"><i class="fa fa-check"></i><b>1.10.2</b> Adding a nonlinear trend to a scatter plot in R</a></li>
<li class="chapter" data-level="1.10.3" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#adding-a-linear-trend-to-a-scatter-plot-in-r"><i class="fa fa-check"></i><b>1.10.3</b> Adding a linear trend to a scatter plot in R</a></li>
</ul></li>
<li class="chapter" data-level="1.11" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#box-plots"><i class="fa fa-check"></i><b>1.11</b> Box plots</a></li>
<li class="chapter" data-level="1.12" data-path="exploratory-data-analysis-using-r.html"><a href="exploratory-data-analysis-using-r.html#scatter-plots-to-represent-three-variables"><i class="fa fa-check"></i><b>1.12</b> Scatter plots to represent three variables</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="machine-learning.html"><a href="machine-learning.html"><i class="fa fa-check"></i><b>2</b> Machine Learning</a>
<ul>
<li class="chapter" data-level="2.1" data-path="machine-learning.html"><a href="machine-learning.html#can-we-teach-a-computer-to-identify-handwritten-digits"><i class="fa fa-check"></i><b>2.1</b> Can we teach a computer to identify handwritten digits?</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="machine-learning.html"><a href="machine-learning.html#step-1-converting-an-image-into-data"><i class="fa fa-check"></i><b>2.1.1</b> Step 1: converting an image into data</a></li>
<li class="chapter" data-level="2.1.2" data-path="machine-learning.html"><a href="machine-learning.html#step-2-assembling-the-training-data-set"><i class="fa fa-check"></i><b>2.1.2</b> Step 2: assembling the training data set</a></li>
<li class="chapter" data-level="2.1.3" data-path="machine-learning.html"><a href="machine-learning.html#step-3-an-algorithm-for-estimating-the-digit-in-a-new-image"><i class="fa fa-check"></i><b>2.1.3</b> Step 3: an algorithm for estimating the digit in a new image</a></li>
<li class="chapter" data-level="2.1.4" data-path="machine-learning.html"><a href="machine-learning.html#the-k-nearest-neighbour-algorithm-knn"><i class="fa fa-check"></i><b>2.1.4</b> The <span class="math inline">\(K\)</span> nearest neighbour algorithm (KNN)</a></li>
<li class="chapter" data-level="2.1.5" data-path="machine-learning.html"><a href="machine-learning.html#using-k-nearest-neighbours-in-r"><i class="fa fa-check"></i><b>2.1.5</b> Using <span class="math inline">\(K\)</span> nearest neighbours in R</a></li>
<li class="chapter" data-level="2.1.6" data-path="machine-learning.html"><a href="machine-learning.html#the-performance-of-the-algorithm"><i class="fa fa-check"></i><b>2.1.6</b> The performance of the algorithm</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="populations-samples-and-statistical-models.html"><a href="populations-samples-and-statistical-models.html"><i class="fa fa-check"></i><b>3</b> Populations, samples and statistical models</a>
<ul>
<li class="chapter" data-level="3.1" data-path="populations-samples-and-statistical-models.html"><a href="populations-samples-and-statistical-models.html#statistical-models"><i class="fa fa-check"></i><b>3.1</b> Statistical models</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="populations-samples-and-statistical-models.html"><a href="populations-samples-and-statistical-models.html#objectives"><i class="fa fa-check"></i><b>3.1.1</b> Objectives</a></li>
<li class="chapter" data-level="3.1.2" data-path="populations-samples-and-statistical-models.html"><a href="populations-samples-and-statistical-models.html#comment-infinite-and-finite-populations"><i class="fa fa-check"></i><b>3.1.2</b> Comment: infinite and finite populations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="point-estimation.html"><a href="point-estimation.html"><i class="fa fa-check"></i><b>4</b> Point estimation</a>
<ul>
<li class="chapter" data-level="4.1" data-path="point-estimation.html"><a href="point-estimation.html#estimating-the-parameters-of-a-normal-distribution"><i class="fa fa-check"></i><b>4.1</b> Estimating the parameters of a normal distribution</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="point-estimation.html"><a href="point-estimation.html#problem-setup-and-notation"><i class="fa fa-check"></i><b>4.1.1</b> Problem setup and notation</a></li>
<li class="chapter" data-level="4.1.2" data-path="point-estimation.html"><a href="point-estimation.html#the-sample-mean-and-sample-variance"><i class="fa fa-check"></i><b>4.1.2</b> The sample mean and sample variance</a></li>
<li class="chapter" data-level="4.1.3" data-path="point-estimation.html"><a href="point-estimation.html#point-estimates-for-the-mean-and-variance"><i class="fa fa-check"></i><b>4.1.3</b> Point estimates for the mean and variance</a></li>
<li class="chapter" data-level="4.1.4" data-path="point-estimation.html"><a href="point-estimation.html#testing-the-method"><i class="fa fa-check"></i><b>4.1.4</b> Testing the method</a></li>
<li class="chapter" data-level="4.1.5" data-path="point-estimation.html"><a href="point-estimation.html#estimators-and-estimates"><i class="fa fa-check"></i><b>4.1.5</b> Estimators and estimates</a></li>
<li class="chapter" data-level="4.1.6" data-path="point-estimation.html"><a href="point-estimation.html#the-chi2-distribution"><i class="fa fa-check"></i><b>4.1.6</b> The <span class="math inline">\(\chi^2\)</span> distribution</a></li>
<li class="chapter" data-level="4.1.7" data-path="point-estimation.html"><a href="point-estimation.html#the-distribution-of-the-estimators"><i class="fa fa-check"></i><b>4.1.7</b> The distribution of the estimators</a></li>
<li class="chapter" data-level="4.1.8" data-path="point-estimation.html"><a href="point-estimation.html#unbiased-estimators"><i class="fa fa-check"></i><b>4.1.8</b> Unbiased estimators</a></li>
<li class="chapter" data-level="4.1.9" data-path="point-estimation.html"><a href="point-estimation.html#the-standard-error-of-an-estimator"><i class="fa fa-check"></i><b>4.1.9</b> The standard error of an estimator</a></li>
<li class="chapter" data-level="4.1.10" data-path="point-estimation.html"><a href="point-estimation.html#consistent-estimators"><i class="fa fa-check"></i><b>4.1.10</b> Consistent estimators</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="point-estimation.html"><a href="point-estimation.html#estimating-the-probability-parameter-in-a-binomial-distribution"><i class="fa fa-check"></i><b>4.2</b> Estimating the probability parameter in a Binomial distribution</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="interval-estimates-and-confidence-intervals.html"><a href="interval-estimates-and-confidence-intervals.html"><i class="fa fa-check"></i><b>5</b> Interval estimates and confidence intervals</a>
<ul>
<li class="chapter" data-level="5.1" data-path="interval-estimates-and-confidence-intervals.html"><a href="interval-estimates-and-confidence-intervals.html#the-student-t-distribution"><i class="fa fa-check"></i><b>5.1</b> The Student <span class="math inline">\(t\)</span> distribution</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="interval-estimates-and-confidence-intervals.html"><a href="interval-estimates-and-confidence-intervals.html#mean-and-variance-of-the-t-distribution"><i class="fa fa-check"></i><b>5.1.1</b> Mean and variance of the <span class="math inline">\(t\)</span>-distribution</a></li>
<li class="chapter" data-level="5.1.2" data-path="interval-estimates-and-confidence-intervals.html"><a href="interval-estimates-and-confidence-intervals.html#notation-quantilespercentiles-of-the-t-distribution"><i class="fa fa-check"></i><b>5.1.2</b> Notation: quantiles/percentiles of the <span class="math inline">\(t\)</span> distribution</a></li>
<li class="chapter" data-level="5.1.3" data-path="interval-estimates-and-confidence-intervals.html"><a href="interval-estimates-and-confidence-intervals.html#the-t-distribution-in-r."><i class="fa fa-check"></i><b>5.1.3</b> The <span class="math inline">\(t\)</span> distribution in R.</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="interval-estimates-and-confidence-intervals.html"><a href="interval-estimates-and-confidence-intervals.html#confidence-intervals-for-the-mean-and-the-variance-of-a-normal-distribution"><i class="fa fa-check"></i><b>5.2</b> Confidence intervals for the mean and the variance of a normal distribution</a></li>
<li class="chapter" data-level="5.3" data-path="interval-estimates-and-confidence-intervals.html"><a href="interval-estimates-and-confidence-intervals.html#confidence-interval-for-the-probability-parameter-in-a-binomial-distribution"><i class="fa fa-check"></i><b>5.3</b> Confidence interval for the probability parameter in a binomial distribution</a></li>
<li class="chapter" data-level="5.4" data-path="interval-estimates-and-confidence-intervals.html"><a href="interval-estimates-and-confidence-intervals.html#alpha-confidence-intervals"><i class="fa fa-check"></i><b>5.4</b> <span class="math inline">\(100(1-\alpha)\%\)</span> Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="hypothesis-testing-a-level-recap.html"><a href="hypothesis-testing-a-level-recap.html"><i class="fa fa-check"></i><b>6</b> Hypothesis testing: A-level recap</a>
<ul>
<li class="chapter" data-level="6.1" data-path="hypothesis-testing-a-level-recap.html"><a href="hypothesis-testing-a-level-recap.html#hypothesis-testing-with-the-neyman-pearson-approach"><i class="fa fa-check"></i><b>6.1</b> Hypothesis testing with the Neyman-Pearson approach</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="hypothesis-testing-a-level-recap.html"><a href="hypothesis-testing-a-level-recap.html#one-sided-and-two-sided-alternative-hypotheses"><i class="fa fa-check"></i><b>6.1.1</b> One-sided and two-sided alternative hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="hypothesis-testing-a-level-recap.html"><a href="hypothesis-testing-a-level-recap.html#fishers-p-value-method"><i class="fa fa-check"></i><b>6.2</b> Fisher’s <span class="math inline">\(p\)</span>-value method</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="hypothesis-testing-a-level-recap.html"><a href="hypothesis-testing-a-level-recap.html#what-counts-as-a-small-p-value"><i class="fa fa-check"></i><b>6.2.1</b> What counts as a small <span class="math inline">\(p\)</span>-value?</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="hypothesis-testing-a-level-recap.html"><a href="hypothesis-testing-a-level-recap.html#relationship-between-the-neyman-pearson-and-p-value-methods"><i class="fa fa-check"></i><b>6.3</b> Relationship between the Neyman-Pearson and <span class="math inline">\(p\)</span>-value methods</a></li>
<li class="chapter" data-level="6.4" data-path="hypothesis-testing-a-level-recap.html"><a href="hypothesis-testing-a-level-recap.html#one-sample-t-test"><i class="fa fa-check"></i><b>6.4</b> One-sample <span class="math inline">\(t\)</span>-test</a></li>
<li class="chapter" data-level="6.5" data-path="hypothesis-testing-a-level-recap.html"><a href="hypothesis-testing-a-level-recap.html#which-hypothesis-test-do-i-use-for"><i class="fa fa-check"></i><b>6.5</b> Which hypothesis test do I use for…?</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html"><i class="fa fa-check"></i><b>7</b> Hypothesis testing: comparing two population means</a>
<ul>
<li class="chapter" data-level="7.1" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#example-can-imagining-eating-food-make-you-eat-less"><i class="fa fa-check"></i><b>7.1</b> Example: can imagining eating food make you eat less?</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#the-hypotheses"><i class="fa fa-check"></i><b>7.1.1</b> The hypotheses</a></li>
<li class="chapter" data-level="7.1.2" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#a-test-statistic"><i class="fa fa-check"></i><b>7.1.2</b> A test statistic</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#hypothesis-testing-using-simulation"><i class="fa fa-check"></i><b>7.2</b> Hypothesis testing using simulation</a></li>
<li class="chapter" data-level="7.3" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#the-two-sample-t-test"><i class="fa fa-check"></i><b>7.3</b> The two-sample <span class="math inline">\(t\)</span> test</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#the-two-sample-t-test-with-the-neyman-pearson-method"><i class="fa fa-check"></i><b>7.3.1</b> The two-sample <span class="math inline">\(t\)</span>-test with the Neyman-Pearson method</a></li>
<li class="chapter" data-level="7.3.2" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#an-illustrated-guide"><i class="fa fa-check"></i><b>7.3.2</b> An illustrated guide</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#confidence-interval-for-the-difference-between-two-means"><i class="fa fa-check"></i><b>7.4</b> Confidence interval for the difference between two means</a></li>
<li class="chapter" data-level="7.5" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#equivalence-of-confidence-intervals-and-neyman-pearson-testing"><i class="fa fa-check"></i><b>7.5</b> Equivalence of confidence intervals and Neyman-Pearson testing</a></li>
<li class="chapter" data-level="7.6" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#the-two-sample-t-test-in-r"><i class="fa fa-check"></i><b>7.6</b> The two-sample <span class="math inline">\(t\)</span> test in R</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#t-tests-with-data-frames-in-r"><i class="fa fa-check"></i><b>7.6.1</b> <span class="math inline">\(t\)</span>-tests with data frames in R</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#examples"><i class="fa fa-check"></i><b>7.7</b> Examples</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#using-the-p-value-method"><i class="fa fa-check"></i><b>7.7.1</b> Using the <span class="math inline">\(p\)</span>-value method</a></li>
<li class="chapter" data-level="7.7.2" data-path="hypothesis-testing-comparing-two-population-means.html"><a href="hypothesis-testing-comparing-two-population-means.html#using-neyman-pearson-testing"><i class="fa fa-check"></i><b>7.7.2</b> Using Neyman-Pearson testing</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="hypothesis-testing-comparing-two-proportions.html"><a href="hypothesis-testing-comparing-two-proportions.html"><i class="fa fa-check"></i><b>8</b> Hypothesis testing: comparing two proportions</a>
<ul>
<li class="chapter" data-level="8.1" data-path="hypothesis-testing-comparing-two-proportions.html"><a href="hypothesis-testing-comparing-two-proportions.html#example-an-investigation-into-gender-bias"><i class="fa fa-check"></i><b>8.1</b> Example: an investigation into gender bias</a></li>
<li class="chapter" data-level="8.2" data-path="hypothesis-testing-comparing-two-proportions.html"><a href="hypothesis-testing-comparing-two-proportions.html#comparing-two-binomial-proportions"><i class="fa fa-check"></i><b>8.2</b> Comparing two binomial proportions</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="hypothesis-testing-comparing-two-proportions.html"><a href="hypothesis-testing-comparing-two-proportions.html#a-simulation-method"><i class="fa fa-check"></i><b>8.2.1</b> A simulation method</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="hypothesis-testing-comparing-two-proportions.html"><a href="hypothesis-testing-comparing-two-proportions.html#an-analytical-method"><i class="fa fa-check"></i><b>8.3</b> An analytical method</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="hypothesis-testing-comparing-two-proportions.html"><a href="hypothesis-testing-comparing-two-proportions.html#the-analytical-method-a-summary"><i class="fa fa-check"></i><b>8.3.1</b> The analytical method: a summary</a></li>
<li class="chapter" data-level="8.3.2" data-path="hypothesis-testing-comparing-two-proportions.html"><a href="hypothesis-testing-comparing-two-proportions.html#conclusion"><i class="fa fa-check"></i><b>8.3.2</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="hypothesis-testing-comparing-two-proportions.html"><a href="hypothesis-testing-comparing-two-proportions.html#confidence-intervals-to-measure-the-difference"><i class="fa fa-check"></i><b>8.4</b> Confidence intervals to measure the difference</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="sample-size-and-power-for-a-neyman-pearson-hypothesis-test.html"><a href="sample-size-and-power-for-a-neyman-pearson-hypothesis-test.html"><i class="fa fa-check"></i><b>9</b> Sample size and power for a Neyman-Pearson hypothesis test</a>
<ul>
<li class="chapter" data-level="9.1" data-path="sample-size-and-power-for-a-neyman-pearson-hypothesis-test.html"><a href="sample-size-and-power-for-a-neyman-pearson-hypothesis-test.html#gender-bias-example-re-visited"><i class="fa fa-check"></i><b>9.1</b> Gender bias example re-visited</a></li>
<li class="chapter" data-level="9.2" data-path="sample-size-and-power-for-a-neyman-pearson-hypothesis-test.html"><a href="sample-size-and-power-for-a-neyman-pearson-hypothesis-test.html#the-power-of-a-hypothesis-test"><i class="fa fa-check"></i><b>9.2</b> The power of a hypothesis test</a></li>
<li class="chapter" data-level="9.3" data-path="sample-size-and-power-for-a-neyman-pearson-hypothesis-test.html"><a href="sample-size-and-power-for-a-neyman-pearson-hypothesis-test.html#an-analytical-approach"><i class="fa fa-check"></i><b>9.3</b> An analytical approach</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html"><i class="fa fa-check"></i><b>10</b> <span class="math inline">\(\chi^2\)</span> tests for contingency tables</a>
<ul>
<li class="chapter" data-level="10.1" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#example-customer-ratings-of-restaurants"><i class="fa fa-check"></i><b>10.1</b> Example: customer ratings of restaurants</a></li>
<li class="chapter" data-level="10.2" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#a-model-and-hypotheses"><i class="fa fa-check"></i><b>10.2</b> A model and hypotheses</a></li>
<li class="chapter" data-level="10.3" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#a-test-statistic-1"><i class="fa fa-check"></i><b>10.3</b> A test statistic</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#the-formula-for-the-expected-counts"><i class="fa fa-check"></i><b>10.3.1</b> The formula for the expected counts</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#computing-the-test-statistic-for-the-observed-data"><i class="fa fa-check"></i><b>10.4</b> Computing the test statistic for the observed data</a></li>
<li class="chapter" data-level="10.5" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#a-simulation-method-1"><i class="fa fa-check"></i><b>10.5</b> A simulation method</a></li>
<li class="chapter" data-level="10.6" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#an-analytical-method-1"><i class="fa fa-check"></i><b>10.6</b> An analytical method</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#chi2-tests-in-r"><i class="fa fa-check"></i><b>10.6.1</b> <span class="math inline">\(\chi^2\)</span> tests in R</a></li>
<li class="chapter" data-level="10.6.2" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#row-homogeneity-and-independence"><i class="fa fa-check"></i><b>10.6.2</b> Row homogeneity and independence</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="chi2-tests-for-contingency-tables.html"><a href="chi2-tests-for-contingency-tables.html#exercise"><i class="fa fa-check"></i><b>10.7</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="index-of-definitions-and-examples.html"><a href="index-of-definitions-and-examples.html"><i class="fa fa-check"></i><b>11</b> Index of definitions and examples</a>
<ul>
<li class="chapter" data-level="11.1" data-path="index-of-definitions-and-examples.html"><a href="index-of-definitions-and-examples.html#definitions"><i class="fa fa-check"></i><b>11.1</b> Definitions</a></li>
<li class="chapter" data-level="11.2" data-path="index-of-definitions-and-examples.html"><a href="index-of-definitions-and-examples.html#examples-1"><i class="fa fa-check"></i><b>11.2</b> Examples</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MPS114 - An Introduction to Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hypothesis-testing-comparing-two-proportions" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">Chapter 8</span> Hypothesis testing: comparing two proportions<a href="hypothesis-testing-comparing-two-proportions.html#hypothesis-testing-comparing-two-proportions" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<script type="text/javascript">
$(document).ready(function() {
  $folds = $(".fold");
  $folds.wrapInner("<div class=\"fold-blck\">"); // wrap a div container around content
  $folds.prepend("<button class=\"fold-btn\">Show solution</button>");  // add a button
  $(".fold-blck").toggle();  // fold all blocks
  $(".fold-btn").on("click", function() {  // add onClick event
    $(this).text($(this).text() === "Show solution" ? "Hide solution" : "Show solution");  // if the text equals "Fold", change it to "Unfold"or else to "Fold" 
    $(this).next(".fold-blck").toggle("linear");  // "swing" is the default easing function. This can be further customized in its speed or the overall animation itself.
  })
});
</script>
<p>In this chapter we will test whether the probability parameters <span class="math inline">\(\theta_X\)</span> and <span class="math inline">\(\theta_Y\)</span> in two binomial distributions <span class="math inline">\(X\sim Bin(n, \theta_X)\)</span> and <span class="math inline">\(Y\sim Bin(m, \theta_Y)\)</span>, are equal or not, given observations from each distribution. In particular, when might we conclude that <span class="math inline">\(\theta_X\)</span> and <span class="math inline">\(\theta_Y\)</span> are different, based on an observed difference between <span class="math inline">\(X/n\)</span> and <span class="math inline">\(Y/m\)</span>?</p>
<p>We will again use two different methods: a computer simulation method, and an analytical method based on the normal distribution.</p>
<div id="example-an-investigation-into-gender-bias" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> Example: an investigation into gender bias<a href="hypothesis-testing-comparing-two-proportions.html#example-an-investigation-into-gender-bias" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Steinpreis et al. (1999)<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a> conducted the following experiment. CVs were sent to male and female academic psychologists at various US universities. The psychologists were asked whether or not they would hire the applicant for an academic job based on the CV. The CVs sent to the psychologists were identical <em>except</em> for the name of the applicant: “Brian Miller” on some, and “Karen Miller” on the others. The interest was in whether the gender of the applicant made a difference: whether male applicants were more or less likely to be hired than female applicants.</p>
<p>Results from the experiment were as follows. The “recruiters” are the academic psychologists. There are 128 different recruiters: each recruiter sees one CV only, where the applicant is either male or female.</p>
<table>
<thead>
<tr class="header">
<th>applicant</th>
<th>recruiter</th>
<th>hired</th>
<th>rejected</th>
<th>% hired</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>male</td>
<td>male</td>
<td>24</td>
<td>7</td>
<td>77.4%</td>
</tr>
<tr class="even">
<td>female</td>
<td>male</td>
<td>16</td>
<td>16</td>
<td>50.0%</td>
</tr>
<tr class="odd">
<td>male</td>
<td>female</td>
<td>22</td>
<td>10</td>
<td>68.8%</td>
</tr>
<tr class="even">
<td>female</td>
<td>female</td>
<td>13</td>
<td>20</td>
<td>39.4%</td>
</tr>
</tbody>
</table>
<p>The data suggest a clear gender bias: male applicants are more likely to be hired (regardless of the gender of the recruiter). But can we be sure of this? We’d expect recruiters to have different opinions anyway, and we can see that within each row of the table, some recruiters must have been more demanding of their applicants than others, in that some chose to hire, and others chose to reject. Perhaps we were just unlucky with our sample of recruiters? For example, perhaps in row two of the table, recruiters tended to be more demanding than the recruiters in row one? We can investigate this using a hypothesis test (as did the study authors, though they used a slightly different method.)</p>
</div>
<div id="comparing-two-binomial-proportions" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> Comparing two binomial proportions<a href="hypothesis-testing-comparing-two-proportions.html#comparing-two-binomial-proportions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>To simplify things, we’ll just consider the male recruiters:</p>
<table>
<thead>
<tr class="header">
<th>applicant</th>
<th>recruiter</th>
<th>hired</th>
<th>rejected</th>
<th>% hired</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>male</td>
<td>male</td>
<td>24</td>
<td>7</td>
<td>77.4%</td>
</tr>
<tr class="even">
<td>female</td>
<td>male</td>
<td>16</td>
<td>16</td>
<td>50.0%</td>
</tr>
</tbody>
</table>
<p>The observed difference in % hired for the two groups was 27.4% Could a difference this large arise purely by chance?</p>
<p>We use a binomial model for the data, with a separate binomial distribution for the number of recruiters choosing to hire in each row of the table: defining <span class="math inline">\(X\)</span> as the number of recruiters who would hire the male applicant, and <span class="math inline">\(Y\)</span> as the number of recruiters who would hire the female applicant, we suppose that</p>
<p><span class="math display">\[\begin{align}
X &amp;\sim Binomial(n, \theta_X),\\
Y &amp;\sim Binomial(m, \theta_Y),
\end{align}\]</span>
with <span class="math inline">\(n = 31\)</span> and <span class="math inline">\(m=32\)</span>. We interpret <span class="math inline">\(\theta_X\)</span> and <span class="math inline">\(\theta_Y\)</span> as, respectively, the proportion of all recruiters in the population who would hire the male applicant, and the proportion of all recruiters in the population who would hire the female applicant.</p>
<p>If the gender of the applicant was irrelevant to all recruiters, then we would have <span class="math inline">\(\theta_X = \theta_Y\)</span>, and we will write our null hypothesis as
<span class="math display">\[
H_0: \theta_X = \theta_Y.
\]</span></p>
<div id="a-simulation-method" class="section level3 hasAnchor" number="8.2.1">
<h3><span class="header-section-number">8.2.1</span> A simulation method<a href="hypothesis-testing-comparing-two-proportions.html#a-simulation-method" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As before, we need to understand what sort of data could arise <em>purely by chance</em>. In our gender bias example, we need to understand how different <span class="math inline">\(X/n\)</span> and <span class="math inline">\(Y/m\)</span> could be, if <span class="math inline">\(H_0\)</span> were true and the probabilities <span class="math inline">\(\theta_X\)</span> and <span class="math inline">\(\theta_Y\)</span> were the same.</p>
<p>In the experiment, the observed values of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> were 24 and 16 (with the observed difference in proportions being <span class="math inline">\(\frac{24}{31} - \frac{16}{32}\simeq 27\%\)</span>).</p>
<ul>
<li>If it’s (almost) impossible to get a difference this large purely by random chance, we would conclude that the experiment has provided evidence <em>against</em> the hypothesis that the two probabilities <span class="math inline">\(\theta_X\)</span> and <span class="math inline">\(\theta_Y\)</span> are equal.</li>
<li>If it’s easy to get a difference this large purely by random chance, we <em>won’t</em> say this shows <span class="math inline">\(H_0\)</span> is true, but we <em>will</em> say that the experiment has <em>failed to provide evidence against <span class="math inline">\(H_0\)</span></em>.</li>
</ul>
<p>Let’s now see what can happen purely by chance, using simulation. We will need to choose <span class="math inline">\(\theta_X\)</span> and <span class="math inline">\(\theta_Y\)</span>, which we need to be equal if we are assuming <span class="math inline">\(H_0\)</span> is true. We’ll choose these probabilities to equal the total number of hires (40) divided by the total number of recruiters (63).</p>
<p>We’ll first simulate five <span class="math inline">\(X,Y\)</span> pairs in R: we simulate five observations from the <span class="math inline">\(Binomial(31, 40/63)\)</span> distribution, and store the result in the vector <code>males</code> and five observations from the <span class="math inline">\(Binomial(32, 40/63)\)</span> distribution, and store the result in the vector <code>females</code>:</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="hypothesis-testing-comparing-two-proportions.html#cb180-1" tabindex="-1"></a>males <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="at">n =</span> <span class="dv">5</span>, <span class="at">size =</span> <span class="dv">31</span>, <span class="at">prob =</span> <span class="dv">40</span><span class="sc">/</span><span class="dv">63</span>)</span>
<span id="cb180-2"><a href="hypothesis-testing-comparing-two-proportions.html#cb180-2" tabindex="-1"></a>females <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="at">n =</span> <span class="dv">5</span>, <span class="at">size =</span> <span class="dv">32</span>, <span class="at">prob =</span> <span class="dv">40</span><span class="sc">/</span><span class="dv">63</span>)</span></code></pre></div>
<p>Then to see what we’ve got:</p>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="hypothesis-testing-comparing-two-proportions.html#cb181-1" tabindex="-1"></a>males</span></code></pre></div>
<pre><code>## [1] 21 21 19 16 22</code></pre>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="hypothesis-testing-comparing-two-proportions.html#cb183-1" tabindex="-1"></a>females</span></code></pre></div>
<pre><code>## [1] 17 16 19 19 24</code></pre>
<p>and to compare the proportions:</p>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb185-1"><a href="hypothesis-testing-comparing-two-proportions.html#cb185-1" tabindex="-1"></a>males<span class="sc">/</span><span class="dv">31</span> <span class="sc">-</span> females<span class="sc">/</span><span class="dv">32</span></span></code></pre></div>
<pre><code>## [1]  0.14617  0.17742  0.01915 -0.07762 -0.04032</code></pre>
<p>The first pair generated for <span class="math inline">\((X,Y)\)</span> was (21, 17), and the difference between the two proportions was <span class="math inline">\(\frac{21}{31} - \frac{17}{32} \simeq 0.15\)</span>: we got a 15% difference in the proportions hired, just by random chance. However, we didn’t get anything as large as the <em>observed</em> difference of 27%. Now we will do this a large number of times, and look at the distribution of the difference between the proportions:</p>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb187-1"><a href="hypothesis-testing-comparing-two-proportions.html#cb187-1" tabindex="-1"></a>males <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="at">n =</span> <span class="dv">100000</span>, <span class="at">size =</span> <span class="dv">31</span>, <span class="at">prob =</span> <span class="dv">40</span><span class="sc">/</span><span class="dv">63</span>)</span>
<span id="cb187-2"><a href="hypothesis-testing-comparing-two-proportions.html#cb187-2" tabindex="-1"></a>females <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="at">n =</span> <span class="dv">100000</span>, <span class="at">size =</span> <span class="dv">32</span>, <span class="at">prob =</span> <span class="dv">40</span><span class="sc">/</span><span class="dv">63</span>)</span>
<span id="cb187-3"><a href="hypothesis-testing-comparing-two-proportions.html#cb187-3" tabindex="-1"></a>differences <span class="ot">&lt;-</span> males<span class="sc">/</span><span class="dv">31</span> <span class="sc">-</span> females<span class="sc">/</span><span class="dv">32</span></span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-173"></span>
<img src="MPS114-Data-Science_files/figure-html/unnamed-chunk-173-1.png" alt="Histogram of simulated differences $X/31 - Y/32$, randomly generated assuming $H_0$ is true. It is possible to obtain differences larger than 0.274 (the difference observed in the experiment), but not very likely; it's hard to obtain a difference this large by random chance alone." width="576" />
<p class="caption">
Figure 8.1: Histogram of simulated differences <span class="math inline">\(X/31 - Y/32\)</span>, randomly generated assuming <span class="math inline">\(H_0\)</span> is true. It is possible to obtain differences larger than 0.274 (the difference observed in the experiment), but not very likely; it’s hard to obtain a difference this large by random chance alone.
</p>
</div>
<p>We can see that it is possible to get a difference as large as 0.274, but not that likely. Out of the 100,000 simulations, we can count how many times this happened:</p>
<div class="sourceCode" id="cb188"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb188-1"><a href="hypothesis-testing-comparing-two-proportions.html#cb188-1" tabindex="-1"></a><span class="fu">sum</span>(differences <span class="sc">&gt;=</span> <span class="fl">0.274</span>)</span></code></pre></div>
<pre><code>## [1] 1306</code></pre>
<p>so we would estimate the probability of seeing a difference as large as 0.274, purely by random chance, to be 1306 <span class="math inline">\(/\)</span> 100000 <span class="math inline">\(\simeq\)</span> 0.013.</p>
<p>What about the negative differences, in particular those, below -0.274? Should we count those? This depends on whether we want to report</p>
<ol style="list-style-type: decimal">
<li>how <em>far apart</em> <span class="math inline">\(X/n\)</span> and <span class="math inline">\(Y/m\)</span> could be, purely by random chance, or</li>
<li>how <em>much greater</em> <span class="math inline">\(X/n\)</span> could be than <span class="math inline">\(Y/m\)</span>, purely by random chance.</li>
</ol>
<p>In this case, a large negative value of <span class="math inline">\(X/n-Y/m\)</span> would still suggest unequal treatment of males and females, so we should report the first case above. This means that we are using a <strong>two-sided</strong> alternative hypothesis</p>
<p><span class="math display">\[
H_A: \theta_X \neq \theta_Y,
\]</span>
rather than a <strong>one-sided</strong> alternative <span class="math inline">\(H_A: \theta_X&gt; \theta_Y\)</span>.</p>
<p>So we calculate how many times we generated obtained <span class="math inline">\(|X/31 - Y/32|\ge 0.274\)</span> (use the <code>abs()</code> command in R to get the absolute value)</p>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb190-1"><a href="hypothesis-testing-comparing-two-proportions.html#cb190-1" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">abs</span>(differences) <span class="sc">&gt;=</span> <span class="fl">0.274</span>)</span></code></pre></div>
<pre><code>## [1] 2308</code></pre>
<p>So in conclusion, we report the value of</p>
<p><span class="math display">\[
P\left(\left|\frac{X}{31} - \frac{Y}{32}\right|\ge 0.274\right),  
\]</span>
assuming <span class="math inline">\(H_0\)</span> to be true, which we estimate to be 100000.274 <span class="math inline">\(/\)</span> 100000 <span class="math inline">\(\simeq\)</span> 0.023.</p>
<p>In summary:</p>
<p>we estimate about a 2% probability that, by nothing other than random chance, the (absolute) difference in percentages of hired applicants between the genders could be as large as 27.4% (the difference that was observed in the experiment).</p>
<div class="rmdnote">
<p>
This probability of 2% is a <span class="math inline"><span class="math inline">\(p\)</span></span>-value: a probability of getting a
difference as extreme as the one we observed, assuming <span class="math inline"><span class="math inline">\(H_0\)</span></span> to be true.
</p>
</div>
</div>
</div>
<div id="an-analytical-method" class="section level2 hasAnchor" number="8.3">
<h2><span class="header-section-number">8.3</span> An analytical method<a href="hypothesis-testing-comparing-two-proportions.html#an-analytical-method" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>So we can write this in general terms, we will define <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> as the observed values of the random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> (in the example, we have <span class="math inline">\(x=21\)</span> and <span class="math inline">\(y=17\)</span>). We used simulation to estimate
<span class="math display">\[
P\left(\left|\frac{X}{n} - \frac{Y}{m}\right|\ge \left|\frac{x}{n} - \frac{y}{m} \right|\right),
\]</span>
assuming <span class="math inline">\(H_0\)</span> to be true. We will now attempt to work out this probability analytically, by expressing it in terms of a standard probability distribution. We have</p>
<p><span class="math display">\[
P\left(\left|\frac{X}{n} - \frac{Y}{m}\right|\ge \left|\frac{x}{n} - \frac{y}{m} \right|\right) =  P\left(\frac{\left|\frac{X}{n} - \frac{Y}{m}\right|}{\sqrt{v}}\ge\frac{ \left|\frac{x}{n} - \frac{y}{m} \right|}{\sqrt{v}}\right)
\]</span></p>
<p>where we define
<span class="math display">\[
v:= p^*(1-p^*)\left(\frac{1}{n} + \frac{1}{m}\right)
\]</span>
with
<span class="math display">\[
p^*: = \frac{x+y}{n+m}
\]</span>
Now we define
<span class="math display">\[
Z:= \frac{\frac{X}{n} - \frac{Y}{m}}{\sqrt{v}}
\]</span>
If we assume <span class="math inline">\(H_0\)</span> is true, and we further assume <span class="math inline">\(\theta_X = \theta_Y = \frac{x+y}{n+m}\)</span> (just as we did to simulate our random data), then we have</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(Z) &amp;= 0,\\
Var(Z)&amp;=1.
\end{align}\]</span>
(Deriving these results is an exercise in the tutorial questions.)</p>
<p>We now make the <em>approximation</em> that <span class="math inline">\(Z\sim N(0,1)\)</span> (using the result that a <span class="math inline">\(Binomial(n,p)\)</span> distribution can be approximated by a <span class="math inline">\(N(np, np(1-p))\)</span> distribution, for ‘large’ <span class="math inline">\(n\)</span> and ‘moderate’ <span class="math inline">\(p\)</span>.).</p>
<div class="rmdnote">
<p>
We <em>didn’t</em> have to make any approximations about normal
distributions in the simulation method, so we can think of that as more
‘accurate’ than this analytical method. But maybe we’ll get similar
results! We will soon see…
</p>
</div>
<p>To compute the <span class="math inline">\(p\)</span>-value, we can write</p>
<p><span class="math display">\[\begin{align}
P\left(\left|\frac{X}{n} - \frac{Y}{m}\right|\ge  \left|\frac{x}{n} - \frac{y}{m} \right|\right)&amp;= P\left(|Z| \ge \frac{\left|\frac{x}{n} - \frac{y}{m} \right|}{\sqrt{v}}\right)\\
&amp; P\left(Z \le - \frac{\left|\frac{x}{n} - \frac{y}{m} \right|}{\sqrt{v}}\right)  + P \left(Z\ge \frac{\left|\frac{x}{n} - \frac{y}{m} \right|}{\sqrt{v}}\right)\\
&amp;\simeq \Phi\left(-\frac{\left|\frac{x}{n} - \frac{y}{m} \right|}{\sqrt{v}}\right) + 1 - \Phi \left(\frac{\left|\frac{x}{n} - \frac{y}{m} \right|}{\sqrt{v}}\right ),
\end{align}\]</span>
where <span class="math inline">\(\Phi(.)\)</span> is the cumulative distribution function of the <span class="math inline">\(N(0,1)\)</span> distribution.</p>
<p>In our example, with <span class="math inline">\(n=31, m=32, x = 24, y = 16\)</span>, we compute</p>
<p><span class="math display">\[p^* =\frac{24 + 16}{31 + 32},\quad v = p^*(1-p^*)\left(\frac{1}{31}+ \frac{1}{32}\right) \]</span>
and our p-value is
<span class="math display">\[
\Phi(-2.2599) + 1 - \Phi(2.2599)= 0.024,
\]</span>
to 3 d.p. Notice how similar this is to the <span class="math inline">\(p\)</span>-value computed using simulation. We visualise the <span class="math inline">\(p\)</span>-value in Figure <a href="hypothesis-testing-comparing-two-proportions.html#fig:binomPval">8.2</a>, where we plot the distribution of <span class="math inline">\(Z\)</span> under <span class="math inline">\(H_0\)</span>. For comparison, we also plot the histogram of our simulated values <span class="math inline">\(X/31 - Y/32\)</span>, each now divided by <span class="math inline">\(\sqrt{v}\)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:binomPval"></span>
<img src="MPS114-Data-Science_files/figure-html/binomPval-1.png" alt="The distribution of the test statistic $Z$ under $H_0$. For comparison, a histogram shows the distribution of test statistics obtained using random simulation: note the close agreement." width="576" />
<p class="caption">
Figure 8.2: The distribution of the test statistic <span class="math inline">\(Z\)</span> under <span class="math inline">\(H_0\)</span>. For comparison, a histogram shows the distribution of test statistics obtained using random simulation: note the close agreement.
</p>
</div>
<div id="the-analytical-method-a-summary" class="section level3 hasAnchor" number="8.3.1">
<h3><span class="header-section-number">8.3.1</span> The analytical method: a summary<a href="hypothesis-testing-comparing-two-proportions.html#the-analytical-method-a-summary" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To summarise, the steps are as follows.</p>
<ol style="list-style-type: decimal">
<li>State the model and hypotheses</li>
</ol>
<p>We wish to compare two binomial proportions. We have</p>
<p><span class="math display">\[
X\sim Bin(n,\theta_X),
\]</span>
<span class="math display">\[
Y\sim Bin(m,\theta_Y)
\]</span>
and our null hypothesis is
<span class="math display">\[
H_0:\theta_X = \theta_Y,
\]</span>
the ‘success’ probabilities in our two samples are the same. For a two-sided alternative, we have
<span class="math display">\[
H_A: \theta_X \neq \theta_Y
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Choose an appropriate test statistic</strong></li>
</ol>
<p>The test statistic measures the difference between the two sample proportions. We use use the test statistic
<span class="math display">\[\begin{equation}
Z = \frac{\frac{X}{n} - \frac{Y}{m}  }{\sqrt{P^*(1-P^*)\left(\frac{1}{n}+\frac{1}{m}\right)}},
\end{equation}\]</span>
where
<span class="math display">\[\begin{equation}
P^* = \frac{X+Y}{n+m}
\end{equation}\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li><strong>State the distribution of the test statistic, under the assumption that <span class="math inline">\(H_0\)</span> is true</strong></li>
</ol>
<p>We think of <span class="math inline">\(Z\)</span> as a random variable, because it is a function of the two binomial random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. If <span class="math inline">\(H_0\)</span> is true, then approximately, we have
<span class="math display">\[Z\sim N(0,1).\]</span></p>
<ol start="4" style="list-style-type: decimal">
<li><strong>Calculate the test statistic for the observed data</strong></li>
</ol>
<p>Remembering that we denote the values we actually observed by <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, the corresponding observed value of the test statistic is</p>
<p><span class="math display">\[
z_{obs} = \frac{\frac{x}{n} - \frac{y}{m}  }{\sqrt{p^*(1-p^*)\left(\frac{1}{n}+\frac{1}{m}\right)}},
\]</span>
where
<span class="math display">\[
p^* = \frac{x+y}{n+m}.
\]</span></p>
<ol start="5" style="list-style-type: decimal">
<li><strong>Report the evidence against the null hypothesis, by calculating the <span class="math inline">\(p\)</span>-value</strong></li>
</ol>
<p>We have the same definition of the <span class="math inline">\(p\)</span>-value as before, but now using the test statistic <span class="math inline">\(Z\)</span> and its corresponding distribution under <span class="math inline">\(H_0\)</span>:
<span class="math display">\[
P(|Z|\ge |z_{obs}|),
\]</span></p>
</div>
<div id="conclusion" class="section level3 hasAnchor" number="8.3.2">
<h3><span class="header-section-number">8.3.2</span> Conclusion<a href="hypothesis-testing-comparing-two-proportions.html#conclusion" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In statistical terms, we would say that with a <span class="math inline">\(p\)</span>-value between 0.01 and 0.05, we have ‘weak’ evidence against the null hypothesis. Given such a <span class="math inline">\(p\)</span>-value (and noting that the experiment was fairly small in any case), it would be desirable to replicate the experiment, to see if the results are the same. This has indeed happened: see for example Moss-Racusin et al. (2012)<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a>], who conducted a similar study, and observed a similar bias against female job applicants.</p>
</div>
</div>
<div id="confidence-intervals-to-measure-the-difference" class="section level2 hasAnchor" number="8.4">
<h2><span class="header-section-number">8.4</span> Confidence intervals to measure the difference<a href="hypothesis-testing-comparing-two-proportions.html#confidence-intervals-to-measure-the-difference" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>An approximate 95% confidence interval for the difference <span class="math inline">\(\theta_X - \theta_Y\)</span> is given by
<span class="math display">\[\begin{equation}
\frac{x}{n} - \frac{y}{m} \pm 1.96 \sqrt{v},
\end{equation}\]</span>
with
<span class="math display">\[v = p^*(1-p^*)\left(\frac{1}{n}+ \frac{1}{m}\right),\quad p^* =\frac{x + y}{n + m}. \]</span>
In our example, we obtain a 95% confidence interval of (3.6%, 51.2%): this is wide in this context, reflecting a lot of uncertainty.</p>
<div class="example">
<p><span id="exm:exampleReoffending" class="example"><strong>Example 8.1  (Hypothesis testing: comparing binomial proportions. Can early release and tagging of prisoners affect the likelihood of reoffending?) </strong></span><br> Meuer and Woessner (2018)<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a> describe an experiment to test the effect of electronic monitoring (tagging) on “low-risk” prisoners. We describe some of their data here. Forty-eight (male) prisoners were randomly allocated to two groups:</p>
</div>
<ul>
<li>in the experimental group, the prisoner served the last part of his sentence under “supervised early work release”, involving the use of an open prison and electronic tagging.</li>
<li>in the control group, the prisoner served the last part of his sentence in prison, as normal.</li>
</ul>
<p>Following the end of the sentence, the prisoners were followed up for two years. It was recorded whether each prisoner reoffended. The results were as follows.</p>
<table>
<thead>
<tr class="header">
<th>group</th>
<th>sample size</th>
<th>number reoffending</th>
<th>% reoffending</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>experimental</td>
<td>24</td>
<td>7</td>
<td>29.2%</td>
</tr>
<tr class="even">
<td>control</td>
<td>30</td>
<td>15</td>
<td>50.0%</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: decimal">
<li><p>Specify an appropriate model for these data and hypothesis to test.</p></li>
<li><p>Use the following R output to assess whether there is evidence that early work release/tagging scheme has affected the probability of reoffending</p></li>
</ol>
<div class="sourceCode" id="cb192"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb192-1"><a href="hypothesis-testing-comparing-two-proportions.html#cb192-1" tabindex="-1"></a>experimental <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="at">n =</span> <span class="dv">100000</span>, <span class="at">size =</span> <span class="dv">24</span>, <span class="at">prob =</span> <span class="dv">22</span> <span class="sc">/</span> <span class="dv">54</span>)</span>
<span id="cb192-2"><a href="hypothesis-testing-comparing-two-proportions.html#cb192-2" tabindex="-1"></a>control <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="at">n =</span> <span class="dv">100000</span>, <span class="at">size =</span> <span class="dv">30</span>, <span class="at">prob =</span> <span class="dv">22</span> <span class="sc">/</span> <span class="dv">54</span>)</span>
<span id="cb192-3"><a href="hypothesis-testing-comparing-two-proportions.html#cb192-3" tabindex="-1"></a>differences <span class="ot">&lt;-</span> experimental <span class="sc">/</span> <span class="dv">24</span> <span class="sc">-</span> control <span class="sc">/</span> <span class="dv">30</span></span>
<span id="cb192-4"><a href="hypothesis-testing-comparing-two-proportions.html#cb192-4" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">abs</span>(differences) <span class="sc">&gt;=</span> <span class="fu">abs</span>(<span class="dv">7</span><span class="sc">/</span><span class="dv">24</span> <span class="sc">-</span> <span class="dv">15</span><span class="sc">/</span><span class="dv">30</span>))</span></code></pre></div>
<pre><code>## [1] 13026</code></pre>
<ol start="3" style="list-style-type: decimal">
<li><p>Conduct a suitable hypothesis test using the normal approximation. Draw a sketch that indicates the <span class="math inline">\(p\)</span>-value. Based on the output above, what do you think the <span class="math inline">\(p\)</span>-value would be?</p></li>
<li><p>Calculate a 95% confidence interval for the difference between the two probabilities of reoffending.</p></li>
</ol>
<div class="fold">
<p><strong>Solution</strong></p>
<ol style="list-style-type: decimal">
<li>Define the random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> as the numbers reoffending in the experimental and control groups respectively. We suppose</li>
</ol>
<p><span class="math display">\[
X\sim Bin(24, \theta_X), \quad Y\sim Bin(30, \theta_Y),.
\]</span>
and our hypotheses are
<span class="math display">\[
H_0: \theta_X = \theta_Y, \quad H_A: \theta_X \neq \theta_Y.
\]</span>
2. The observed difference in proportion was
<span class="math display">\[
\frac{7}{24} - \frac{15}{30} = -0.208,
\]</span>
(to 3 d.p.). In the R code, we have simulated <span class="math inline">\(X, Y\)</span> pairs assuming <span class="math inline">\(H_0\)</span> is true, with <span class="math inline">\(\theta_X = \theta_Y =\frac{7 + 15}{24 + 30}\)</span>. The last line counts how many times we simulated a pair where the (absolute) difference in proportions was at least 0.208. This happened 13026 times out of 100,000, so we estimate that there is 13% probability of observing, purely by random chance, a difference as large at that seen in the experiment. This probability is relatively high, giving no evidence against <span class="math inline">\(H_0\)</span>: no evidence that the early work release/tagging scheme has affected the probability of reoffending.</p>
<ol start="3" style="list-style-type: decimal">
<li>We compute</li>
</ol>
<p><span class="math display">\[
z_{obs} = \frac{\frac{7}{24} - \frac{15}{30}  }{\sqrt{p^*(1-p^*)\left(\frac{1}{24}+\frac{1}{30}\right)}} = -1.54 ,
\]</span>
(with <span class="math inline">\(p^* = (7+15)/(24+30)\)</span>)</p>
<p>The <span class="math inline">\(p\)</span>-value is obtained from
<span class="math display">\[
P(|Z|\ge 1.54),
\]</span></p>
<p>where <span class="math inline">\(Z\sim N(0,1)\)</span>, and is shown as the shaded area in the following plot.</p>
<p>from the R output in part (2), we would expect this to be around 0.13. We can obtain the <span class="math inline">\(p\)</span>-value from R as follows.</p>
<ol start="4" style="list-style-type: decimal">
<li>An approximate 95% confidence interval for the difference in proportions is</li>
</ol>
<p><span class="math display">\[
-0.208 \pm 1.96 \sqrt{v},
\]</span>
with <span class="math inline">\(v = p^*(1-p^*)(1/24 + 1/30)\)</span> and <span class="math inline">\(p^* = (7 + 15)/(24+30)\)</span>, which gives
<span class="math display">\[
(-47\%,\,5.5\% )
\]</span></p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="9">
<li id="fn9"><p>Steinpreis, R. E., Anders, K. A. and Rizke, D. (1999). The Impact of Gender on the Review of the Curricula Vitae of Job Applicants and Tenure Candidates: A National Empirical Study. Sex Roles, Vol. 41, Nos. 7/8.<a href="hypothesis-testing-comparing-two-proportions.html#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p><a href="http://www.pnas.org/content/early/2012/09/14/1211286109">Faculty’s subtle gender biases favor male students</a>,
Corinne A. Moss-Racusin, John F. Dovidio, Victoria L. Brescoll, Mark J. Graham, Jo Handelsman, Proceedings of the National Academy of Sciences Sep 2012, 201211286; DOI: 10.1073/pnas.1211286109<a href="hypothesis-testing-comparing-two-proportions.html#fnref10" class="footnote-back">↩︎</a></p></li>
<li id="fn11"><p>Meuer, K. and Woessner, G. (2018). Does electronic monitoring as a means of release preparation reduce subsequent recidivism? A randomized controlled trial in Germany. European Journal of Criminology, 1-22.<a href="hypothesis-testing-comparing-two-proportions.html#fnref11" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="hypothesis-testing-comparing-two-population-means.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="sample-size-and-power-for-a-neyman-pearson-hypothesis-test.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
